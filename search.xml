<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Kubernetes 组件和架构介绍]]></title>
    <url>%2F2019%2F07%2F29%2Fkubernetes-overview%2F</url>
    <content type="text"><![CDATA[Kubernetes 组件和架构介绍Kubernetes 组件一个 Kubernetes(k8s) 集群的基本构成采用的主从方式，包含 Master Node（主节点） 和 Worker Node（从节点） Master 节点主节点属于 K8s 的控制平面，掌管着集群的全局调度，集群的事件的检测和处理等。主节点内部包含若干组件，尽管每个组件本身可以在集群中任意一台机器上运行，启动脚本为了简化，将组件部署在同样的一台机器上，为了保证集群的高可用，集群环境一般包括多个主节点。下面简单梳理一下主节点的各个组件构成： kube-apiserver kuber-apiserver 是 k8s 控制平面的前端，对外提供 API 服务，可以方便的水平扩展 etcd 为 k8s 集群数据的提供一致性高可用 K, V 存储 kube-scheduler 负责将 pod 调度到合适的 Worker Node 上，调度综合考虑，硬件，软件，策略限制，亲和性设置，数据本地化，不同负载之间的干扰等 kube-controller-manager 控制器主要是主节点对于从节点管理，服务层面的鉴权，服务端点维护等，包括： Node Controller：负责从节点失效的监测和处理 Replication Controller： 维护 Pod 服务数量的一致性 Endpoints Controller： 服务端点的变化相关的维护 Service Account &amp; Token Controllers： 名字空间下的账户和 API 访问口令的管理 cloud-controller-manager k8s 和不同云服务厂商对接的管理器，主要包含不同云厂商的定制化相关的功能管理，社区希望云厂商相关的代码和 k8s 核心代码尽量减少依赖，各自独立开发，依靠 cloud-controller-manager 的链接方式运行云厂商相关的管理器，但是历史原因还是有一些相关的控制器依赖，主要包括： Node Controller： 节点停止服务后，节点是否在云厂商那边真正删除 Route Controller： 路由的建立 Service Controller： 云负载均衡器 Volume Controller： 卷存储的生命周期交互 Worker 节点Worker 节点主要是提供 k8s 的容器运行环境，维护运行的 pods，从节点组件包括： kubelet 从节点上运行 Agent，保证 pod 中容器正常运行，健康检查管理等 kube-proxy 从节点运行的网络代理，提供路由转发 container runtime 容器运行环境，支持 docker，containerd， cri-o，rktlet，只要是符合 CRI 接口要求的运行环境都支持。 其他扩展扩展插件利用 k8s 资源等机制实现了集群相关的一些特性功能，主要包括： 提供网络通信和网络策略管理 服务发现（DNS） 可视化和管理 Web 平台 集群内部容器资源的监控 集群级别的日志处理 Kubernetes 架构来自 Kubernetes 官方的文档中给出 k8s 和云控制管理器演化的架构对比，其中也包含了关于不同组件的架构组成： Kubernetes 高可用k8s 的高可用多主节点架构如下： 除了上面这种堆叠式架构外，还可以采用另外一种外部的 etcd 节点架构， 两种架构各有优缺点，根据自身的需求进行选择。 Kubernetes Service 网络架构在 k8s 中， service 这个对象代表一个提供网络服务的应用，这个应用背后就是一组 pods。 pods 在每个从节点上运行，利用 kube-proxy 进行相应的网络转发和代理，kube-proxy 的实现方式是虚拟 IP 的方式，具体有以下几种形式： 用户空间代理模式 （默认是 round-robin） iptables 代理模式 （默认是 random） ipvs 代理模式 （支持多种，rr，lc，dh，sh, sed, nq) k8s 主要支持两类服务发现模型，环境变量和DNS k8s 中服务对外的发布主要有四类方式： ClusterIP （集群内部 IP） NodePort (每个节点 IP， Port) LoadBalancer（云厂商的负载均衡器） ExternalName（CNAME 方式，无需代理方式） Kubernetes 生产环境部署k8s 集群按照相应层次的面向对象不同，涵盖应用，数据面，控制面，集群基础设施，常规集群运维等方面，究竟是自身管理还是使用云产品打包方案，有如下几种形式： 对于上面的几种解决方案，各个云厂商支持的粒度有很大差别，具体可以见参考资料中表格总结 参考资料 https://kubernetes.io/docs/concepts/cluster-administration/addons/ https://kubernetes.io/docs/concepts/overview/components/ https://kubernetes.io/docs/concepts/architecture/cloud-controller/https://kubernetes.io/docs/concepts/architecture/cloud-controller/ https://kubernetes.io/docs/tasks/administer-cluster/highly-available-master/ https://kubernetes.io/docs/concepts/services-networking/service/ https://kubernetes.io/docs/setup/#production-environment]]></content>
      <tags>
        <tag>云原生</tag>
        <tag>Cloud</tag>
        <tag>Container</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于 HTTP/3 的访谈]]></title>
    <url>%2F2019%2F06%2F30%2F%E5%85%B3%E4%BA%8E-HTTP-3-%E7%9A%84%E8%AE%BF%E8%B0%88%2F</url>
    <content type="text"><![CDATA[HTTP/3 是什么？HTTP3 是为了解决现有的 HTTP2 一些性能，安全上的问题而提出的，最初的原型来自于 Google 的内部QUIC 传输层协议，基于 UDP 开发。 HTTP2 历经了 16 年洗礼，才逐渐被各大浏览器产商，软件厂商接受和应用起来， HTTP2 的座位还没稳固，HTTP3 就已经开始迈向历史舞台， 发展过程大致如下： 1QUIC （2012 Google） --》 IETF 进行标准化（2015） --》 QUIC（核心规范提交 IESG 2019） HTTP/3 做了什么改进？HTTP/2 相比 HTTP /1.1 最大程度解决了 HTTP head of line blocking， 引入了 Multiplexing 方法，通过一个 TCP 连接就可以实现客户端，服务端之间的双向数据流并行发送，带来了一定条件下的性能提升。 HTTP/2 确实大大减少了 TCP 连接数，但是却没有解决 TCP 协议层面的引发的 head of line blocking，这个主要是 TCP 本身是有序传输的，单个流的数据丢失会导致其他的数据流受影响而等待，直到丢失的数据被重传接收。 这个问题在丢包率较高的环境下，会让 HTTP/2 相对于的 HTTP/1.1 的性能优势荡然全无。 为了克服 TCP 协议的这个固有问题，QUIC 引入了基于 UDP 之上的类 TCP 实现，使用独立的数据流进行并行传输，单个流的数据丢失只是影响自身，其他的数据流不必停下来等待。 至于为什么选择 UDP， 而不是改进 TCP 或者设计一个新的协议，这个还是历史包袱的问题，大量的网络基础设施已经遍布世界各地，更换代价和时间成本很高，全新的协议基本不靠谱；TCP 协议又因为被广泛使用，改动变更和落实也是很头疼的事情，基本是出力不讨好。 为了让改进特性更快的尝试和兼容，最终选择了基于 UDP 进行传输，同时上层的放在用户态空间实现，减少了对不同操作系统内核的过度依赖。 HTTP/3 协议栈下面的这个图形象的说明了 HTTP/3 相对 HTTP/2 协议栈的不同： 来源：https://http3-explained.haxx.se/zh/the-protocol.html HTTP/3 的未来尽管 HTTP/3 已经在标准化的路上走得越来越稳，摆在面前的一些质疑和问题依然不断，主要是 UDP 的性能 QUIC 资源占用 成长太慢 参考资料 https://datatracker.ietf.org/wg/quic/charter/ https://http3-explained.haxx.se/zh/why-h2.html https://tools.ietf.org/html/draft-ietf-quic-transport-18 https://tools.ietf.org/html/draft-ietf-quic-transport-20 https://diophant.com/blog/what-is-http3-and-why-is-it-needed/]]></content>
      <tags>
        <tag>互联网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019 Hello]]></title>
    <url>%2F2019%2F01%2F01%2FHello2019%2F</url>
    <content type="text"><![CDATA[过去的一年里，陆陆续续的将过去 Chinaunix 上的文章都迁移到 Git 上进行管理了，一方面，不太希望自己的文章绑定到一个平台上，如果平台没有提供合适的保存文章工具，我很担心某天告诉我，你的文章无法继续维护，请自行进行备份迁移。 另外一方面，工具化的发布流程，相比平台的富文本化的工具编辑来说，更加灵活和可控。 2019 年已经到来，新的一代也将进入舞台，我们老胳膊老腿的人也要不甘落后，历史改革滚滚向前，我们自己不能因循守旧，随着年龄越来越大，更要保持初心，对新事物更加包容，就是一句话，直接上，向前进。 致敬我的 2018 年的技术生活。]]></content>
      <tags>
        <tag>闲散</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[玩转 Hexo 配置]]></title>
    <url>%2F2018%2F12%2F16%2F%E7%8E%A9%E8%BD%AChexo%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[随着微信，头条，知乎等自媒体平台的丰富，传统的 Blog 站点相对来讲不再如同以往那样流行了。不过对于技术爱好者来说，Blog 站点仍然是一个可以 free style 的地方，不必受到平台等统一的约束，可以发挥很多 Hack 的地方，结合 Git 玩转的很溜。如果从追风的角度看，单独的沉迷于个人站点是不可以取的，几个原因： 首先，个人的站点访问量小，相比平台内容的曝光率和传播渠道来说，不是很匹配。其次，个人的站点没有适当的推广策略，而平台固有的圈子和口味多样的用户群，相对来说，更容易增加阅读量和关注点。最后，个人的站点变现相对来说比较单一，而平台的变现生态方法更多，更容易有质变条件。 尽管有如此的不足之处，个人站点有个独特的好处就是安静，不管是记录个人生活还是工作，技术都能减少最大的平台无关信息干扰。说了这些，咱们谈谈主题吧，写文章发布的时候，不可避免的有两个需求： 文章太长，需要支持更多内容跳转阅读 文章发表的太多，如何根据关键字迅速的找到原有的内容。 于是，Hexo 下面的两个配置，你一定用得着： 使用 &lt;!-- more --&gt; 来标记阅读全文 注意 这个配置后，跳转页面后是新插入 &lt;!-- more --&gt; 锚的地方，不是文章的最开始处。 配置 localsearch 支持搜索，具体如下： $ npm install hexo-generator-searchdb --save 编辑站点配置文件，加入内容： search: path: search.xml field: post format: html limit: 1000 编辑主题配置文件，将 local_search 的 enable 设置为 true 参考资料： https://theme-next.iissnan.com/faqs.html http://theme-next.iissnan.com/third-party-services.html#search-system]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于 WOT 2018 会议的见闻]]></title>
    <url>%2F2018%2F12%2F01%2FWOT2018_Conf%2F</url>
    <content type="text"><![CDATA[周六大早上北京的天气仍然很糟糕，寒冷并且浓重的雾霾。 为了参加 WOT 会议，所以这个周末起的有点早。 最近因为工作太忙，周五的一天没有来参加，也就今天来赶个晚场了。 签到后，看了一些各个分会场的主题内容，听了听搜索和推荐相关的 AI 实战，主要是各种算法模型的利用和优化，因为没有做过这方面的工作，听得不是很深入。下午，有几个 AI 在行业的赋能场景和平台化建设的话题，蛮有意思。 相对来说，技术打法差别不大，主要是行业的深入应用和场景化剪裁，使得AI落地更加容易。 总体下来，收货不少，有些议题干货充足，每个分会场针对提问的观众都会随机发一些技术书，我自己收到了 3 本书，分别是关于算法，机器学习和社会媒体挖掘，关于议题的更多内容大家可以到官网 http://www.51cto.com/ 了解更多，我就不再赘述了。]]></content>
      <tags>
        <tag>IT 业界</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置简约风格的 Hexo 主题]]></title>
    <url>%2F2018%2F11%2F18%2F%E9%85%8D%E7%BD%AE%E7%AE%80%E7%BA%A6%E9%A3%8E%E6%A0%BC%E7%9A%84_Hexo_%E4%B8%BB%E9%A2%98%2F</url>
    <content type="text"><![CDATA[今天写博客的时候，突然感觉这个 landscape 主题不优雅，想换一个简约优雅的主题风格。查找了一下，发现 Hexo 的 Next 风格很协调，所以打算切换一下看看效果。 动手操作还是比较简单，具体如下： 安装 Next 稳定版本12$ mkdir themes/next$ curl -s https://api.github.com/repos/iissnan/hexo-theme-next/releases/latest | grep tarball_url | cut -d '"' -f 4 | wget -i - -O- | tar -zx -C themes/next --strip-components=1 采用 Hexo Data 文件完成主题配置这种方式是为了解决 Next Git 更新主题冲突的问题，每次冲突需要用户去解决，很是不方便。 Next 推荐采用唯一配置文件，具体位置放在 source/_data/next.yml 下面。 1234$ mkdir -p source/_data$ cd source/_data# 将 site 相关的配置和 theme 主题相关的配置都拷贝到 next.yml 生成网站内容，并且部署12$ hexo g --config source/_data/next.yml$ hexo deploy --config source/_data/next.yml 注明 可以使用 hexo server --debug --config source/_data/next.yml 在本地查看效果 切换主题的时候最也执行 hexo clean 来清除缓存 关于更多的配置 Tags 配置 1234567$ hexo new page tags$ cat source/tags/index.mdtitle: tagsdate: 2018-11-18 21:36:22type: tags--- Social 配置 （连接到 Github， 打开即可） 访问站点统计 （busuanzi_count) 参考 http://ibruce.info/2015/04/04/busuanzi/ Scheme 切换（Gemini 感觉这个左右分栏的布局更上眼） 参考资料http://theme-next.iissnan.com/getting-started.htmlhttps://github.com/iissnan/hexo-theme-nexthttps://hexo.io/zh-cn/docs/themes.html]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang 最新的模块特性]]></title>
    <url>%2F2018%2F11%2F18%2FGoModule%2F</url>
    <content type="text"><![CDATA[Go ModuleGo 1.11 引入对于 Module 概念的初步支持，这个特性具体是什么？ 为什么要引入这个概念，我觉得有必要给大家简单的介绍一下。 背景Go 从最初的 2009.11 发布到如今，已经迈过了 9 年的时间，Go 的包版本管理经历了几个阶段性发展。 2009.11 最初的开始，没有确定的方法来共享 Go 发布的程序，依靠一个简单的 gobuild 封装来构建单一包，产生 makefile 文件，这种方式会 2010.2 goinstall 的提出引入了包的命名格式方式，无需特殊配置来对版本库的代码进行代码库下载和管理 2011.12 Go 1，引入 go 命令 go get 来代替 goinstall go get 作为代码共享的入口，带来了很大的便利，但是有一个重要的问题没哟解决，关于不同包的代码版本如何控制和管理 go get 没有去解决。 go get 默认从代码版本工具获取最新的拷贝，引入了两个问题。 其一，用户无法预料 go get 更新带来的问题 2013~2015其二，无法确保重复性的生成相同的编译版本。 2012~2015 针对问题1，引入了语义化版本规范， 针对问题2，引入了不同的非官方工具，Goven, godep, gb，实现方式各异，无法统一。2016-2017 一个接近官方的工具的诞生和普及 Dep，但是仍然面临类似的问题，缺少和标准化 go 工具统一集成设计的理念。后来 Go 团队就通过一个新的 vgo 项目来进行后续的工作了。 go module 从 vgo 实验（2018.2) 到 1.11 正式纳入官方的实验特性 (2018.8) ，说明 Go 团队仍有许多的设计和社区反馈需要持续演进，社区期望在 1.12 版本中 go module 能够最终稳定下来。 使用方法 对于新的项目 操作方法如下： 创建目录123$ mkdir -p /tmp/scratchpad/hello$ cd /tmp/scratchpad/hello 初始化模块1$ go mod init github.com/HackToday/hello 项目代码1234567891011$ cat &lt;&lt;EOF &gt; hello.gopackage mainimport ( "fmt" "rsc.io/quote")func main() &#123; fmt.Println(quote.Hello())&#125; 运行，生产相应的 mod 文件1234$ go build $ ./helloHello, world. 12345$ cat go.modmodule github.com/you/hellorequire rsc.io/quote v1.5.2 对于已有的项目 项目的结构1234567891011121314151617181920$ cat main.gopackage mainimport ( "fmt" "github.com/go-redis/redis")func main() &#123; fmt.Println("vim-go") client := redis.NewClient(&amp;redis.Options&#123; Addr: "localhost:6379", Password: "", DB: 0, &#125;) pong, err := client.Ping().Result() fmt.Println(pong, err) 根据依赖生成 mod 文件1$ go mod init github.com/HackToday/mtest 注明： 直接运行 go mod init 会报错，是因为无法自动推导出模块路径 12$ cat go.modmodule github.com/HackToday/mtest 构建模块1$ go build ./... 1234$ cat go.mod module github.com/HackToday/mtestrequire github.com/go-redis/redis v6.14.2+incompatible 测试验证123$ go test ./...$ go test all 参考文献https://github.com/golang/go/wiki/Moduleshttps://semver.org/lang/zh-CN/https://go.googlesource.com/proposal/+/master/design/24301-versioned-go.md]]></content>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[体验最新的 Ubuntu 18.04 版本]]></title>
    <url>%2F2018%2F05%2F05%2F%E4%BD%93%E9%AA%8C%E6%9C%80%E6%96%B0%E7%9A%84-Ubuntu-18-04-%E7%89%88%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[作为一个忠实的 Ubuntu 用户，从 8.04 追随到如今，的确也算对 Ubuntu 有所偏爱了。每次系统的更新和升级总给我带来不一样的感受。不管是喜欢的，还是吐槽的，慢慢的体会到在 Linux 世界中，作为一款易用的，有美感的桌面系统实属不易，自认为在 Linux 纷繁复杂的世界中。 Ubuntu 一路的设计和改进，对 Linux 桌面系统普及使用，有着不小的贡献。18.04 作为 Ubuntu 下一个 LTS 版本，融合较大的改进，其中最突出的莫过于，从 Unity 切换到 GNOME 了。 为了能提前体验最新的 18.04 ，下面就简单的说说如何从现有的 16.04 升级到最新的 18.04。根据目前的 Ubuntu 升级策略，16.04 不能立即得到升级到 18.04 的通知，我自己实践中发现，需要先升级到 17.10，然后从 17.10 升级到 18.04https://wiki.ubuntu.com/BionicBeaver/ReleaseNotes 涉及到的主要操作就是，在软件更新管理器中，配置升级策略：立即通知，任何版本。然后按照上面的官方说明命令进行操作就可以了，接下来就是，喝上一杯茶，看看书，耐心的等待升级完成。 升级后的界面清爽了许多，如下： 其他参考： https://wiki.ubuntu.com/BionicBeaver/ReleaseSchedule https://itsfoss.com/ubuntu-18-04-release-features/ https://www.zdnet.com/article/how-to-upgrade-to-ubuntu-linux-18-04/]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊 GeoHash 算法的一些事]]></title>
    <url>%2F2018%2F04%2F21%2F%E8%81%8A%E8%81%8A%20GeoHash%20%E7%AE%97%E6%B3%95%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[一. LBS 的实际问题LBS 有一个经典的使用场景，就是查找当前位置附近的商家，车辆，或者交通站点。对于如何利用现有的技术来实现这个简单的需求，网上已经有成堆的资料可以查到，这里就不再赘述了，简单的说一下其中的一个关键的技术点 GeoHash 算法，仅此备忘。 传统的空间上的区域的数据都是二维以上的，比如经纬度，笛卡尔坐标等。存储的数据的形式通用的一般是关系型数据，和非关系型数据。 关系型数据在查询的支持的使用最多的就是依靠索引，B+树方式高效查询这点不用怀疑，但是如何针对二维数据有效的查询是心有余而力不足，那么如何解决二维数据的存储查询问题，就会有以下两种思路 使用一种特殊的索引结构实现对于空间数据的支持，这个就是所谓的空间索引 使用其他的非关系型数据，支持这些空间数据的存储，查询处理，所谓的 Redis，MongoDB 流派就是搞这个的。 不管1&gt; 还是 2&gt; ，他们其中用到的核心算法就是我们今天要讲的主角：GeoHash 二. GeoHash 算法GeoHash 是一种地理编码，实现对于二维经纬度数据转化为一维的字符串，也就是降维打法，有了一维的数据，就可以进行方便的查询处理了。 GeoHash 算法，具体如下： 对于经纬度的数据，进行二分比较后，进行编码其中纬度的总区间是 (-90, 90)经度的总区间是 (-180, 180) 划分后，就可以根据要求的精度大小，最终收敛到某个区间范围，从开始到这个区间就对应唯一的二进制编码（二分处理过程中，属于0 还是 1） 按照 Z 阶曲线（局部保序性），对经纬度的编码进行合并，奇数位是纬度，偶数位是经度，得到新的编码 然后对于得到的编码按照 Base32 进行编码 可以看到上述的这种区间的划分方式，最终就会分布成一个个矩形块，每个矩形块的编码是字符串，矩形块内部编码一致（如果精度不再进一步细分的前提下），不同矩形块的编码是不同的。我们很自然的会以为，附件的点一定是在某个矩形块（某个精度）中，其实不然，对于矩形块的边界区域，很可能存在两个点地理上很近，但是被划分在不同的矩形块中，所以，我们在查找附近的点的时候，势必要求我们还需要对当前矩形块周围的 8个矩形块同时搜索，减少附件点的遗漏。 关于 Z 阶曲线的数学特性和不同数据库空间索引的比较，可以查看后面的文献，加深理解。 参考： https://halfrost.com/go_spatial_search/https://charlee.li/geohash-intro.htmlhttps://cloud.tencent.com/developer/article/1012791]]></content>
      <tags>
        <tag>数据库开发技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无服务器 - Serverless 入门知识]]></title>
    <url>%2F2018%2F02%2F25%2F%E6%97%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%20-%20Serverless%20%E5%85%A5%E9%97%A8%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[Serverless 这个单词最早大约来源于Ken Form 的一篇文章中， 不过并不是今天我们要讨论的这个意思，如今的含义是无服务器，主要是指让开发人员专注于业务代码的本身逻辑上，无需关注代码部署的资源、维护、扩展性和高可用性，减少代码开发人员的业务无关的工作量，提高开发效率，具有无状态运行，基于事件触发，按需付费，运维完全托管到第三方等特点。 Serverless 面向的粒度主要是应用层面，更具体说是应用的函数层面，在 XaaS 里面，更偏向是 FaaS，但是仅仅 FaaS 也不全面，因为Serverless 的这种分发和使用方式，开发者更多的时候是使用第三方提供的 API 来封装调用集成服务，所以也包含了 BaaS （Backend as a Service）的范畴，其中 FaaS 是最突出的一个特点，一方面，函数级别的粒度，必然对于运行时间，计费方式有新的要求和设计，另外一方面，对于如何快速开发出符合平台规范的 FaaS ，以及跨平台的 FaaS 方法论上存在很多问题尚未很好的解决。 FaaS 目前在各大云厂商都有了相应的支持，支持的程度略微不同，主要包括，语音运行环境，开发调试工具，第三方云服务集成，触发方式 Serverless 作为一种新型的软件架构和概念，可以和几个有意思的概念相比较来说明： 微服务， 也是一种软件低耦合，分布式，模块化界限设计软件架构方式，微服务也是面向应用，不过更多的是从组件或者模块化的粒度来设计分析 Serverless， 如今更多的是面向 Function， 虽然 Function 粒度有大小区分，但是执行时间的粒度和生命周期方式和微服务有很多不同 PaaS， 作为面向应用的一个平台服务，更多的是对 IaaS 层面的封装和抽象，伴随着容器化的流行，私有 PaaS 和 公有 PaaS 都在不同的企业中有很多落地实践，PaaS 很多的设计依然没有做到完全透明，比如实例的数量，资源的需求，以及扩容的配置等。相比 FaaS ，透明性不高，控制能力稍强。 Serverless 这个概念开始火大约来源于 AWS 2014 年的发布的 Lambda，用户仅需对自身业务代码负责，运行即产生费用，无须关注机器资源，这样的计算抽象间接的引入一种新的应用发布形式， 注明：其他产商的 Serverless 功能都大体类似，这里仅仅以 lambda 为例 对于这种基于 Function 粒度新型的开发模式，势必一个值得研究的问题就是开发效率的问题，如何更加方便的开发，分发这些 function ，如何保证 function 的安全性，便是最近 AWS 官方发布的 Serverless Application Repository，每个案例都是一个可以部署试验的应用，这些应用程序都是采用 SAM 模板方式分发，保证了 Serveless 应用的可复制性和可分发性。因为 Function 粒度的问题，还有应用的可操作性，使用性，所以这个仓库中的范畴，从代码，组件到应用都包含，间接的可以理解为一个容器仓库，只不过容器仓库本身面向的是容器应用而已。 可以预见未来很长的时间， AWS 应该为着力把这个应用仓库完善起来，只有仓库丰富性增强，相应的 Serverless 生态才可能壮大，才会有更多应用落地，方便开发，降低学习 Serverless 的门槛。当然如何类似 Docker 仓库，实现基于 dockerfile 更简易的编程和继承方式也是值得研究的地方。 最后总结一下 Serverless 未来学习需要考虑的几个点： 语言平台支持维度开发调试工具支持标准互通，第三方厂商绑定，编程，维护性支持（编排）函数性仓库支撑可控延迟性，性能支撑迁移成本监控，诊断和已有的应用集成难度 参考资料：https://en.wikipedia.org/wiki/Serverless_computinghttp://serverless.ink/https://jimmysong.io/posts/what-is-serverless/https://amazonaws-china.com/cn/blogs/china/iaas-faas-serverless/https://amazonaws-china.com/cn/serverless/https://amazonaws-china.com/cn/lambda/https://amazonaws-china.com/cn/serverless/serverlessrepo/http://fastzhong.com/2018/01/30/serverless%20-%20intro/https://cloud.google.com/serverless/http://gitbook.cn/books/5a4b66e3f957ee33939ec3cf/index.htmlhttps://s3.cn-north-1.amazonaws.com.cn/videos-localize/%E5%BF%AB%E9%80%9F%E7%90%86%E8%A7%A3AWS+Lambda%EF%BC%8C%E8%BD%BB%E6%9D%BE%E6%9E%84%E5%BB%BAServerless%E5%90%8E%E5%8F%B0.pdf]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[故障分析平台 Sentry 的 LDAP 集成搭建]]></title>
    <url>%2F2017%2F12%2F21%2F%E6%95%85%E9%9A%9C%E5%88%86%E6%9E%90%E5%B9%B3%E5%8F%B0%20Sentry%20%E7%9A%84%20LDAP%20%E9%9B%86%E6%88%90%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[sentry 是一个支持软件系统故障信息报告和聚集的平台，可以扩平台的部署和管理故障信息，不同于传统的 ELK 日志分析平台，sentry 更加专注对于故障和异常类信息的处理，减少无关消息的干扰，实时的汇集和报告软件系统的潜在问题，帮助开发和管理人员迅速的解决问题。 sentry 本身提供了扩展点，方便第三方来实现相关的系统集成，以 LDAP 为例，sentry-ldap-auth 是一个 django 定制化实现，支持 LDAP， 具体的配置在 github 介绍中比较简陋，所以用户在配置中容易出现各类奇怪的问题，所以，今天我们以一个系统为例，说说 LDAP 相关的配置。 首先是 sentry 本身的安装，这个比较简单， 下载 https://github.com/getsentry/onpremise，然后进行 docker 镜像的构建，在构建之前，需要根据实际情况对 sentry.conf.py 进行配置，这里就涉及到 LDAP 插件的定制， 对 LDAP 相关的插件进行定制，以 https://github.com/Banno/getsentry-ldap-auth 为文档基础，按照我们的 LDAP 基础设施情况配置，例如： 1234567891011121314151617181920212223242526272829303132333435363738import ldapfrom django_auth_ldap.config import LDAPSearch, GroupOfUniqueNamesTypeAUTH_LDAP_SERVER_URI = 'xxxxx'AUTH_LDAP_BIND_DN = 'xxxxx'AUTH_LDAP_BIND_PASSWORD = 'xxxxx'OU=unicode('xxxxx', 'utf8')AUTH_LDAP_USER_SEARCH = LDAPSearch( OU, ldap.SCOPE_SUBTREE, '(sAMAccountName=%(user)s)',)AUTH_LDAP_GROUP_SEARCH = LDAPSearch( '', ldap.SCOPE_SUBTREE, '(objectClass=groupOfUniqueNames)')AUTH_LDAP_USER_ATTR_MAP = &#123; "username": 'xxxxx', "first_name": "xxxxx", "last_name": "xxxxx", "email": "xxxxx"&#125;AUTH_LDAP_GROUP_TYPE = GroupOfUniqueNamesType()AUTH_LDAP_REQUIRE_GROUP = NoneAUTH_LDAP_DENY_GROUP = NoneAUTH_LDAP_FIND_GROUP_PERMS = FalseAUTH_LDAP_CACHE_GROUPS = TrueAUTH_LDAP_GROUP_CACHE_TIMEOUT = 3600AUTH_LDAP_DEFAULT_SENTRY_ORGANIZATION = u'xxxxx'AUTH_LDAP_SENTRY_ORGANIZATION_ROLE_TYPE = 'member'AUTH_LDAP_SENTRY_ORGANIZATION_GLOBAL_ACCESS = TrueAUTHENTICATION_BACKENDS = ( 'sentry_ldap_auth.backend.SentryLdapBackend', 'django.contrib.auth.backends.ModelBackend',)AUTH_LDAP_DEFAULT_EMAIL_DOMAIN='xxxxx'SENTRY_EMAIL_BACKEND='dummy'SENTRY_BEACON = False 3.执行 make build 构建 docker 镜像 4.根据构建好的镜像进行安装 https://docs.sentry.io/server/installation/docker/，如下：（这里没有安装 email 相关的邮件传输服务） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354docker run \--detach \--name sentry-redis \redis:3.2-alpinedocker run \--detach \--name sentry-postgres \--env POSTGRES_PASSWORD=secret \--env POSTGRES_USER=sentry \postgres:9.5docker run \--rm sentry-onpremise \config generate-secret-keydocker run \--rm -it \--link sentry-redis:redis \--link sentry-postgres:postgres \--env SENTRY_SECRET_KEY=$&#123;SENTRY_SECRET_KEY&#125; \sentry-onpremise upgradedocker run \-it \--name sentry-web-01 \--link sentry-redis:redis \--link sentry-postgres:postgres \--env SENTRY_SECRET_KEY=$&#123;SENTRY_SECRET_KEY&#125; \--publish 9000:9000 \sentry-onpremise \run webdocker run \--detach \--name sentry-worker-01 \--link sentry-redis:redis \--link sentry-postgres:postgres \--env SENTRY_SECRET_KEY=$&#123;SENTRY_SECRET_KEY&#125; \sentry-onpremise \run workerdocker run \--detach \--name sentry-cron \--link sentry-redis:redis \--link sentry-postgres:postgres \--env SENTRY_SECRET_KEY=$&#123;SENTRY_SECRET_KEY&#125; \sentry-onpremise \run cron 5.验证访问 http://localhost:9000 然后使用 LDAP 账户访问就可以了 其他相关参考文献：http://thefourtheye.in/2013/04/20/installing-python-ldap-in-ubuntu/http://www.cnblogs.com/dreamer-fish/p/5474289.html]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tcpdump 调试 TCP 连接超时问题]]></title>
    <url>%2F2017%2F12%2F15%2Ftcpdump%20%E8%B0%83%E8%AF%95%20TCP%20%E8%BF%9E%E6%8E%A5%E8%B6%85%E6%97%B6%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题简单描述： 服务端负载均衡 4 层有超时配置，如果没有数据交互，那么 tcp 连接会断开。 为了支持可定制化配置，需要验证超时生效的问题，于是我做了一个简单的 Flask app 的镜像(启动在8083 端口, 120 秒返回结果），启动后，使用 curl http://ip:8083 发现， 过了超时时间后，服务端仍然完整了返回了结果。 调查：这种问题，一般用 tcpdump 跟踪一下就容易解决。 123456708:19:59.630162 IP myhost.24435 &gt; VIP.http: Flags [P.], seq 1:77, ack 1, win 58, length 7608:19:59.721043 IP VIP.http &gt; myhost.24435: Flags [.], ack 77, win 58, length 008:20:59.720669 IP myhost.24435 &gt; VIP.http: Flags [.], ack 1, win 58, length 008:20:59.811523 IP VIP.http &gt; myhost.24435: Flags [.], ack 77, win 58, length 008:21:59.819678 IP myhost.24435 &gt; VIP.http: Flags [.], ack 1, win 58, length 008:21:59.822046 IP VIP.http &gt; myhost.24435: Flags [P.], seq 1:18, ack 77, win 58, length 17 可以看到在 60 秒，myhost 发送了一个类似心跳的消息，这就是为什么超时后，连接仍然没有端口的原因了。 这个问题显然是 curl 程序本身的设置，查 curl 文档 https://curl.haxx.se/docs/manpage.html 发现 12345--keepalive-timeThis option sets the time a connection needs to remain idle before sending keepalive probes and the time between individual keepalive probes. It is currently effective on operating systems offering the TCP_KEEPIDLE and TCP_KEEPINTVL socket options (meaning Linux, recent AIX, HP-UX and more). This option has no effect if --no-keepalive is used.If this option is used several times, the last one will be used. If unspecified, the option defaults to 60 seconds. 原因找到了，我们再验证一下，是否是这个导致，验证如下： 设置一个小于 4层默认超时时间，但是大于 curl 本身的超时时间，这里设置 70s， curl -v –keepalive-time 70 -X GET http://ip:8083 tcpdump 如下： 12345678908:25:46.112532 IP myhost.31425 &gt; VIP.http: Flags [.], ack 1, win 58, length 008:25:46.112635 IP myhost.31425 &gt; VIP.http: Flags [P.], seq 1:77, ack 1, win 58, length 7608:25:46.204289 IP VIP.http &gt; myhost.31425: Flags [.], ack 77, win 58, length 008:26:56.267663 IP myhost.31425 &gt; VIP.http: Flags [.], ack 1, win 58, length 008:26:56.359620 IP VIP.http &gt; myhost.31425: Flags [.], ack 77, win 58, length 008:27:46.218753 IP VIP.http &gt; myhost.31425: Flags [P.], seq 1:18, ack 77, win 58, length 1708:27:46.218770 IP myhost.31425 &gt; VIP.http: Flags [.], ack 18, win 58, length 0 没有问题，70s 发送了心跳 设置一个大于 4 层超时时间的配置，但是小于服务端程序本身的响应时间，这里设置为 100 秒 curl -v –keepalive-time 100 -X GET http://ip:8083 tcpdump 如下： 1234508:48:44.235749 IP myhost.64757 &gt; VIP.http: Flags [.], ack 1, win 58, length 008:48:44.235823 IP myhost.64757 &gt; VIP.http: Flags [P.], seq 1:77, ack 1, win 58, length 7608:48:44.325588 IP VIP.http &gt; myhost.64757: Flags [.], ack 77, win 58, length 008:50:14.324860 IP VIP.http &gt; myhost.64757: Flags [R], seq 2189599717, win 0, length 0 收到了 Rest 包，没有问题 经过上面的分析，我们就明白了，验证问题本身，使用的测试程序不同，直接结果可能表现不一样，这需要我们深入到测试程序本身，搞明白其中相关的设置，避免不必要的误解。 最后，上面如果用 telnet 测试，就不会衍生出上面的这个问题了，因为 telnet 默认没有相关的心跳维护，自然不会出现 curl 上面的问题了。]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决 Nginx 502 Bad Gateway 问题]]></title>
    <url>%2F2017%2F11%2F29%2F%E8%A7%A3%E5%86%B3%20Nginx%20502%20Bad%20Gateway%20%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[今天访问镜像页面的时候发现时不时的出现 502 这个奇怪的错误，感觉是个值得研究的性能相关的问题，尤其是大量镜像访问的时候出现的频率加大，于是撸起袖子准备搞起。 环境： Nginx + gunicorn + Web App 解决思路： 既然是 Nginx 问题，先看 nginx error 日志，发现 Upstream prematurely closed connection while reading response header from upstream 网上这个问题一大堆，众说纷纭。其中一个主要的线索是 Nginx 和 gunicorn 之间的连接出了问题。 通过 tcpdump 看，确实是有 Fin 信号，那么查看 gunicorn 进程的日志 gunicorn 显示 WORKER TIMEOUT 退出，OK 线索进一步了，超时相关的问题。进一步看 gunicorn 文档，如果应用超过 30s， 仍然没有获得响应，自动退出。 验证，发现确实 30s，程序退出。 解决方法： 增大延迟，30s –》 60s 意外： 注意 60s 虽然减缓了 502 的问题，但是你会发现 504 的 Timeout 问题，这是 Nginx 和 gunicorn 之间的连接超过默认 60s，就会报错， nginx 里面的 proxy_read_timeout 可以配置这个参数。 当然最终问题，仍然还是后台的程序有性能瓶颈，这是后续的 Web App 自身的优化了。基本可以告一段落前面的调查结果了。至少不会出现 502， 504 这些相关的错误了。]]></content>
      <tags>
        <tag>架构设计与优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大话容器标准-OCI CNCF]]></title>
    <url>%2F2017%2F10%2F29%2F%E5%A4%A7%E8%AF%9D%E5%AE%B9%E5%99%A8%E6%A0%87%E5%87%86-OCI%20CNCF%2F</url>
    <content type="text"><![CDATA[这是以前写的文章，一直没有分享出来，一方面觉得业界还在不停的变化，另一方面还在忙别的事情，随着前些日子，docker 官方原生支持 Kubernetes 的部署，我觉得回过头来看看以前自己写的这篇文章还是很有意思的事情。 OCI 2015年6月建议，发起者主要是 docker 公司还有容器行业的其他的公司。最初主要是解决容器运行标准化的问题，后来扩展包括了对于容器镜像标准的问题的涵盖。 目前主要包含以下标准：http://www.github.com/opencontainers/runtime-spechttp://www.github.com/opencontainers/image-spec 主要的流程是，从镜像源下载 OCI 镜像，解压符合 OCI 运行时的文件系统 Bundle，然后由 OCI Runtime 运行（例如runc）不难看出，上面 OCI的使命主要是解决底层容器运行相关容器打包标准化和运行环境规范，实现容器镜像的跨云，平台的即插即用。 第一章. 群雄逐鹿 Containerddocker 公司官方实现的符合 OCI 运行规范的实现是 runc，并且捐赠给 OCI 组织。 对于 runc 这么底层的运行程序，显示对于更高一级管理（host级别，或者cluster 级别）是需要一定程度的抽象和封装，为此就有了所谓的 containerd和随着一套的工具集合，这些也是目前 docker 版本中被集成和实现了，具体的工具交互流程图如下： 具体的内部架构图如下： 用户或者外部系统通过 API ，来跟子系统进行交互，包括，镜像相关（distribution 拉取镜像，Bundle 提取和打包镜像），容器相关（bundle 的执行，来进行容器的创建运行）对应下面的组件，包括：Executor（容器运行时的实现），Supervisor（容器状态的监控和上报），Metadata（镜像和bundle持久化引用的存储，存储到graph db中），Content（镜像RO部分），Snapshot（graphdriver 部分，对于容器镜像部分的管理），Events（事件支持），Metrics（指标）。 程序内部流程图： Rkt Rkt 和 Docker 走的架构有些不同，走的是 daemon less，以pod为基础单位，下面的是 rkt 的一个架构图： stage0: 根据不同的触发方式，调用 rkt， 然后获取 ACL 镜像，生成 pod 相关的元数据，创建相关的文件系统，解压镜像到相关的目录。stage1: 根据stage0产生的镜像和pod元数据，创建相应的隔离环境，（支持的flavor 有： fly,systemd,kvm）stage2: 在 stage1的隔离环境中，调用对应的app 可执行程序 相比 docker，这个本身不存在单点故障，rkt 本是主要接口是一个命令行工具，不需要类似 docker dameon 或者 containerd 类似的支撑。不过 docker 从原来的 docker daemon 重构迁移到模块化结构的 containerd 方案后，通过 live-restore 是可以实现 docker daemonless 的container，重启 docker daemon ，容器仍然保持运行。 参看 coreos 网站给了一个 关于 rkt vs docker 比较，其实这两个现在不适合直接比较了，更应该是比较 rkt 和 containerd 之间的比较。 不论是 containerd 和 rkt，都在其中对于 OCI 的支持列入到了自身的 Roadmap 中，具体分别是：https://github.com/containerd/containerd/blob/master/ROADMAP.mdhttps://github.com/rkt/rkt/blob/master/ROADMAP.md 值得一提的是，关于 rkt 是 CoreOS 主导的，CoreOS 公司有些融资是来自于谷歌风投的。（想想rkt 现在努力支持k8s CRI， k8s 中使用的 etcd，天生的pod 适配，等待..） CNCF 容器本身的特点，极大的促使新型的应用转交和发布，服务的动态关联和发现。一些互联网企业开始从传统的单体架构转向微服务架构，依次衍生出对于云原生应用的需求和技术，CNCF 就是在这种背景下产生，主要是目标是提供可使用的软件栈满足以下需求：提供服务容器化、动态编排、面向微服务的。 说道这个 CNCF 就不得不说 google 和 kubernetes，这个基金会成立之初也是google 为了推广 kubernetes 生态的发展，kubernetes 作为容器管理系统，是一个面向企业级的偏重的全能型实现方案，几乎所有的容器服务的场景和融合方案（网络，存储，编排，AutoScale 等）都会涵盖。 CNCF 基金会以面向可用系统级别为出发点，吸纳了其他衍生项目的加入，包括但不限于： CNCF 的摊子铺的可算比较大， 除了 SDN， SDS， IaaS， OS， Container Runtime 之外。上面的部分，还有接口的支持和集成，都包括在内。 第二章 部落联盟 关于 OCI 和 CNCF 还有一个比较有趣的双方协定， OCI 中，说How does OCI integrate with CNCF?A container runtime is just one component of the cloud native technical architecture but the container runtime itself is out of initial scope of CNCF (as a CNCF project), see the charter Schedule A for more information. CNCF 这样说For further discussionThe following are considered out of scope for now, but might need to be included later. * Application environment. Crafting a well formed, minimal userland environment for cloud native applications. * OCI topics (container format and runtime). The goal is to integrate with the OCI group. 虽然这里看到还是有井水河水之分，但是依据微妙的声明，可以看到还是会有融合的可能。CNCF 的影响力不断增大，docker 官方也打算并且提交将containerd 捐献给CNCF， CoreOS 也是同样提交了 rkt 给 CNCF，希望将容器运行核心项目交由 CNCF 基金会维护，更加发展壮大。这可谓树大好乘凉。 那我们看看containerd 和 rkt 在 未来的云原生系统中占据什么位置，如下： 显然，无论是 docker 还是 rkt 都希望自身在未来的容器生态系统占据核心重要一环。而且未来，docker 不满足 containerd 只是简单的容器运行和进程管理，他希望可以扩充更多的，涵盖distribution，storage，和networking，下面两张图对比来看： 第三章 联盟求同存异 CNCF 在 Berblin KubeCon 上宣布同时接受了 containerd and rkt 这两个 runtime 项目 作为 CNCF 孵化项目https://thenewstack.io/separate-votes-cncf-adopts-dockers-containerd-coreos-rkt/ 所以 CNCF 官方网站上就有了以下的有趣的成员图： 第四章 生态之争 每年的DockerCon 都会不甘寂寞，放出一些很酷的 feature 和声明，这次 DockerCon 2017 也不例外， Docker 公司做出来两个重要的宣布 Docker 开源社区单独命名： Docker 成为公司商业产品的代名词，开源社区的运营以 Moby 为代名词，Moby 代表社区的围绕容器系统生态相关的各个组件，框架项目统称，基于这些开源化的组件，不同的系统集成或者公司都可以开发自身的容器管理集成系统，当然也包括 Docker 公司自己。Docker 公司本身的很多产品（比如Docker DataCenter）是基于这些组件搭建的，同时包含了一些特别的高级功能，这样 Docker 名字命名的改变，应该是公司自身一来明确的产品界限，二来希望基于自身的技术的开源生态系统更加更加丰富（看看人家 kubernetes 生态系统搞得大不大），这也是一场不确定的生态系统战争，双方胜负未定，至少对方都希望不要输的太早。 参考资料： https://www.opencontainers.org/ https://github.com/docker/containerd/blob/master/design/architecture.md https://coreos.com/rkt/docs/latest/devel/architecture.html https://coreos.com/rkt/docs/latest/rkt-vs-other-projects.html#rkt-vs-runc https://www.cncf.io/about/charter/ https://www.opencontainers.org/faq https://containerd.io/ https://blog.docker.com/2017/03/docker-donates-containerd-to-cncf/ https://coreos.com/blog/rkt-container-runtime-to-the-cncf.html http://events.linuxfoundation.org/sites/events/files/slides/(OSF_Mr.%20Chris%20Aniszczyk)CNCF%20(OS%20Forum%20Japan%202016).pdf https://github.com/moby/moby/pull/24970]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[相同的 pip 命令 --trusted-host 错误消息不一致]]></title>
    <url>%2F2017%2F10%2F25%2F%E7%9B%B8%E5%90%8C%E7%9A%84%20pip%20%E5%91%BD%E4%BB%A4%20--trusted-host%20%E9%94%99%E8%AF%AF%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%80%E8%87%B4%2F</url>
    <content type="text"><![CDATA[问题：最近部署系统的时候，发现 ansible 执行同样的 pip 安装命令，结果不一样，一台正常，一台报错 –trusted-host 没有设置。 原因：简单的调查发现，其中的 pip 版本不一致，一个没有涉及到 –trusted-host， 另外的新版的 pip 支持了 –trusted-host 修复：简单的方法是，将其中支持 –trusted-host 配置到 pip.conf 文件中]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes 的 CRI-O 1.0 版本发布]]></title>
    <url>%2F2017%2F10%2F18%2FKubernetes%20%E7%9A%84%20CRI-O%201.0%20%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83%2F</url>
    <content type="text"><![CDATA[CRI-O 的源头： Kubernetes 作为编排领域的巨头，一直也是在标准化兼容的路上一路前行，为了支持多种的容器运行时系统（Docker, Rkt) 等，减少集成维护的成本，开发了自身的 CRI 接口规范，由于事实上的 OCI 已经被多方厂商认可，所以 CRI 和 OCI 的桥接也是自然的事情，CRI-O 这个项目来源也就是如此。 CRI-O 的内部窥探：（下面的图片来源于 https://www.redhat.com/en/blog/introducing-cri-o-10） CRI-O 项目也特别声明了自身的定位： 只是用于 Kubernetes 用来管理和运行 OCI 标准兼容的容器，也不是面向开发人员的，或者用来打包镜像的。 差不多另外一天， docker 官方也公布了自身的对于 kubernetes 的编排的原生支持，Docker 社区版和企业版都可以使用 docker 官方的类似 compose 工具来部署维护 Kubernetes 的pods 和 services 等。 参考文献： https://blog.docker.com/2017/10/kubernetes-docker-platform-and-moby-project/ https://www.redhat.com/en/blog/introducing-cri-o-10]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 相同的 url 下载行为不一致调查 （Tornado）]]></title>
    <url>%2F2017%2F08%2F24%2Fpython%20%E7%9B%B8%E5%90%8C%E7%9A%84%20url%20%E4%B8%8B%E8%BD%BD%E8%A1%8C%E4%B8%BA%E4%B8%8D%E4%B8%80%E8%87%B4%E8%B0%83%E6%9F%A5%20%EF%BC%88Tornado%EF%BC%89%2F</url>
    <content type="text"><![CDATA[前几天遇到一个神奇的问题，同样的一个 url，在浏览器访问这些远端的机器时，会出现不同的行为：直接下载或是打开。为什么行为不一致呢？ 很奇怪。 没有很好的办法，只能从 debug 浏览器的 request 请求开始，发现一台机器是 application/octet-strea，另外一台是 text/plain同样的 url 在不同的机器上有这个奇怪的表现，不多说了，肯定是 tornado web 中的一些代码逻辑导致的，于是决定翻源码。https://github.com/python/cpython/blob/master/Lib/mimetypes.pyhttps://github.com/tornadoweb/tornado/blob/branch4.3/tornado/web.py 定位到决定 content 内容的源码如下：点击(此处)折叠或打开 12345678910111213def get_content_type(self): """Returns the ``Content-Type`` header to be used for this request. .. versionadded:: 3.1 """ mime_type, encoding = mimetypes.guess_type(self.absolute_path) # per RFC 6713, use the appropriate type for a gzip compressed file mimetypes.py 中会根据不同的文件扩展类型来推测 mime_type ，一台机器是 application/octet-strea，另外一台是 text/plain这就奇怪了，同样的操作系统和 tornadoweb 版本 再细看 mimetypes.py 源码发现，里面有一些蹊跷 123456789101112131415161718192021knownfiles = ["/etc/mime.types","/etc/httpd/mime.types", # Mac OS X"/etc/httpd/conf/mime.types", # Apache"/etc/apache/mime.types", # Apache 1"/etc/apache2/mime.types", # Apache 2"/usr/local/etc/httpd/conf/mime.types","/usr/local/lib/netscape/mime.types","/usr/local/etc/httpd/conf/mime.types", # Apache 1.2"/usr/local/etc/mime.types", # Apache 1.3] 其中 /etc/mime.types 一台机器上没有，另外一台包含， 这个文件中包含了 .log 结尾的文件情况，那么看看是哪个包导致的不同： 12# rpm -q --whatprovides /etc/mime.typesmailcap-xxx-.el7.noarch 后来确认才知道，一台机器当时使用的最小化安装，所以遗漏了一些后期的标准化安装的包。这个差别才导致了行为的差异。]]></content>
      <tags>
        <tag>Web开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 的性能分析利器——Django 篇]]></title>
    <url>%2F2017%2F08%2F23%2FPython%20%E7%9A%84%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%88%A9%E5%99%A8%E2%80%94%E2%80%94Django%20%E7%AF%87%2F</url>
    <content type="text"><![CDATA[1） django debug_toolbar 这个插件可以使用，按照官方文档配置，https://django-debug-toolbar.readthedocs.io/en/stable/installation.html但是最主要的一点是需要配置 INTERNAL_IPS ，对于这个是需要特别注意的，假设你是使用远程调试，这个时候需要把你的客户端的 ip 加入进去，这样启动的时候，就能看到 debug panel 了，否则就会不能显示出来，这个问题也是困扰我了半天，推荐一般 debug panel 不能正常显示的时候，查看这个是否正确设置。 特点，jazzband 开发， 可以看到相应页面的 sql query 数量 和 相应的时间，还有浏览器渲染等。 2）silk 也是 jazzband 开发，针对 django，配置更加简单，除了包含上面的一些统计数据，同时可以针对某块代码，进行 profiling。 3）python 自身标准库的profiler 支持，统计的数据，可以使用 pstats 模块进行格式化输出 3.1 cprofile： 基于 lsprof 模块， 以 C 扩展的方式实现，相对开销较小，可以针对对应的代码进行 profile3.2 profile： python 的实现，接口和 cprofile 一致，开销较大，不过第三方开发基于此较容易 3.1 和 3.2 分别有接口 enable disable 对某块代码进行 profile，设置对应的是否对 built-in 进行 profile 以 cprofile 为例，输出的内容每列信息如下： ncalls — for the number of calls,tottime — for the total time spent in the given function (and excluding time made in calls to sub-functions)percall — is the quotient of tottime divided by ncallscumtime — is the cumulative time spent in this and all subfunctions (from invocation till exit). This figure is accurate even for recursive functions.percall — is the quotient of cumtime divided by primitive callsfilename:lineno(function) — provides the respective data of each function 类似如下图： 相对的统计信息比较繁多，包含了很多 built-in 3.3 hotshot： (不再维护的）的方式， 进行代码级别的profile， 类似 https://code.djangoproject.com/wiki/ProfilingDjango 示例1]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scrapy 爬取 Blog 网页内容到 MD 文件]]></title>
    <url>%2F2017%2F08%2F04%2FScrapy%20%E7%88%AC%E5%8F%96%20Blog%20%E7%BD%91%E9%A1%B5%E5%86%85%E5%AE%B9%E5%88%B0%20MD%20%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[传统的 Blog 网站，没有提供完善的 md 格式支持，所以书写的 Blog 文件往往不具有 export 其他格式的功能。以我自己的 Blog 为例，这里书写的都是按照网站的 Blog 样式进行转化都是 html 页面，如果要转化对应的 md 格式，需要提取相应的标题，文本主体和其他相应的格式处理。 目标清楚了，我们首先想到的是使用爬虫工具来快速的处理的这个事情，下面 scrapy 就隆重登场了。 scrapy 作为一个开源实现的基于 python 爬虫框架，它内部的架构图具体如下： 主要包括： 爬虫引擎、调度器、下载器、具体爬虫、Item 流水线、下载器中间件和爬虫中间件具体作用分别如下： 引擎：控制中枢，系统核心数据流的具体流动，并且相应动作发生时触发事件调度器：接受引擎的request 输入，队列处理，再需要时提供给引擎下载器：获取实际的web 页面，并返回给引擎，最终到具体的爬虫爬虫：根据获取的页面，进行实际的解析处理，提取 itemItem 流水线：处理爬虫获取的 item，比如清理，验证和持久化下载器中间件：下载器和引擎之间的中介，处理下载器返回给引擎的 response爬虫中间件：处理爬虫的输入（response），和输出（items，requests） 下面我们一个实际的例子来说明如何使用：创建项目非常简单，类似 django 封装的效果。 1scrapy startproject tutorial 项目创建完成后，就是具体的爬虫的编写了，以我的博客首页为例： http://blog.chinaunix.net/uid/21335514/ 我们需要根据上述的 URL 依次按照 年份 –》 标题 –》 内容就行爬取，存储使用简单的 json 文件格式，根据存储的 json 文件格式，就行简化的 md 格式转换。 12345678910111213141516171819202122232425class UnixBlogSpider(scrapy.Spider): name = 'unixblogtaker' start_urls = ['http://blog.chinaunix.net/uid/21335514'] def parse(self, response): for year in response.css('p.Blog_p4 &gt; span'): if year.css('.Blog_jia1') is None: continue blog_page = year.css('span + a::attr(href)').extract_first() if blog_page: yield response.follow(blog_page, callback=self.parse_title) def parse_title(self, response): for blog_summary in response.css('div.Blog_tit4 &gt; b'): if blog_summary.css('.Blog_b1') is None: continue b_content = blog_summary.css('b + a::attr(href)').extract_first() if b_content: yield response.follow(b_content, callback=self.parse_content) next_page = response.css('li.next a::attr(href)').extract_first() if next_page is not None: yield response.follow(next_page, self.parse_title) def parse_content(self, response): ...... parse_content 这里处理的时候，可能需要根据一些特殊的字符含义进行相应的转化，以为后续的 md 简化转化提供便利。 运行 scrapy crawl unixblogtaker -o blog.json 就生成了我们的 json 文件 简单的处理上述的 content，（simplemr_tool.py 中的一部分） 123def raw_save(content, title): with open(title, 'w') as new_file: new_file.write(re.sub('(\r\n\r\n)+', '\r\n\r\n', content).encode('utf-8')) 然后执行 python simplemr_tool.py blog.json 就会生成一系列的 md 博客了。 参考：https://doc.scrapy.org/en/latest/intro/tutorial.html#creating-a-projecthttp://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/architecture.html]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ChatterBot 智能机器人玩起来]]></title>
    <url>%2F2017%2F07%2F23%2FChatterBot%20%E6%99%BA%E8%83%BD%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%8E%A9%E8%B5%B7%E6%9D%A5%2F</url>
    <content type="text"><![CDATA[机器学习作为一门技术已经被应用到很多场景中，从个性化推荐到智能数据商业分析等，举不胜举，今天我们看一个简单的小例子，智能会话机器人、 所需技术： gunicorn，nginx，mongodb，mysql ChatterBot 是一个支持多种语言的机器人，通过基于历史会话进行机器学习，从而可以产生自动应答的效果。具体原理图如下： 官方已经有一个 django 的应用例子，不过默认是使用的 sqlite db改动： 我们使用了 mongodb，然后 django 应用对应的配置了 mysql，使用gunicorn （HTTP server）和 nginx （proxy server）， 具体如下： 下载 django_app https://github.com/gunthercox/ChatterBot/tree/master/examples/django_app 配置 mysql db 配置 mysql： 123sudo apt-get updatesudo apt-get install mysql-serversudo mysql_secure_installation 1234567CREATE DATABASE chattraindb CHARACTER SET UTF8;CREATE USER aiuser@localhost IDENTIFIED BY 'password';GRANT ALL PRIVILEGES ON chattraindb .* TO aiuser@localhost;FLUSH PRIVILEGES; 123sudo apt-get install python-mysqldbpython manage.py migrate 安装 mongdb (略，参考官方文档 4） 修改 chatterbot 配置 12345678910CHATTERBOT = &#123; 'name': 'Django ChatterBot Example', 'trainer': 'chatterbot.trainers.ChatterBotCorpusTrainer', 'training_data': [ 'chatterbot.corpus.english' ], 'storage_adapter': 'chatterbot.storage.MongoDatabaseAdapter', 'database': 'train-sample', 'django_app_name': 'django_chatterbot'&#125; 安装 gunicorn，nginx 12sudo pip install gunicornsudo apt-get install nginx 然后进行systemd 配置 12345678910111213141516171819$ cat /etc/systemd/system/gunicorn.service[Unit]Description=gunicorn daemonAfter=network.target[Service]PIDFile=/run/gunicorn/pidUser=kennanGroup=kennanRuntimeDirectory=gunicornWorkingDirectory=/home/kennan/workRepo/ChatterBot/examples/django_appExecStart=/usr/local/bin/gunicorn --pid /run/gunicorn/pid \ --bind unix:/run/gunicorn/socket example_app.wsgiExecReload=/bin/kill -s HUP $MAINPIDExecStop=/bin/kill -s TERM $MAINPIDPrivateTmp=true[Install]WantedBy=multi-user.target nginx 配置如下: 12345678910111213 server &#123; listen 80; server_name kennan-box; location /static/ &#123; root /home/kennan/workRepo/ChatterBot/examples/django_app/example_app; &#125; location / &#123; proxy_pass http://unix:/run/gunicorn/socket; &#125; &#125; &#125; 为了访问 80 端口，不会默认到 nginx 欢迎页面，需要删除默认配置 1sudo rm -rf /etc/nginx/sites-enabled/default nginx 生效，就能访问了， 效果如下：]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linuxkit 在 OpenStack Ocota 版本的实验]]></title>
    <url>%2F2017%2F06%2F22%2FLinuxkit%20%E5%9C%A8%20OpenStack%20Ocota%20%E7%89%88%E6%9C%AC%E7%9A%84%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[测试环境 CentOS 7.3 需要说明关于 Devstack 部分，不同的 OS 除了本身 Devstack 默认安装基本步骤一样，还有不同的额外步骤，有的不需要（比如下面的一些防火墙的规则，可能 Ubuntu 默认安装的就不需要） 说一下这个实验的思路，就是 Linuxkit 本身是可以 build VM 镜像的，而 OpenStack 本身又是一款包含有虚拟化管理功能的软件，那么我们希望试试 LinuxKit 自身build的镜像是不是可以很好的运行在 OpenStack 这个平台上。具体步骤如下： 搭建 OpenStack 环境方法1： 使用 Devstack优点，简单，快速，定位解决问题方便缺点，有些自定义的配置比较多，可以参考 Devstack 详细解释文档，一般不需要 方法2： 使用 RDO （因为是 CentOS 环境）优点：基本不需要自定义话配置缺点：使用 RDO 前置条件较多，除了配置源之外，还需要对防火墙等做一些处理。因为集成了 puppet， 所以不熟悉 puppet的话，出了问题，定位解决不方便。网上资料虽多，但是还是不如 DevStack 最初尝试了 RDO，试了几次均不成功，发现除了一些模块相关的问题（我拿到手的这台 CentOS 机器也是被做了一些自定义配置，有些不知名的问题，比如 ipv4 iptables 中 filter 规则不识别，ipv6 模块加载不正常等），还最会报错 sql connection 配置没有。 因为我们今天的重点不是研究怎么部署 OpenStack, 所以就没功夫调试 RDO 了，投入了 DevStack 的怀抱 DevStack 老方法，文档也介绍的很详细，不再累赘了，请参考文献【1】 说几个在 DevStack 中没有提到的，就是最新版的devstack 在 CentOS 安装后，需要开启对应的 80， 443 端口，要不然你在其他机器上无法访问 Horizon Dashboard， 具体就是参考文献【2】 /etc/sysconfig/iptables 加入下面的两条规则，然后重启 iptables 服务 12-A INPUT -p tcp -m multiport --dports 443 -j ACCEPT-A INPUT -p tcp -m multiport --dports 80 -j ACCEPT 搭建完 DevStack 基本就完了，如果还有其他的需要的话（比如通过虚拟机ping 主机 IP），你可能在 tcpdump 发现有admin prohibited 日志，那么就需要参考文献【4】进行防火墙规则的更新。 部署 DevStack 后，简单的部署一个 Cirros 镜像，然后测试 private ip 连通性，分配一个 floating ip，测试联通性（假设你添加的securitygroups 中包含了对相应协议端口的开放，比如 ICMP，DNS 等） 下面开始导入 Linuxkit 镜像，这里以 sshd 镜像为例，具体怎么 Build， 在我的博客中文献【5】也做了介绍 上传 sshd qcow2 镜像 （当然可以使用 kernel+inittrd ramdisk 方式） 到 OpenStack Glance， 这里简化通过 dashboard 操作，不用命令行，如下图所示： 部署镜像，关联 float ip （上面的图中的ip 172.24.4.5） 验证测试效果, 如下图所示： 123456789101112[root@mytestpc ~]# ssh 172.24.4.5Welcome to LinuxKitmoby:~# whoamirootmoby:~# lsmoby:~# ps -ef | grep ssh 317 root 0:00 ctr run --runtime-config /containers/services/sshd/config.json --rootfs /containers/services/sshd/rootfs --id sshd 427 root 0:00 /sbin/tini /usr/bin/ssh.sh 524 root 0:00 /usr/sbin/sshd -D -e 548 root 0:00 sshd: root@pts/0 554 root 0:00 grep sshmoby:~# 当然我们也可以测试 linuxkit 中 redis 镜像，如下 验证如下： 1234567891011121314[root@mytestpc ~]# redis-cli -h 172.24.4.3172.24.4.3:6379&gt; helpredis-cli 3.2.8To get help about Redis commands type: "help @" to get a list of commands in "help " for help on "help " to get a list of possible help topics "quit" to exitTo set redis-cli perferences: ":set hints" enable online hints ":set nohints" disable online hintsSet your preferences in ~/.redisclirc172.24.4.3:6379&gt; 参考： https://docs.openstack.org/developer/devstack/ https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux_OpenStack_Platform/2/html/Getting_Started_Guide/chap-Deploying_The_Dashboard.html http://linuxwiki.github.io/NetTools/tcpdump.html http://blog.chinaunix.net/uid-21335514-id-5403664.html http://blog.chinaunix.net/uid-21335514-id-5765203.html]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django Migration 的 Cannot add foreign key constraint 问题解决]]></title>
    <url>%2F2017%2F06%2F14%2FDjango%20Migration%20%E7%9A%84%20Cannot%20add%20foreign%20key%20constraint%20%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[最近在 Django 项目执行 Migration 的时候发现一个奇怪的报错： 12345678910111213File "/usr/lib64/python2.7/site-packages/django/db/backends/mysql/base.py", line 124, in executereturn self.cursor.execute(query, args)File "/usr/lib64/python2.7/site-packages/MySQLdb/cursors.py", line 205, in executeself.errorhandler(self, exc, value)File "/usr/lib64/python2.7/site-packages/MySQLdb/connections.py", line 36, in defaulterrorhandlerraise errorclass, errorvaluedjango.db.utils.IntegrityError: (1215, 'Cannot add foreign key constraint') 在新数据库 CI Migration 测试中是没有发现这类问题的，后来 Google 发现有类似的问题和分析 [1]，于是整理一下，以备其他人参考这是因为老系统原来的表使用的是 MyISAM 引擎，但是现在 MySQL 新版本默认的表都是 InnoDB 了，而 MyISAM 是不支持外键约束的。MyISAM 在 MySQL 5.5.1 之前是默认的引擎InnoDB 在 MySQL 5.5 之后是默认的引擎 所以如果你的老的表是 MyISAM，而新表对此有外键引入， 那么自然会报上面的错误了。 解决方法也很简单：（修改旧表引擎为 InnoDB），具体如下： 1ALTER TABLE ENGINE = InnoDB; 如何查看表的信息： 查看所有表的信息 1SHOW TABLE STATUS FROM `DB_NAME`; 查看某个表的信息 1SHOW TABLE STATUS FROM `DB_NAME` LIKE 'TABLE_NAME'; 参考资料： https://stackoverflow.com/questions/6178816/django-cannot-add-or-update-a-child-row-a-foreign-key-constraint-fails https://stackoverflow.com/questions/12614541/whats-the-difference-between-myisam-and-innodb https://stackoverflow.com/questions/4515490/how-do-i-know-if-a-mysql-table-is-using-myisam-or-innodb-engine https://dev.mysql.com/doc/refman/5.6/en/storage-engine-setting.html https://github.com/divio/django-filer/issues/939]]></content>
      <tags>
        <tag>Mysql/postgreSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linuxkit 源码分析，从开始到镜像构建完成]]></title>
    <url>%2F2017%2F06%2F08%2FLinuxkit%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%8C%E4%BB%8E%E5%BC%80%E5%A7%8B%E5%88%B0%E9%95%9C%E5%83%8F%E6%9E%84%E5%BB%BA%E5%AE%8C%E6%88%90%2F</url>
    <content type="text"><![CDATA[在上一篇【1】中我们介绍了 “Linuxkit 中的 kernel+initrd 镜像启动过程”，那么我们接下来看看 Linuxkit 是如何一步一步构造出 kernel +initrd 这些镜像的。 首先看一下 Moby 结构体定义，基本和 yml 中支持的属性一一对应 12345678910111213141516171819202123 // Moby is the type of a Moby config file 24 type Moby struct &#123; 25 Kernel struct &#123; 26 Image string 27 Cmdline string 28 &#125; 29 Init []string 30 Onboot []MobyImage 31 Services []MobyImage 32 Trust TrustConfig 33 Files []struct &#123; 34 Path string 35 Directory bool 36 Symlink string 37 Contents string 38 &#125; 39 Outputs []struct &#123; 40 Format string 41 &#125; 42 &#125; 43 NewConfig（parse yml config 文件） –&gt; buildInternal (实际的 build 过程) –&gt; outputs （生成相应格式的镜像） 其中 buildInternal 的过程如下 1--&gt; dockerPull --&gt; ImageExtract --&gt; untarKernel 下载 Kernel 对应的 image，从对应的镜像中提取文件系统并返回一个 tar，从 tar 中提取出 kernel 、 kernel.tar 并放到新的 tar 文件中（initrdAppend 操作），tar 文件为了区分 kernel 和 其他文件，对 kernel 设置了 tar header 字段（boot/kernel boot/cmdline） 对于 Init 镜像都要解压，并且添加到上面新的tar 文件中（initrdAppend） 对于 Onboot 镜像，执行以下操作：ConfigToOCI(image) ， –&gt; ImageBundle（对应目录为/containers/onboot/） –&gt; 同样添加到文件中 （initrdAppend） 对于 service 镜像，执行以下操作： ConfigToOCI(image) –》 ImageBundle（对应目录为 /containers/services/） –&gt; 同样添加到文件中 （initrdAppend ) 最后是添加一些额外的文件，程序需要的，比如 ssh key 文件（initrdAppend） –&gt; outputs按照 yml 中的输出格式，输出对应的文件，这里以 kernel+initrd 举例输出对应的 kernel + initrd 文件，其中 kernel 和 initrd 是在前面的 tar 包装的时候，都有设置了对应的 tar header，所以可以从一个文件中抽取出 kernel，剩下的就是 initrd 文件 对于其他虚拟机镜像格式，其实就是讲对应的 kernel + initrd 打包成对应的镜像格式比如 qcow2 那么对于上述构造的 VM 镜像，里面的容器如何自动运行起来的。那么我们就需要理解前面讲的 kernel +initrd 的启动过程，在 BIOS 自检后，bootloder 开始加载 kernel +initramfs， 那么我们从下面将这里如何对应到 moby 构建的镜像里面的代码 initrd 上面除了包含一些 modules， 还包含 init， onboot， services 镜像，其中 kernel+ initrd 配合完成对应的真正 root 挂载后，控制权交给了/sbin/init init 进程，开始根据 /etc/inittab 中进行进程的派生，看卡 inittab 什么样子 1234567891011121314151617181920/ # cat /etc/inittab# /etc/inittab::sysinit:/etc/init.d/rcS::once:/etc/init.d/containerd::once:/etc/init.d/containers# Stuff to do for the 3-finger salute::ctrlaltdel:/sbin/reboot# Stuff to do before rebooting::shutdown:/usr/sbin/killall5 -15::shutdown:/bin/sleep 5::shutdown:/usr/sbin/killall5 -9::shutdown:/bin/echo "Unmounting filesystems"::shutdown:/bin/umount -a -rttyS0::once:cat /etc/issuettyS0::respawn:/sbin/getty -n -l /bin/sh -L 115200 ttyS0 vt100tty0::once:cat /etc/issuetty0::respawn:/sbin/getty -n -l /bin/sh 38400 tty0 我们看到了熟悉的 /etc/init.d/containerd 和 /etc/init.d/containers，其中 containerd 是容器运行控制进程，首先启动。接着对于所有的containers 进行 roofs 的挂载，runc 调用运行这些容器，代码如下： 123456789101112131415161718192021222324252627282930313233/ # cat /etc/init.d/containers#!/bin/sh# start onboot containers, run to completionif [ -d /containers/onboot ]then for f in $(find /containers/onboot -mindepth 1 -maxdepth 1 | sort) do base="$(basename $f)" /bin/mount --bind "$f/rootfs" "$f/rootfs" mount -o remount,rw "$f/rootfs" /usr/bin/runc run --bundle "$f" "$(basename $f)" printf " - $base\n" donefi# start service containersif [ -d /containers/services ]then for f in $(find /containers/services -mindepth 1 -maxdepth 1 | sort) do base="$(basename $f)" /bin/mount --bind "$f/rootfs" "$f/rootfs" mount -o remount,rw "$f/rootfs" log="/var/log/$base.log" ctr run --runtime-config "$f/config.json" --rootfs "$f/rootfs" --id "$(basename $f)" $log &gt;$log &amp; printf " - $base\n" donefiwait 通过mount 查看里面的挂载情况： 12345678910tmpfs on /var type tmpfs (rw,nosuid,nodev,noexec,relatime)tmpfs on /containers/onboot/000-sysctl/rootfs type tmpfs (rw,relatime)tmpfs on /containers/onboot/001-sysfs/rootfs type tmpfs (rw,relatime)tmpfs on /containers/onboot/002-binfmt/rootfs type tmpfs (rw,relatime)tmpfs on /containers/onboot/003-format/rootfs type tmpfs (rw,relatime)tmpfs on /containers/onboot/004-mount/rootfs type tmpfs (rw,relatime)tmpfs on /containers/services/dhcpcd/rootfs type tmpfs (rw,relatime)tmpfs on /containers/services/docker/rootfs type tmpfs (rw,relatime)tmpfs on /containers/services/ntpd/rootfs type tmpfs (rw,relatime)tmpfs on /containers/services/rngd/rootfs type tmpfs (rw,relatime) 如此，就完成了 VM 启动后的容器的自动运行 参考： http://blog.chinaunix.net/uid-21335514-id-5765657.html https://en.wikipedia.org/wiki/Tar_(computing)]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linuxkit 中的 kernel+initrd 镜像启动过程]]></title>
    <url>%2F2017%2F05%2F31%2FLinuxkit%20%E4%B8%AD%E7%9A%84%20kernel%2Binitrd%20%E9%95%9C%E5%83%8F%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Linuxkit 中有一种镜像输出方式是 kernel+initird，以这类镜像为例，我们就来谈谈一个可运行的操作系统启动过程“发展史”： 开机，主板上电 CPU Reset，寄存器初始化，根据 CS、IP 寄存器（FFFF0h） 运行第一条指令地址，由于处于内存高位地址，所以一般是一个简单的跳转指令（JMP），找到对应的BIOS 程序 启动 BIOS 进行 POST 自检 （内存等硬件自检），然后 BIOS 会查找可引导的设备，找到后也就是对应的引导扇区 MBR，加载内存中，然后执行 引导扇区比较小，只有 512 字节，所以肯定无法完成后续的操作系统加载初始化的所有工作，所以这里就包含了一些关键信息：如何继续启动过程和装载 OS 的一些信息，也就是包含分区表，Boot Code（查看哪个分区是 Active）Boot code 执行后就会把控制权交给对应 Active 分区的 boot 部分 接下来就是 Bootloader（比如 GRUB） 部分，装载 kernel 和 initrd initrd 就是 Ram Disk，可以被 kernel 解压使用，用来作为临时的 root 文件系统，直到真正的 root 文件系统被挂载。initrd 主要包含了可以挂载真正 root 文件系统的程序和一 些必要的驱动 kernel 和 initrd 配合完成上面的，就开始将控制权交给 /sbin/init (对于 initramfs 则是 /init)，/sbin/init 主要会加载所有对应的 service 和用户空间的工具（配置的内容在 /etc/inittab 文件中），挂载对应 /etc/fstab 下的分区 用户进入登录界面 特别说明，关于 initrd 和 initramfs 区别，在于initrd 和 initramfs 都是作为根文件系统被挂载前的临时文件系统，被内核调用 区别是：(更详细参考文献 12)initrd 是 linux kernel 2.6 前引入的， 是一个 gzip 压缩的文件系统类型的镜像，需要内核中相应的模块编译才能完成对应的加载（比如loop 设备）initramfs 是 linux kernel 2.6 引入的，一个 gzip 压缩的 cpio 归档，是一个内存盘，不依赖于底层的文件系统 Image type Location of init Tool used to build the imageinitramfs /init cpio -H newc -oinitrd /sbin/init mkcramfs, genext2fs (and others) 具体查看对应镜像中的内容如下： 1234567891011121314151617181920212223242526initrd： # mkdir /tmp/initrd# cp initrd.img /tmp/initrd# gunzip &lt; /tmp/initrd/initrd.img# mkdir /mnt/initrd# mount –ro loop /tmp/initrd/initrd /mnt/initrd# cd /mnt/initrdinitramfs：# gunzip -c /boot/initrd-2.6.31.img &gt; /tmp/my_initrd# cpio -it &lt; /tmp/my_initrd [examine contents] lib lib/udev lib/udev/console_init lib/firmware lib/firmware/radeon lib/firmware/radeon/RV730_me.bin ... snip ... lib/modules lib/modules/2.6.31 lib/modules/2.6.31/radeon.ko lib/modules/2.6.31/modules.isapnpmap ... and so on and so on ...# cd [somewhere] [in preparation for unloading]# cpio -i &lt; /tmp/my_initrd [unload] 参考： [1] http://flint.cs.yale.edu/feng/cos/resources/BIOS/[2] https://www.bbsmax.com/A/pRdBnwg9dn/[3] http://www.dewassoc.com/kbase/hard_drives/master_boot_record.htm[4] https://www.pks.mpg.de/~mueller/docs/suse10.1/suselinux-manual_en/manual/cha.boot.html[5] https://www.novell.com/documentation/suse91/suselinux-adminguide/html/ch12s03.html[6] https://www.kernel.org/doc/html/v4.10/admin-guide/initrd.html[7] https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/5/html/Installation_Guide/ch-boot-init-shutdown.html[8] https://en.wikipedia.org/wiki/Initrd[9] https://en.wikipedia.org/wiki/Linux_startup_process[10] http://www.thegeekstuff.com/2011/02/Linux-boot-process/[11] http://www.aclevername.com/articles/linux-xilinx-tutorial/minimalist-initramfs.html[12] https://www.kernel.org/doc/Documentation/filesystems/ramfs-rootfs-initramfs.txt[13] https://www.zhihu.com/question/22364502[14] https://www.linux.com/learn/kernel-newbie-corner-initrd-and-initramfs-whats[15] http://www.aclevername.com/articles/linux-xilinx-tutorial/minimalist-initramfs.html[16] https://zh.wikipedia.org/wiki/Initrd[17] https://ksearch.wordpress.com/2010/09/30/extract-contents-of-initrd/]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一篇很好的 Linux EXT 文件系统入门介绍的文章]]></title>
    <url>%2F2017%2F05%2F27%2F%E4%B8%80%E7%AF%87%E5%BE%88%E5%A5%BD%E7%9A%84%20Linux%20EXT%20%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D%E7%9A%84%E6%96%87%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[一个国外的技术专家写的文章，介绍了 EXT 文件系统演进的历史，以及文件系统的基础知识，绝对值得一读 https://opensource.com/article/17/5/introduction-ext4-filesystem]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编译 QEMU 报错 configure.ac:14: error: possibly undefined macro: AC_PROG_LIBTOOL]]></title>
    <url>%2F2017%2F05%2F25%2F%E7%BC%96%E8%AF%91%20QEMU%20%E6%8A%A5%E9%94%99%20possibly%20undefined%20AC_PROG_LIBTOOL%2F</url>
    <content type="text"><![CDATA[在 CentOS 7.2 上编译最新的 QEMU 2.9.0 版本的时候，发现除了常规的 1yum install gcc gcc-c++ zlib-devel glibc-devel automake autoconf 依赖包，还会报另外一个错误 123configure.ac:14: error: possibly undefined macro: AC_PROG_LIBTOOL If this token and others are legitimate, please use m4_pattern_allow. See the Autoconf documentation. 这个错误可以安装如下的包来解决： 1yum install libtool]]></content>
      <tags>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CNI 项目被接纳托管到 CNCF，推动云原生应用的网络模型演进]]></title>
    <url>%2F2017%2F05%2F24%2FCNI%20%E9%A1%B9%E7%9B%AE%E8%A2%AB%E6%8E%A5%E7%BA%B3%E6%89%98%E7%AE%A1%E5%88%B0%20CNCF%EF%BC%8C%E6%8E%A8%E5%8A%A8%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%9A%84%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%BC%94%E8%BF%9B%2F</url>
    <content type="text"><![CDATA[今天 CNCF 又迎来了一位重要网络项目成员——CNI，这也是放在 CNCF 托管的第10个项目 CNI 是一个关于容器网络接口标准的项目，由 CoreOS 发起，Redhat OpenShift, Apache Mesos, Cloud Foundry, Kubernetes, Kurma 和 rkt 公司创立。CNI 定义了一套通用接口，接口面向网络插件和容器运行环境，CNI 定义的接口也是最小化，主要关注：容器的网络连通性和容器移除的时候的相关网络资源释放。 CNI 主要包含了三大组件 （参考下图） CNI Specification： 定义了容器运行时和网络插件之间的API，实现容器网络的建立和销毁 Plugins：支持不同网络技术和方案的扩展性手段 Library：提供了 CNI Specification 一种 Go 实现，容器运行时可以很容易的使用 CNI 当然 CNI 还很年轻，还需要根据容器领域的发展很好的进一步调整和适配，保证容器运行可以很便利稳定的消费 CNI， 为整个容器系统构建稳定网络环境 参考： https://www.cncf.io/category/blog/]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web 开发值得注意的 12 个安全原则]]></title>
    <url>%2F2017%2F05%2F23%2FWeb%20%E5%BC%80%E5%8F%91%E5%80%BC%E5%BE%97%E6%B3%A8%E6%84%8F%E7%9A%84%2012%20%E4%B8%AA%E5%AE%89%E5%85%A8%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[下面的这篇文章值得读一下，结合云计算开发中一些特点，将相应的安全问题分类做了一些总结： https://simplesecurity.sensedeep.com/web-developer-security-checklist-f2e4f43c9c56.]]></content>
      <tags>
        <tag>Web开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linuxkit 快速 build VM 镜像]]></title>
    <url>%2F2017%2F05%2F19%2FLinuxkit%20%E5%BF%AB%E9%80%9F%20build%20VM%20%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[Linuxkit 是什么？ 这个我原来这博文【1】中大概介绍过，今天再重新说一下，其实 Linuxkit 就是一个强大的工具集，这个工具集可以定制化基于容器的操作系统，这些镜像可以部署到现有的一些云平台上，因为本身支持很多的镜像格式 kernel+initrd，qcow2 等。 废话不多说，我们演示一下如何 build 一个镜像，拿 docker 为例 1&gt; $ git clone https://github.com/linuxkit/linuxkit.git2&gt; $ cd linuxkit运行 make 命令 一会就 build 完成对应的工具，包括 linuxkit，moby，rtf linuxkit 命令主要用于和 cloud 或者本地 hypervisor 交互的： push 镜像，部署镜像moby 用于 build VM 镜像的rtf 社区开发中运行集成测试的 3&gt; 使用上面的工具开始 build 镜像 $ cd examples$ moby build docker默认生成 kernel+initrd 镜像，还有对应的启动参数 123-rw-r--r-- 1 root root 71622481 May 17 11:42 docker-initrd.img-rw-r--r-- 1 root root 7541328 May 17 11:42 docker-kernel-rw-r--r-- 1 root root 40 May 17 11:42 docker-cmdline $ 运行 docker 镜像 1$ linuxkit run docker 注意这里运行的时候，依赖一些可支持的平台，如下： 123456Supported backends are (default platform in brackets): gcp hyperkit [macOS] qemu [linux] vmware packet 本文一台 CentOS 机器，装了相关的 QEMU 相关的软件，否则会出现不能运行，或者进入VM 后，出现乱码的状况 最后有如下的画面 12345678910111213141516171819[ 12.764709] tsc: Refined TSC clocksource calibration: 2294.665 MHz[ 12.764991] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x2113854cd53, max_idle_ns: 440795215552 ns[ 12.773755] Freeing unused kernel memory: 820K (ffff8ba191933000 - ffff8ba191a00000)[ 12.823433] Freeing unused kernel memory: 1012K (ffff8ba191d03000 - ffff8ba191e00000)[ 13.782833] clocksource: Switched to clocksource tscWelcome to LinuxKit ## . ## ## ## == ## ## ## ## ## === /"""""""""""""""""\___/ === ~~~ &#123;~~ ~~~~ ~~~ ~~~~ ~~~ ~ / ===- ~~~ \______ o __/ \ \ __/ \____\_______// # 执行 runc list 查看 12345/ # runc listID PID STATUS BUNDLE CREATED OWNERdhcpcd 607 running /run/containerd/linux/dhcpcd 2017-05-18T10:36:44.584310687Z rootdocker 639 running /run/containerd/linux/docker 2017-05-18T10:36:47.003939228Z rootntpd 668 running /run/containerd/linux/ntpd 2017-05-18T10:36:48.825102369Z root 进入 docker 容器， 1234/ # runc exec -t docker sh/ # docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES/ # 这样一个 VM 中的容器中运行的 docker 进程就 OK 了，也很简单 当然了社区这个工具开发相对时间不长，所以有些调试或者使用易用性上还有很多要做的工作 参考文献： http://blog.chinaunix.net/uid-21335514-id-5763176.html https://github.com/linuxkit/linuxkit]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP-2 的简单介绍和理解]]></title>
    <url>%2F2017%2F05%2F14%2FHTTP-2%20%E7%9A%84%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%E5%92%8C%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[演进时间点HTTP 发明(1989 Tim Berers-Lee) –&gt; HTTP 1.0 (1996) –&gt; HTTP 1.1 (1999) –&gt; HTTP/2 (2015) HTTP 1.0 中的问题：每次请求都是一次独立的 TCP （3次握手）连接建立和关闭的过程；HOL （Head-of-line blocking）如果由于前面的请求不能及时处理，后续请求需要被阻塞直到前面的请求处理完毕才能继续发送。 HTTP 1.1 相比 1.0 改进了包括：持久化连接，重用了 TCP 连接，减少不必要的资源的建立和释放过程。Pipeline 机制：多个请求可以同时发送，但是服务端仍然要按序一个个返回，所以仍然有一定程度的(HOL)， 各个浏览器对于这个特性不太感冒，很多禁掉或者没有实现这个Pipeline 机制 除了上述主要修改，还涵盖Cache，扩展性（引入的比如路径追踪的头部和OPTIONS 方法），带宽利用（断点续传，部分资源请求，压缩），网络连接管理（持久化，Pilelining），消息传递（分块传输，编码方式指定），网络地址维护，错误通知的管理（新的状态码和警告头部），安全和完整性 为了有效利用带宽和提高Web 服务性能，采用了一些技术 拼接技术： 多个 js 文件整合一个，减少请求次数，但是也造成杀鸡牛刀的影响（小改动大数据的重新下载） 嵌入内联 （将一些图片原始数据嵌入 css 中，也是减少请求次数，缓存无法有效利用，无法页面共享） Sprite 技术 （将很多小图拼接大图，然后使用js和css 等重新切割出来的小图，维护开发相对复杂） Sharding 技术（浏览器限制某一个域最多有 5（不同浏览器有些小的差别）连接，所以有些网站为了提高性能，使用新的主机名，提高同时连接的数目，实现资源请求的效率的提升） HTTP/2 登场HTTP 1.1 虽然较 1.0 改进了了很多，但是在如今随着网页的越来越复杂丰富，移动网络的兴起（相比传统的有线稳定的网络），如今的带宽往往处理这些越来越力不从心，所以演进了 HTTP/2 (基于 Google SPDY) HTTP/2 有如下特点： 二进制的协议（相比原来的文本方式，解析处理更加容易） 采用多路复用（共享连接上双方可以同时发送请求和响应，这样原来 HTTP/1.1 的中一些技术比如sharding，嵌入内联，Spriting 就没有必要了） 每个流可以设置优先级和依赖关系 （服务器或者客户端对于并行发送的这些独立的帧的设置，可以控制资源的获取先后顺序） 服务器推送 （服务器主动将资源推送给客户端，减少客户端额外请求的延迟） 头部压缩 （HPACK 压缩格式，主要是静态Huffman 对头部字段编码 ，并且客户端和服务端同时维护，更新这些头部字段的索引列表） 流量控制 （服务器和客户端可以实现自己的数据流流量控制，更加接近应用级别的流控） HTTP/2 的支持 现在基本所有大型浏览器对提供了对于 HTTP/2 的支持，包括Firefox， Chrome 等。 （HTTP/2本身并不强制使用TLS，但是一些浏览器要求使用HTTP/2 必须使用 TLS） ,一些主要的Web 服务器也提供了支持，比如Nginx，Apache 等。 部署 HTTP/2 需要客户端和服务器同时支持，如果对于普通的Web 程序，浏览器支持就够了。 HTTP/2 性能比较一个例子 通过https://imagekit.io/demo/http2-vs-http1 这个例子，我们开启 Chrome 中的protocol 显示，发现 HTTP/2 的请求几乎是同时，然后完成加载 而 HTTP/1.1 同一时间是大约是5~6 个并发请求，所以对于这种100 个小图拼接的图像，HTTP/2 完败 HTTP/1.1 以上只是简单的总结，更加深入的介绍还需要对于 HTTP/2 规范等细致的通读一下。 https://www.w3.org/Protocols/HTTP/1.0/spec.htmlhttps://www.w3.org/Protocols/History.htmlhttp://www8.org/w8-papers/5c-protocols/key/key.htmlhttps://bagder.gitbooks.io/http2-explained/content/zh/part3.htmlhttps://developers.google.com/web/fundamentals/performance/http2/https://linjunzhu.github.io/blog/2016/03/10/http2-zongjie/http://www.jianshu.com/p/52d86558ca57https://imququ.com/post/header-compression-in-http2.htmlhttp://if-true.com/2015/04/27/tech-difference-between-http-1.1-2.0.htmlhttps://blog.imagekit.io/still-not-using-http-2-327d56397b58https://tools.ietf.org/html/rfc7540https://en.wikipedia.org/wiki/Head-of-line_blockinghttps://en.wikipedia.org/wiki/HTTP_pipelininghttp://www.cnblogs.com/xiaohuochai/p/6159326.htmlhttps://imagekit.io/demo/http2-vs-http1]]></content>
      <tags>
        <tag>服务器与存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[screen 的优化配置]]></title>
    <url>%2F2017%2F04%2F22%2Fscreen%20%E7%9A%84%E4%BC%98%E5%8C%96%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[在原来的一篇文章中曾经提到过 screen 的一些使用方法，参见下面的内容 http://blog.chinaunix.net/blog/post/id/4033839.html 但是在使用过程中，发现一个好的 screen 配置是十分必要的，比如一个自己使用的例子如下点击(此处)折叠或打开 123456789101112131415161718192021222324vbell offbell_msg ""startup_message off# Tell screen how to set colors. AB = background, AF=foregroundtermcapinfo xterm 'Co#256:AB=\E[48;5;%dm:AF=\E[38;5;%dm'## Enables use of shift-PgUp and shift-PgDntermcapinfo xterm|xterms|xs|rxvt ti@:te@## Enable 256 color termterm xterm-256color## Cache 30000 lines for scroll backdefscrollback 30000# https://wiki.archlinux.org/index.php/GNU_Screen#Start_at_window_1bind c screen 1bind ^c screen 1bind 0 select 10screen 1hardstatus off# https://bbs.archlinux.org/viewtopic.php?id=12571# http://man7.org/linux/man-pages/man1/screen.1.htmlhardstatus alwayslastlinehardstatus string '%&#123;= kG&#125;%c %06=%-Lw%&#123;= RW&#125;%50&gt;%n%f* %t%&#123;-&#125;%+Lw%&lt;' 其中最复杂的配置部分就是 hardstatus，这里 string 里的配置依次是： 设置颜色，显示标题时间（固定），当前窗口的显示颜色，窗口标号，窗口的标志，星号，窗口标题。其中比较晦涩的地方就是缩短的控制（screen 窗口过多的情况下，避免后续新开的窗口无法显示出来，完成一个类似可以动态窗口显示的功能）]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 开始了新的容器生态系统玩法]]></title>
    <url>%2F2017%2F04%2F19%2FDocker%20%E5%BC%80%E5%A7%8B%E4%BA%86%E6%96%B0%E7%9A%84%E5%AE%B9%E5%99%A8%E7%94%9F%E6%80%81%E7%B3%BB%E7%BB%9F%E7%8E%A9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[这两天在Austin, Texas.举办的 DockerCon 2017 释放了重要的信息，Docker 官方发布了两个开源的项目，一个是 LinuxKit ，一个是 Moby LinuxKit 目前看应该是为容器系统搭建基础的可定制化，可裁剪的 Linux 发行版，这个是为了解决目前容器系统运行的一些基础镜像过分笨重的问题 Moby 更是 Docker 官方升级容器系统的一个大玩法，不再局限于单纯的 Swarm 或者 Docker 运行时了，而是面向系统集成厂商或者创新实现的 Hacker们，开创的一种 Framework + Library 方法，可以利用广泛的开源的容器相关的组件（比如 runtime，build，image，volume 等）搭建出个定制化的容器化大系统，这种策略可以初期看出来更像平台玩法，吸引更多的集成商进来助力Docker 相关容器系统的推广和使用。当然这个项目不是针对应用开发者的，毕竟应用开发者不关心底层的系统构建。 通过这两个重要信息，我们可以看出以前的工具类的玩法逐渐变为平台玩法，平台开发吸引更多的厂商加入，才可能把市场影响力扩大。为了支持这个平台玩法，从基础镜像裁剪到运行时，到build，security 等组件化，为新的玩法提供了这种可能。 或无疑问，这种开放策略必将容器生态扩大，但这种策略能否助力 Docker 公司自身的成功，还是需要一些生态推进和执行力保证的。让我们拭目以待。 来源： https://blog.docker.com/2017/04/introducing-the-moby-project/http://www.eweek.com/cloud/docker-opens-ups-container-platform-with-linuxkit-and-moby-project]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[值得收藏的几个快捷Linux操作，提高工作效率]]></title>
    <url>%2F2017%2F04%2F08%2F%E5%80%BC%E5%BE%97%E6%94%B6%E8%97%8F%E7%9A%84%E5%87%A0%E4%B8%AA%E5%BF%AB%E6%8D%B7Linux%E6%93%8D%E4%BD%9C%EF%BC%8C%E6%8F%90%E9%AB%98%E5%B7%A5%E4%BD%9C%E6%95%88%E7%8E%87%2F</url>
    <content type="text"><![CDATA[https://www.linux.com/learn/intro-to-linux/2017/4/fabulous-bash-navigation-shortcuts记录了一些命令使用技巧，有些自己没太常用，觉得熟悉这些还是很有帮助的，至少提高工作的效率，挑选了几个觉得有用的如下： locate filename 查找文件Shift+PageUp / Shift+PageDown 浏览比较长的命令输出结果locate filename 查找文件鼠标选择（middle 点击） 拷贝命令cd - 当前和上一次的目录快速切换 Ctrl+l == clear 命令Ctrl+a == HomeCtrl+e == EndAlt+b 向后一个单词Alt+f 向前一个单词Ctrl+c 清除当前命令Ctrl+u 删除从光标到最前面的所有字符Ctrl+k 删除从光标到最后面的所有字符Ctrl+y 粘贴删除的字符]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google 新的开源领导力见证- opensource.google.com 起航]]></title>
    <url>%2F2017%2F03%2F30%2FGoogle%20%E6%96%B0%E7%9A%84%E5%BC%80%E6%BA%90%E9%A2%86%E5%AF%BC%E5%8A%9B%E8%A7%81%E8%AF%81-%20opensource.google.com%20%E8%B5%B7%E8%88%AA%2F</url>
    <content type="text"><![CDATA[Google 一直是开源领域重量级的参与者，一方面因为技术人才辈出，另一方面因为涉猎的领域颇为广泛，所以从中积累了大量的优秀的开源软件产品和经验，如何更加有效的整合这些开源产品，如何管理，如何发布和支持，Google 有一套自己的处事哲学。相比基于这些出点点启动的opensource.google.com 对于技术人员不是一个坏事情，所以大家可以结合自己的兴趣到网站上去了解一些自己刚兴趣的项目的较为全方位的信息，从中受益。 参考： https://opensource.googleblog.com/2017/03/a-new-home-for-google-open-source.html?m=1]]></content>
      <tags>
        <tag>IT业界</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[有趣的 Go 语言 2016 调查]]></title>
    <url>%2F2017%2F03%2F13%2F%E6%9C%89%E8%B6%A3%E7%9A%84%20Go%20%E8%AF%AD%E8%A8%80%202016%20%E8%B0%83%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[golang网站的一篇blog 记录了 2016 关于 go 语言的一些用户调查，有些和 stackoverflow 调查相似的结论，有点意思，大概总结我感兴趣的几点 调查人群以美国和欧洲为主体调查开发平台多是 Linux对 golang 的使用较多的编辑器是 Vim， 并且大家感到比较满意，同时希望在debug 上有更亲民的进展（这个都是 VIM 的深粉丝啊）golang 应用到 web 开发， RPC， API 服务上（看看网上一些微服务的相关的，新火的 web 框架，可想而知）在评价语言的偏好上，go 被列为了第一(这个和stackoverflow 不太一样，而是伟大的 javascript）大家觉得 go 语言简单易学stackoverflow 依然是大家获取问题解答的主要阵地 参考： https://blog.golang.org/survey2016-results?utm_source=golangweekly&amp;utm_medium=email&amp;imm_mid=0ee8ca&amp;cmp=em-prog-na-na-newsltr_20170311]]></content>
      <tags>
        <tag>IT业界</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 非常实用的命令技巧]]></title>
    <url>%2F2017%2F03%2F06%2FLinux%20%E9%9D%9E%E5%B8%B8%E5%AE%9E%E7%94%A8%E7%9A%84%E5%91%BD%E4%BB%A4%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[1.格式化表格输出命令结果通过 column 命令来格式化结果 例如： mount | column -t 因为默认的以空格作为分隔符，如果对于一些命令的输出分隔符不是空格的情况下，使用下面的方式：还有类似的 cat /etc/passwd | column -t -s : 重复的执行命令直到成功这个没有什么特别的的地方，使用 while 循环 巧妙的使用sort来对某些列进行排序 例如根据内存使用来对进程进行排序：ps aux | sort -nk 4 同时查看监控多个log文件 单个文件的查看的时候通常是使用 tail，如果同时查看多个文件的话使用multitail 命令【TODO】 回退到上一次目录 cd - 6.Make a Non-Interactive Shell Session InteractiveTo do this, change the settings from ~/.bashrc to ~/.bash_profile. 个人注：【这个目前在平常没有发现使用的场景 ，不做进一步的介绍】 固定间隔下监控命令的输出 1watch df -h 8.在session（shell）结束的时候仍然保持程序的运行 1nohup wget site.com/file.zip 这个也可以通过screen 来实现 在一些交互式的命令中自动的回答yes 和 no通过yes 命令来完成，例如： 1yes | apt-get update 如果是想回答no的话，使用 yes no | command 10.创建一个特定大小的文件，使用dd 命令来完成，例如: 1dd if=/dev/zero of=out.txt bs=1M count=10 11.以root身份运行上一个命令sudo !! 记录你的Linux 终端回话记录这个不是单纯的history 记录执行的命令，它除了记录执行的命令，还有执行的结果。使用方式：script …. 执行的命令 exit 它会自动生成一个typescript 文件，包含了你说执行的命令和输出结果 同时可以结合 scriptreplay 来回放你刚才执行的过程。 使用tab 来替换掉空格通过使用tr命令，例如: 1cat geeks.txt | tr ':[space]:' '\t' &gt; out.txt 使用xargs 命令来完成一些高级的管道命令操作 1find. -name *.png -type f -print | xargs tar -cvzf images.tar.gz 注意这里默认是使用上一个命令的输出给xargs命令的最后面 如果你的命令需要的是中间的位置，比如 cp xx /somepath 这样可以借助 {} 和 -i 参数 例如： 1ls /etc/*.conf | xargs -i cp &#123;&#125; /home/likegeeks/Desktop/out 参考： https://dzone.com/articles/most-useful-linux-command-line-tricks]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[当 Virtualbox 5.x 在 4.9内核中遇到了编译错误]]></title>
    <url>%2F2017%2F02%2F16%2F%E5%BD%93%20Virtualbox%205.x%20%E5%9C%A8%204.9%E5%86%85%E6%A0%B8%E4%B8%AD%E9%81%87%E5%88%B0%E4%BA%86%E7%BC%96%E8%AF%91%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[在使用 VBox 安装的 Fedora 25 虚拟机，安装Guest Addition 过程中，发现无法安装，报编译错误 查看Vbox 官方问题列表发现 https://www.virtualbox.org/ticket/16286这个在 5.1.12 修复了，具体changelog 参考列表https://www.virtualbox.org/wiki/Changelog 解决方法，升级5.1.12 或者最新的 5.1.14 版本 另外附上：具体常规的安装步骤如下： 123dnf update kernel*reboot 从 GUI 上选择安装增强功能 12345678mkdir /media/VirtualBoxGuestAdditionsmount -r /dev/cdrom /media/VirtualBoxGuestAdditionsdnf install gcc kernel-devel kernel-headers dkms make bzip2 perlcd /media/VirtualBoxGuestAdditions./VBoxLinuxAdditions.run 参考： https://www.if-not-true-then-false.com/2010/install-virtualbox-guest-additions-on-fedora-centos-red-hat-rhel/]]></content>
      <tags>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈谈 stackoverflow 2016 开发者调查结果]]></title>
    <url>%2F2017%2F02%2F11%2F%E8%B0%88%E8%B0%88%20stackoverflow%202016%20%E5%BC%80%E5%8F%91%E8%80%85%E8%B0%83%E6%9F%A5%E7%BB%93%E6%9E%9C%2F</url>
    <content type="text"><![CDATA[调查从 技术，工作，社区三大方面展开，每个大方面都包含若干个小的方面，根据自己感兴趣的几个地方，汇总如下：接受调查提供反馈的人以英语国家为主，平均年龄是29.6，编程经验为6.5 年（这里注意一下，这里不一定是职业编程经验，因为有些学生称自己有 3.4 年的编程经验） 开发者职业方向最多的是 full-stack web开发者占据 28%， 学生也占据一个比较大的比例约为 11% 在语言的使用上，javascript 占据优势 女性更偏向从事设计师，QA，机器学习等 73% 开发者偏向多样化的工作环境 69% 都会将自学作为学习新知识的途径 技术趋势方面: React, Node.js, and AngularJS 仍在增长，还有 spark， cloud 等继续保持增长 平均每个工程师使用4-5门语言，比如一些开发者经常使用 javascript，php 和sql 工程师开发环境主要还是 notepad++,VS, Sublime Text 和 vim, 一般使用 2-3 中开发环境。桌面操作系统Mac 居多，为26.2%，但是Linux 也相差不多，约为21.7% 求职方面，开发者在求职考虑中，会包括薪水，工作生活平衡，公司文化，好的团队成员等一般薪水低的国家的开发者对于薪水的考虑更多一些。 开发者最讨厌不切实际的开发期望，糟糕的文档，不具体的产品需求越是资深的开发者这方面表现的越明显，而经验越少的开发者对于为人友善更加强调。 开发者更喜欢自己代码有实际用处，并且在生产环境中使用。 资料参考来源： http://stackoverflow.com/research/developer-survey-2016]]></content>
      <tags>
        <tag>IT业界</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DevOps, SRE and system engineering 的一些必备知识技能]]></title>
    <url>%2F2017%2F02%2F05%2FDevOps%2C%20SRE%20and%20system%20engineering%20%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BF%85%E5%A4%87%E7%9F%A5%E8%AF%86%E6%8A%80%E8%83%BD%2F</url>
    <content type="text"><![CDATA[有一篇很不错的英文如下，总结了一些基本的知识点，这个对于工作和面试的一些方面有参考价值，希望对其他人有帮助之处： 来源： https://hackernoon.com/the-must-know-checklist-for-devops-system-reliability-engineers-f74c1cbf259d?imm_mid=0ec6e8#.1qvl6v6uoSource 我本着学习和兴趣的需要，总结分类如下： 系统基础 熟悉理解和使用 *nix 系统，了解不同发行版的区别，理解系统内部的基本原理熟练掌握查看系统、CPU 内存等性能数据理解和使用 cron，理解和掌握一种shell，shell相关文件的配置。知道 bash/dash/sh/ash/zsh 区别设置环境变量，如何持久化知道 init 系统原理，upstart systemd，会使用systemctl journalctl 分析和调试问题会编译源代码理解ext4, ntfs, fat 等文件系统，知道Union文件系统系统如何备份，备份策略，如何验证工作md5, SHA 验证和使用 网络 配置和理解 IP/DNS/DHCP 的原理，router 查看和调试问题SSH keys 和无密码访问配置会配置firewal 设置rule，知道TCP/UDP 区别， OSI模型和 TCP/IP 模型， 知道Vxlan熟悉tcpdump wireshark等分析调试网络问题熟悉使用进程管理ps, top, htop, atop，性能查看nmon, iostat, sar, vmstat网络分析nmap, tcpdump, ping, traceroute, airmon, airodump等熟悉完全协议相关的TLS, STARTTLS, SSL, HTTPS, SCP, SSH, SFTP, FTPS知道 PPTP, OpenVPN, L2TP/IPSec 不同SSL/TLS 如何工作，数字证书（https）如何工作HTTP不同状态码的意义 Web 懂得配置 Web Server（Nginx Apache）Nginx、Apache 区别配置反向代理（Nginx..） 负载均衡，缓存服务器 Devops 懂得配置管理工具，例如chef puppet ansible etc懂得Jenkfins 等 CI的基本配置和使用监控系统的Nagios, Zabix, Sensu, prometheus 搭建和配置使用了解chatops，基本的一些流行的框架 开发基础 脚本语言的使用python ruby 等分布式版本控制工具 Git 的使用和基本原理Vim Vagrant 开发环境的使用，熟悉一种 IDE 环境熟悉理解 docker 和容器的底层技术熟悉理解 Kubernetes/Mesos/SwarmKit 等相关的技术和区别深入掌握 DB （mysql 等）熟悉Redis/Memcache 类似的工具 架构 理解 PaaS/Iaas/Saas/CaaS/FaaS/DaaS and serverless 架构关联和区别理解monolithic和microservices不同，和优缺点理解stateful 和 stateless应用如何设计可扩展，高可靠的分布式系统熟悉理解微服务相关的API和服务知识，例如 RESTfull, RESTful-like, API gateways, Lambda functions, serverless computing,SOA, SOAP, JMS, CRUD 学习方法 Google, StackOverflow, Quora 和其他论坛的使用跟踪其他知名公司 blog， github 开源项目]]></content>
      <tags>
        <tag>系统运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3个开源会议将在中国首次举办 （LinuxCon, ContainerCon, and CloudOpen）]]></title>
    <url>%2F2017%2F01%2F19%2F3%E4%B8%AA%E5%BC%80%E6%BA%90%E4%BC%9A%E8%AE%AE%E5%B0%86%E5%9C%A8%E4%B8%AD%E5%9B%BD%E9%A6%96%E6%AC%A1%E4%B8%BE%E5%8A%9E%20%EF%BC%88LinuxCon%2C%20ContainerCon%2C%20and%20CloudOpen%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Linux 基金会宣布将在中国首次举办旗下的 flagship LinuxCon, ContainerCon and CloudOpen 三大会议，目前会议地点是北京国家会议中心 时间是 2017年6月19-20日 这也是继 MesosCon Asia and Cloud Foundry Summit Asia 在中国举办后的又一推动，这些活动的举办也寓意中国在开源领域正在发挥更大的作用和话语权，因为这些潜在的影响力才能获取更多著名会议的举办机会。 来源： http://events.linuxfoundation.org/events/linuxcon-containercon-cloudopen-china]]></content>
      <tags>
        <tag>IT业界</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[桌面环境安装 Failed to give slave programs access to the display 问题]]></title>
    <url>%2F2017%2F01%2F11%2F%E6%A1%8C%E9%9D%A2%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%20Failed%20to%20give%20slave%20programs%20access%20to%20the%20display%20%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在测试环境安装桌面环境发现 gdm 有错误如下： 1Failed to give slave programs access to the display 尝试安装 gnome 3 桌面环境 gdm 启动不再出现类似的错误。 1yum group install "GNOME Desktop" 但是 gnome desktop 和 gdm 不是一个东西，gdm 只是一个 diplay manager gnome desktop 使用也不完全依赖 gdm]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决 TypeError('{!r} is not a Python function'.format 问题]]></title>
    <url>%2F2017%2F01%2F11%2F%E8%A7%A3%E5%86%B3%20TypeError('%7B!r%7D%20is%20not%20a%20Python%20function'.format%20%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[今天因为在一个测试环境安装更新 gnome桌面发现一个问题 123456789101112131415161718 import requests File "/usr/lib/python2.7/site-packages/requests/__init__.py", line 52, in from .packages.urllib3.contrib import pyopenssl File "/usr/lib/python2.7/site-packages/requests/packages/urllib3/contrib/pyopenssl.py", line 49, in from cryptography.hazmat.backends.openssl import backend as openssl_backend File "/usr/lib64/python2.7/site-packages/cryptography/hazmat/backends/openssl/__init__.py", line 7, in from cryptography.hazmat.backends.openssl.backend import backend File "/usr/lib64/python2.7/site-packages/cryptography/hazmat/backends/openssl/backend.py", line 37, in from cryptography.hazmat.backends.openssl.x509 import _Certificate File "/usr/lib64/python2.7/site-packages/cryptography/hazmat/backends/openssl/x509.py", line 24, in class _Certificate(object): File "/usr/lib64/python2.7/site-packages/cryptography/utils.py", line 23, in register_decorator verify_interface(iface, klass) File "/usr/lib64/python2.7/site-packages/cryptography/utils.py", line 43, in verify_interface actual = inspect.getargspec(getattr(klass, method)) File "/usr/lib64/python2.7/inspect.py", line 815, in getargspec raise TypeError('&#123;!r&#125; is not a Python function'.format(func))TypeError: is not a Python function 这个一般从网上找有各种各样的解答，直接照搬是没有帮助的，初步当时怀疑是python 的一些安装包版本冲突导致了，仔细看上面的是从 requests 引发的，那么我们先通过 pip 查看对应的 requests 版本，发现有两个版本，显然是前面升级中误操作了什么导致的。 解决方法，卸载全部的requests 包，然后重新使用 pip 安装]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Clair - 容器安全监测工具的安装]]></title>
    <url>%2F2016%2F12%2F29%2FClair%20-%20%E5%AE%B9%E5%99%A8%E5%AE%89%E5%85%A8%E7%9B%91%E6%B5%8B%E5%B7%A5%E5%85%B7%E7%9A%84%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Clair 是 Coreos 公司推出的一款安全的镜像静态分析扫描工具，类似的功能在 Docker 官方的商业 dockerhub 上也有不同的实现。 Clair 是一款开源的软件，具体可以参考 https://github.com/coreos/clair 我们简单的来介绍一下如何使用 docker 容器来快速的体验相应的功能，具体实践步骤如下： 安装 PostgreSQL 9.4+ 数据库， 这里我们使用 sameersbn/postgresql:9.5-3 镜像来安装 这里为了方便网络的配置，使用 host net 方案， 1docker run --net host --name postgresql -itd --restart always --env 'PG_PASSWORD=yourpassword' sameersbn/postgresql:9.5-3 创建 clair 的配置 1curl -L https://raw.githubusercontent.com/coreos/clair/v1.2.6/config.example.yaml -o $HOME/clair_config/config.yaml 修改其中的 postgresql 配置， 类似如下： 1source: postgresql://postgres:yourpassword@ip:5432?sslmode=disable 运行 clair 1docker run -d -p 6060-6061:6060-6061 -v /root/clair_config/:/config -v /tmp:/tmp clair:dev -config=/config/config.yaml 这样clair 就运行了，clair 刚开始运行需要一段较长的时间来更新安全数据数据库，所以确保外网网络连接正常 运行 clair 扫描工具 1./analyze-local-images a1553cdf672f 这里的 analyze 通过如下安装 1go get -u github.com/coreos/clair/contrib/analyze-local-images 运行结果类似如下： 12345678910111213141516171819202122232425CVE-2016-0494 (High) Unspecified vulnerability in the Java SE and Java SE Embedded components in Oracle Java SE 6u105, 7u91, and 8u66 and Java SE Embedded 8u65 allows remote attackers to affect confidentiality, integrity, and availability via unknown vectors related to 2D. Package: icu @ 52.1-8+deb8u3 Fixed version: 52.1-8+deb8u4 Link: https://security-tracker.debian.org/tracker/CVE-2016-0494 Layer: 8760f48ef252d37743b66f97f5d55646656a84a9e967d3a8028e09b3b7544106CVE-2016-7167 (High) Multiple integer overflows in the (1) curl_escape, (2) curl_easy_escape, (3) curl_unescape, and (4) curl_easy_unescape functions in libcurl before 7.50.3 allow attackers to have unspecified impact via a string of length 0xffffffff, which triggers a heap-based buffer overflow. Package: curl @ 7.38.0-4+deb8u5 Link: https://security-tracker.debian.org/tracker/CVE-2016-7167 Layer: 8760f48ef252d37743b66f97f5d55646656a84a9e967d3a8028e09b3b7544106......]]></content>
      <tags>
        <tag>网络与安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下删除减号开头的文件]]></title>
    <url>%2F2016%2F11%2F24%2FLinux%E4%B8%8B%E5%88%A0%E9%99%A4%E5%87%8F%E5%8F%B7%E5%BC%80%E5%A4%B4%E7%9A%84%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[个人无意使用原因产生了一个临时文件，发现类似 “-2015testdoc” 这种文件不是使用常规或者\转移符类似的方式，需要使用类似下面的方式 1rm -- "-2015testdoc" 关于创建类似 1touch -- -2015testdoc 或 touch ./-2015testdoc 可以创建 参考资料： http://blog.csdn.net/starperfection/article/details/50310711]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[确定javascript新语法的兼容性]]></title>
    <url>%2F2016%2F11%2F24%2F%E7%A1%AE%E5%AE%9Ajavascript%E6%96%B0%E8%AF%AD%E6%B3%95%E7%9A%84%E5%85%BC%E5%AE%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[前段时间使用javascript比较新的语法，比如Destructuring assignment发现浏览器兼容问题，这个主要是因为不同浏览的版本在语法支持上有不同的要求类似 chrome 48 不支持，chrome 49 就支持了，所以在使用上大家还是尽量注意要支持的浏览器版本的要求。 参考资料 https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Destructuring_assignment https://www.chromestatus.com/feature/4588790303686656]]></content>
      <tags>
        <tag>Web开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[refresh页面，如何保持当前的tab]]></title>
    <url>%2F2016%2F11%2F24%2Frefresh%E9%A1%B5%E9%9D%A2%EF%BC%8C%E5%A6%82%E4%BD%95%E4%BF%9D%E6%8C%81%E5%BD%93%E5%89%8D%E7%9A%84tab%2F</url>
    <content type="text"><![CDATA[经过调查和尝试, 发现有两类方法，一个是使用location.hash，另外一种是使用localStorage windows.location.hash 有一个问题，在于不切换tab的情况下，tab标号不变导致 submit 是不进行相应页面reload的 localStorage 也有一个潜在的问题是 对应的tab的情况下，因为是相当于cache机制，所以会造成对应的共享问题，但是这个可以通过让每个对象公用一个 tab，减少不同对象之间的冲突 参考资料： http://stackoverflow.com/questions/16808205/keep-the-current-tab-active-with-twitter-bootstrap-after-a-page-reload]]></content>
      <tags>
        <tag>Web开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[marathon 1.3.0 功能介绍]]></title>
    <url>%2F2016%2F10%2F24%2Fmarathon%201.3.0%20%E5%8A%9F%E8%83%BD%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[marathon 1.3.0 相较1.1.0 增加一些新的功能，同时有些新功能的加入并不是向后兼容的，包括对外部的依赖marathon 从 1.2.0 版本以后，就开始要求 mesos 的版本大于1.0.0 不兼容修改： 下面来详细介绍一下新的功能： 新的选举依赖库 marathon 的 leader 选举代码改进增加了稳定性，Leader 选举的代码是依赖于 Curator 第三方库的因为新的leader 选举库是和 1.2.0 之前marathon 不兼容的，所以如果从老的 marathon 升级而来，需要停掉老的marathon 再进行升级，否则会出现多个 leader 冲突 Framework 的增加了验证命令行参数支持 Framework 的认证主要是为了配合 mesos 认证功能来使用的，mesos 的认证运行可信赖的 Framework 向 mesos 注册。默认是关闭的，用户需要通过 –mesos_authentication 来使用 这项功能 TASK_LOST GC 的超时默认值的更改 如果 task 确认为lost 状态，因为某个原因表明 task 还会恢复，marathon 等待其恢复直到超时原来默认的是 24 小时，现在改为 75秒，可以通过以下的参数来控制 1-task_lost_expunge_gc, --task_lost_expunge_initial_delay, --task_lost_expunge_interval. 新功能简介 Universal Containerizer从 1.3.0开始，marathon 支持在没有docker daemon 的情况下部署docker image。通过原生的操作系统的功能来支持 AppC 和 docker 镜像启动和配置，提供隔离性 TASK_LOST behavior如果mesos agent 和 master 失联，所有agent 上的 task 都认为是 lost 状态。 marathon 过去是对这些 lost task直接杀掉的。但是某些情况下，这些agent 可能会重新加入集群，所以 lost并不是终止态 在这个新版本，marathon 会等待 lost task 直到被确认为 dead，默认超时时间是 75 秒，超过75秒，lost task 就被杀掉了 Task Kill Grace Period每个应用都可以定义个kill grace period，当对task 进行杀死操作的时候，agent 会尽量在这个grace period之后销毁task。但是这个等待时间是弱限制的，agent 可能会给其分配一个短的间隔强制终止 MAX_PER constraint之前版本的限制无法满足在某个agent 部署固定数目的容器，现在可以限制部署任意的数量 Virtual heartbeat monitor之前版本的marathon 在网络改变的情况下，无法知道和master失联，虚拟心跳提供了这种支持 Authorization to system endpoints之前版本的marathon包含了 对于 AppDefinition 和 Group 改变的授权钩子，新的版本增加了 /v2/leader, /v2/info, /v2/events , /v2/eventSubscriptions 授权钩子 Secrets API support在AppDefinition 中可以使用secrets了，secrets 作为重要的实体在环境变量里使用原生的mesos不支持，需要借助一个插件来支持 Support for Nvidia GPU在AppDefintion 中可以使用gpus作为Nvidia GPU资源了，mesos 对gpus这种重要实体提供原生支持，marathon 中 通过命令行参数 --enable_features gpu_resources来开启使用，要想使用上面的功能，mesos 还需要编译了包含了对于 Nvidia GPU的支持 Support all attribute types with constraints新版中对非文本类型的属性提供了constraint支持 zookeeper digest authentication supportzk 客户端现在可以支持 zk 认证 和 acl了 Support for virtual networking for docker containers提供了Docker USER 网络的支持 CNI networking support增了ipAddress.Name的可选字段，可以使用CNI 网络来启动task Enforce the uniqueness of service portsmarathon 会保证所有新创建或者更新的app 的service端口是新的这个可能导致marathon原来使用的 app defintion 失效 若干的性能改进和缺陷修正 注明：文中如有理解偏差之处，欢迎指正。]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim问题 ValueError: Still no compile flags, no completions yet]]></title>
    <url>%2F2016%2F10%2F19%2FVim%E9%97%AE%E9%A2%98%20ValueError-%20Still%20no%20compile%20flags%20no%20completions%20yet%2F</url>
    <content type="text"><![CDATA[这个是因为ycm_extra_conf没有提供给YouCompleteMe编译标志，具体参见这个issue https://github.com/Valloric/YouCompleteMe/issues/700 解决方法： Set below in vimrc works fine. (设置对应的.ycm_extra_conf.py的路径) 1let g:ycm_global_ycm_extra_conf = '/root/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/.ycm_extra_conf.py']]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bootstrap-sortable 在零个row的情况下排序报错的问题]]></title>
    <url>%2F2016%2F10%2F19%2FBootstrap-sortable%20%E5%9C%A8%E9%9B%B6%E4%B8%AArow%E7%9A%84%E6%83%85%E5%86%B5%E4%B8%8B%E6%8E%92%E5%BA%8F%E6%8A%A5%E9%94%99%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[最近使用了 bootstrap-sortable，发现一个问题 1 Uncaught TypeError: Cannot read property 'appendChild' of undefined 这个问题是在表格没有数据的情况下报的错，调查发现是 Tinysort 的问题，https://github.com/Sjeiti/TinySort/issues/102注明：Tinysort 是一个对HTML元素进行排序的 javascript 脚本。 这个已经在 Tinysort 2.2.4中修订了，但是 bootstrap-sortable 因为长久没有及时的更新，导致同样的问题。 解决方法：在 bootstrap-sortable 项目没有更新 Tinysort 前，需要自己手动更新 Tinysort. 直接将对应版本的 Tinysort 代码更新，如https://github.com/Sjeiti/TinySort/blob/v2.2.4/dist/tinysort.jgz]]></content>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Install from Source - Mesos 集群]]></title>
    <url>%2F2016%2F09%2F12%2FInstall%20from%20Source%20-%20Mesos%20%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[安装build和运行环境依赖 12345678# Install the latest OpenJDK.$ sudo apt-get install -y openjdk-8-jdk# Install autotools (Only necessary if building from git repository).$ sudo apt-get install -y autoconf libtool# Install other Mesos dependencies.$ sudo apt-get -y install build-essential python-dev libcurl4-nss-dev libsasl2-dev libsasl2-modules maven libapr1-dev libsvn-dev zlib1g-dev 编译 mesos 1234567891011# Change working directory.$ cd mesos# Bootstrap (Only required if building from git repository).$ ./bootstrap# Configure and build.$ mkdir build$ cd build$ ../configure$ make 其中遇到的问题对于找不到jar的处理： http://www.linuser.com/thread-2057-1-1.html 生成运行框架（例子） 1234567891011# Run test suite.$ make check4. 运行mesos$ cd build# Start mesos master (Ensure work directory exists and has proper permissions).$ sudo ./bin/mesos-master.sh --ip=127.0.0.1 --work_dir=/var/lib/mesos# Start mesos agent (Ensure work directory exists and has proper permissions).$ sudo ./bin/mesos-agent.sh --master=127.0.0.1:5050 --work_dir=/var/lib/mesos 安装/运行 zookeeper 下载安装包 （其实这一步是不需要的，因为mesos的build 中集成了zookeeper，参见 https://mesosphere.com/blog/2013/08/01/distributed-fault-tolerant-framework-apache-mesos-html/其中的介绍， 可以直接进入 /build/3rdparty/zookeeper-3.4.*, 调到步骤2） 1wget http://apache.fayea.com/zookeeper/stable/zookeeper-3.4.9.tar.gz 创建 conf/zoo.cfg 123tickTime=2000dataDir=/var/lib/zookeeperclientPort=2181 启动zookeeper in standalone mode 1$ bin/zkServer.sh start 验证zookeeper 可以正常工作 1$ bin/zkCli.sh -server 127.0.0.1:2181 运行 help , ls / 命令等 对于安装zookeeper 后，mesos需要向zookeeper注册，所以原来的mesos 启动的命令需要修改如下： 12$ ./bin/mesos-master.sh --zk=zk://localhost:2181/mesos --work_dir=/var/lib/mesos --quorum=1$ ./bin/mesos-agent.sh --master=zk://localhost:2181/mesos --work_dir=/var/lib/mesos 应用docker containerizers，为了使用docker 容器化，我们需要使用 –containerizers=docker,mesos主要是 agent 启动参数修改，具体如下： 1sudo ./bin/mesos-agent.sh --master=zk://localhost:2181/mesos --work_dir=/var/lib/mesos --containerizers=docker,mesos 因为agent 修改了，启动时候可能报错，执行以下 sudo rm -rf /var/lib/mesos/meta/slaves/latest 就行了 安装/运行 marathon 安装有两种方式，一种是源码安装，另外一个是release tarball 安装 1234- option1：build from source https://github.com/mesosphere/marathon- option 2: tarball install wget http://downloads.mesosphere.com/marathon/v1.1.1/marathon-1.1.1.tgz 启动marathon 1$ sudo MESOS_NATIVE_JAVA_LIBRARY=/home/kennan/mesos-1.0.1/build/src/.libs/libmesos-1.0.1.so ./bin/start --master zk://localhost:2181/mesos --zk zk://localhost:2181/marathon 如果mesos没有注册到zookeeper 也就是 standalone mode 方式，比如 local 方式 或者 http://host:port ，命令如下： 1$ sudo MESOS_NATIVE_JAVA_LIBRARY=/home/kennan/mesos-1.0.1/build/src/.libs/libmesos-1.0.1.so ./bin/start --master local --zk zk://localhost:2181/marathon 使用Unified Containerizer为了减少对docker dameon的依赖，mesos引入了unified containerizer，通过对docker registry 的curl请求， 内部的isolators需要开启来支持对应的隔离。（取代docker的对于容器创建隔离的部分）。所以，为了使用这个功能，相应的agent运行的命令修改如下： 1sudo ./bin/mesos-agent.sh --master=zk://localhost:2181/mesos --work_dir=/var/lib/mesos --containerizers=mesos --image_providers=appc,docker --isolation=filesystem/linux,docker/runtime 测试： 123456/mesos-1.0.1/build/src$ sudo ./mesos-execute --master=localhost:5050 --name=test --docker_image=library/redis --shell=false$ sudo docker run -ti --net=host redis redis-cli127.0.0.1:6379&gt; pingPONG127.0.0.1:6379&gt; 比如，我们运行nginx，不在使用默认image里的entrypoint和cmd，而是这里自己制定： 1sudo ./mesos-execute --master=localhost:5050 --name=test2 --docker_image=library/nginx --shell=true --command="nginx -g 'daemon off;'" 访问 http://127.0.0.1/ 就可以看到nginx 页面了 更多参考资料： http://mesos.apache.org/documentation/latest/operational-guide/ mesos containerizershttp://mesos.apache.org/documentation/latest/containerizer/ zookeeper 介绍http://zookeeper.apache.org/doc/trunk/zookeeperStarted.html Unified Containerizerhttps://github.com/apache/mesos/blob/master/docs/container-image.md]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DC-OS 安装体验]]></title>
    <url>%2F2016%2F09%2F12%2FDC-OS%20%E5%AE%89%E8%A3%85%E4%BD%93%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[本文主要尝试如何快速的创建一个 DC/OS 的开发测试集群 安装virtualbox下载链接 https://www.virtualbox.org/wiki/Downloads根据不同的平台来安装不同的格式包，比如rpm下载pack： 1Oracle_VM_VirtualBox_Extension_Pack-5.0.26-108824.vbox-extpack 进行安装，点击安装 安装vagrant也是根据不同的平台来安装下载链接 https://www.vagrantup.com/downloads.html 注意 1,2步骤有坑的地方是，不同的版本组合会有问题，比如我安装的时候使用的1.8.4 最新的virtualbox 5.1.4vagrant是不能识别virtualbox provider的，具体错误是：No Usable default provider could be found for your system 这个是因为有滞后支持的现象的，所以在安装的时候，根据安装需求的时候需要&gt;=的版本跨度不要太大 clone dcos-agent repo 1git clone https://github.com/dcos/dcos-vagrant 安装 Vagrant Host Manager插件 1vagrant plugin install vagrant-hostmanager 下载DC/OS installer 1https://downloads.dcos.io/dcos/EarlyAccess/dcos_generate_config.sh?_ga=1.153462449.848392970.1471186149 这里是1.8.2版本 配置DC/OS installer 12export DCOS_GENERATE_CONFIG_PATH=dcos_generate_config.shexport DCOS_CONFIG_PATH=etc/config-1.8.yaml 配置DC/OS的机器类型 1cp VagrantConfig.yaml.example VagrantConfig.yaml 下载VM的基础镜像 1vagrant box add https://downloads.dcos.io/dcos-vagrant/metadata.json 但是这里我发现另外的机器下载很慢，于是进入链接，先下载镜像 https://downloads.dcos.io/dcos-vagrant/dcos-centos-virtualbox-0.7.0.box下载到路径 /root/dcos-centos-virtualbox-0.7.0.box 下面的格式修改如下： 12345678910111213141516171819&#123; "name": "mesosphere/dcos-centos-virtualbox", "description": "Base image on which to install Mesosphere DC/OS on VirtualBox", "versions": [ &#123; "version": "0.7.0", "status": "active", "description_markdown": "Enable IPv4 forwarding", "providers": [ &#123; "name": "virtualbox", "url": "/root/dcos-centos-virtualbox-0.7.0.box", "checksum_type": "sha1", "checksum": "fc9d5a6a99ecb70aee67d4b68b8b6a48563e57cb" &#125; ] &#125; ]&#125; 执行： 1vagrant box add metadata.json 可选的配置： Configure 认证，（默认安装是使用OAuth，支持Google，Github, or Microsoft）这个会在第一次登陆的时候提示认证，当然你也可以配置不同认证，参考 https://dcos.io/docs/1.7/administration/id-and-access-mgt/managing-authentication/#authentication-opt-out 部署集群 比如 vagrant up m1 a1 p1 boot 上面的对应的是：m1 master节点a1 agent private节点p1 agent public 节点boot boot节点 更多参考： https://github.com/dcos/dcos-vagrant/blob/master/VagrantConfig.yaml.example 扩展集群增加 agent node 12vagrant up a2vagrant up p2 减少节点 12vagrant destroy -f a1vagrant destroy -f p1 删除整个集群 1vagrant destroy -f 简单的测试集群工作， 创建一个nginx 的 job]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Selenium python UI Test]]></title>
    <url>%2F2016%2F08%2F14%2FSelenium%20python%20UI%20Test%2F</url>
    <content type="text"><![CDATA[python中如何容易的使用selenium来进行APP的测试，可以从如下考虑： Python中有个方便的库进行快速的集成和测试，py.test，pytest支持一系列的插件，其中就包含了 对于selenium的支持，使用方式如下： 1234def test_example(selenium): selenium.get('http://www.example.com')py.test --driver Firefox Selenium广泛使用的远程测试是使用Remote Driver，具体如下： 1 py.test --driver Remote --host selenium.hostname --port 5555 --capability browserName firefox 一般测试使用例子如下（远程测试）： 1py.test --base-url http://10.221.83.203:8081 --driver Remote --host 10.15.240.120 --capability browserName firefox 3.如果采用了marker方式，可以指定运行某类测试： 1py.test --base-url http://10.221.83.203:8081 --driver Remote --host 10.15.240.120 --capability browserName firefox -m negative 这里就只会运行 pytest.mark.negative 类型的测试 python中如何容易的使用selenium来进行APP的测试，可以从如下考虑： Python中有个方便的库进行快速的集成和测试，py.test，pytest支持一系列的插件，其中就包含了 对于selenium的支持，使用方式如下： 1234def test_example(selenium): selenium.get('http://www.example.com')py.test --driver Firefox Selenium广泛使用的远程测试是使用Remote Driver，具体如下： 1 py.test --driver Remote --host selenium.hostname --port 5555 --capability browserName firefox 一般测试使用例子如下（远程测试）： 1py.test --base-url http://10.221.83.203:8081 --driver Remote --host 10.15.240.120 --capability browserName firefox 3.如果采用了marker方式，可以指定运行某类测试： 1py.test --base-url http://10.221.83.203:8081 --driver Remote --host 10.15.240.120 --capability browserName firefox -m negative 这里就只会运行 pytest.mark.negative 类型的测试]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Selenium Headless Automated Testing]]></title>
    <url>%2F2016%2F08%2F14%2FSelenium%20Headless%20Automated%20Testing%2F</url>
    <content type="text"><![CDATA[关于ubuntu的介绍如下： http://www.installationpage.com/selenium/how-to-run-selenium-headless-firefox-in-ubuntu/ 如果使用的是yum源系统，安装如下的包： 1yum install xorg-x11-server-Xvfb.x86_64 然后执行如下，启动xvfb服务： 1Xvfb :10 -ac 在系统中以headless方式启动centos 12export DISPLAY=:10firefox 执行selenium测试：python code 如下： 1234567891011121314151617181920212223242526272829303132from selenium import webdriverfrom selenium.common.exceptions import TimeoutExceptionfrom selenium.webdriver.support.ui import WebDriverWait # available since 2.4.0from selenium.webdriver.support import expected_conditions as EC # available since 2.26.0# Create a new instance of the Firefox driverdriver = webdriver.Firefox()# go to the baidu home pagedriver.get("http://www.baidu.com")# the page is ajaxy so the title is originally this:print driver.title# find the element that's name attribute is q (the baidu search box)inputElement = driver.find_element_by_name("wd")# type in the searchinputElement.send_keys("cheese!")# submit the form (although baidu automatically searches now without submitting)inputElement.submit()try: # we have to wait for the page to refresh, the last thing that seems to be updated is the title WebDriverWait(driver, 10).until(EC.title_contains("cheese!")) # You should see "cheese! - baidu Search" print driver.titlefinally: driver.quit() 运行如下：百度一下，你就知道cheese!_百度搜索]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UTC的Datetime和ISO处理]]></title>
    <url>%2F2016%2F08%2F14%2FUTC%E7%9A%84Datetime%E5%92%8CISO%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[问题1， Django中集成了相应的函数来处理这种转化如下 参考 http://www.dannysite.com/blog/122/ 12345&gt;&gt;&gt; from django.utils.timezone import utc&gt;&gt;&gt; from django.utils.timezone import localtime&gt;&gt;&gt; now = datetime.datetime.utcnow().replace(tzinfo=utc)&gt;&gt;&gt; localtime(now)datetime.datetime(2013, 12, 5, 0, 3, 13, 122000, tzinfo= CST+8:00:00 STD&gt;) 问题2， 还有一种情况，对应的是ISO8601 字符串，要转化成对应的datetime对象一种是用iso8601包，但是这种情况下需要单独通过pip安装iso8601，参考：https://julien.danjou.info/blog/2015/python-and-timezones 12&gt;&gt;&gt; import iso8601&gt;&gt;&gt; iso8601.parse_date(utcnow().isoformat()) 还有一种方式是用传统的python的dateutil包：参考：http://stackoverflow.com/questions/969285/how-do-i-translate-a-iso-8601-datetime-string-into-a-python-datetime-object 12import dateutil.parseryourdate = dateutil.parser.parse(datestring) 如果本身不是字符串，而是对应的datetime对象，可以直接使用 https://docs.djangoproject.com/en/1.9/topics/i18n/timezones/localtime来处理 问题3， 如果需要特殊的处理，可以写custom的 template filter，具体如下：https://docs.djangoproject.com/en/1.8/howto/custom-template-tags/ 这种方式可以处理普通的template中无法处理的情况]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[USB数据恢复的几种方法]]></title>
    <url>%2F2016%2F07%2F06%2FUSB%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8D%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[这几天帮别人解决数据恢复的事情，USB盘文件无法识别，全都是乱码，无法识别目录，发现有一篇文章写得很好【1】当然还是靠那篇文章中强大的一款软件搞定，觉得特别有帮助。 参考资料： http://blog.sciencenet.cn/blog-781100-974887.html]]></content>
      <tags>
        <tag>WINDOWS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[youtube技术视频的下载方法]]></title>
    <url>%2F2016%2F07%2F06%2Fyoutube%E6%8A%80%E6%9C%AF%E8%A7%86%E9%A2%91%E7%9A%84%E4%B8%8B%E8%BD%BD%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[因为youtube有些技术视频非常好，有时候很需要下载到自己的手机上随时看，那么某乎上有些介绍如【1】网上也有些推荐如： 1) http://www.clipconverter.cc/2) http://en.savefrom.net/ 参考资料： https://www.zhihu.com/question/22247271]]></content>
      <tags>
        <tag>信息化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[exFAT格式的移动硬盘在Windows 7下无法写]]></title>
    <url>%2F2016%2F07%2F02%2FexFAT%E6%A0%BC%E5%BC%8F%E7%9A%84%E7%A7%BB%E5%8A%A8%E7%A1%AC%E7%9B%98%E5%9C%A8Windows%207%E4%B8%8B%E6%97%A0%E6%B3%95%E5%86%99%2F</url>
    <content type="text"><![CDATA[前段时间使用的Mac格式化的exFAT格式的移动硬盘，发现无法创建文件和删除文件，原来需要检查修复一下就可以了， 具体如下：管理员权限运行cmd，执行下面的命令即可： chkdsk 盘符 /F 参考: http://blog.chenxu.me/post/detail?id=1fa055ec-b46a-4437-a92f-a5d1596ad654]]></content>
      <tags>
        <tag>WINDOWS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编译内核及其Kernel Perf工具记录]]></title>
    <url>%2F2016%2F06%2F20%2F%E7%BC%96%E8%AF%91%E5%86%85%E6%A0%B8%E5%8F%8A%E5%85%B6Kernel%20Perf%E5%B7%A5%E5%85%B7%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[最近在尝试编译安装最新的4.6.1内核，遇到一些问题，记录如下: 编译内核的错误： Alert: /dev/disk/by-uuid/** does not exist 这个主要原因是相应的driver没有编译进内核导致。主要是相应的顺序错误, make install 是最后一步，不能在模块编译安装前运行。 1234567makemake modulesmake modules_installmake install 对应的perf tool对应的ubuntu安装包没有相应的内核的版本，需要自己编译步骤； 12345cd /usr/src/linux-4.6.1cd tools/perfmakemake install 参考资料: http://askubuntu.com/questions/50145/how-to-install-perf-monitoring-toolhttp://stackoverflow.com/questions/34473447/custom-linux-kernel-build-failure-in-vmware-workstationhttps://lkml.org/lkml/2016/5/3/3]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux, Windows, Mac之间的文件共享和迁移]]></title>
    <url>%2F2016%2F06%2F20%2FLinux%2C%20Windows%2C%20Mac%E4%B9%8B%E9%97%B4%E7%9A%84%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB%E5%92%8C%E8%BF%81%E7%A7%BB%2F</url>
    <content type="text"><![CDATA[最近在打算把原来Mac上面的一些资料迁移到我的Windows机器上，碰到了几个问题纪录一下： exfat， ntfs的问题 最初我打算是用我的移动硬盘作为载体，把Mac上的资料Copy到Windows上，问题来了，原来的移动硬盘格式是NTFS的，Mac下面，这种格式默认是只支持读，不可写，当然可以借助第三方工具做这个，但是会有相应的格式损坏的风险，所以打算从原生角度开展，exfat是一种windows visa开始支持的，但是我的Windows机器是XP，exfat的支持微软官方提供了相应的驱动。 windows Mac 文件之间传输的网络方式 从windows XP 访问Mac， 根据我的实验，即使在Mac上设置了共享和读写权限，以及保证和XP是同一个workgroup，还是无法访问，防火墙里也有对应的File sharing 允许规则，参看这个帖子：https://social.technet.microsoft.com/Forums/en-US/daea5819-f6fa-4273-9203-51051c12f4d5/-winxp-osx-?forum=windowsxpzhchs 网上微软论坛也没给出解决，估计问题比较难定位类似的参考link，具体没有时间细细研究： http://forums.macrumors.com/threads/windows-8-1-cant-access-share-on-mac-with-valid-credentials.1807636/http://forums.macrumors.com/threads/windows-7-can-see-but-not-access-os-x-share.1638263/ 从Mac访问windows XP比较简单，按照windows的共享目录的设置，然后打开Finder，Command+K打开，输入smb://,就可以访问了 Ubuntu Linux exfat挂载Ubuntu默认的是没有安装对应的exfat驱动，需要运行下面的命令安装驱动 1sudo apt-get install exfat-fuse exfat-utils 这里为什么提到Ubuntu的exfat，因为最后我采用的方式，是安装了一个Ubuntu16.04的虚拟机，然后安装了对应的exfat驱动支持，通过usb挂载方式，这样虚拟机就可以访问了移动硬盘了。接下来就需要通过虚拟机的共享目录方式(virtualbox 需要安装对应的增强功能，才能挂载对应的vboxsf文件类型)，实现虚拟机和windows XP主机的文件访问，从而可以将移动硬盘的资料拷贝到windows XP的目录中。 其他的云方案，暂时没有考虑，因为自己的需求比较简单，杀鸡不用牛刀。 参考资料： http://techmeasy.blogspot.com/2012/07/add-support-for-exFAT-in-Windows-XP.html http://www.liqi.name/windows-xp-7-mac-os-x-network-share/ http://askubuntu.com/questions/451364/how-to-enable-exfat-in-ubuntu-14-04]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kindle购买美国亚马逊的书籍]]></title>
    <url>%2F2016%2F05%2F29%2Fkindle%E8%B4%AD%E4%B9%B0%E7%BE%8E%E5%9B%BD%E4%BA%9A%E9%A9%AC%E9%80%8A%E7%9A%84%E4%B9%A6%E7%B1%8D%2F</url>
    <content type="text"><![CDATA[参考知乎上的链接 https://www.zhihu.com/question/23863224 主要步骤： 注册美亚账号 填写地址信息，如果使用中国地址，你是无法购买美亚的kindle书籍的 使用信用卡或者礼品卡（某tao网站） 下单，直接选择deliver方式，会发现kindle设备的书籍下载进度很慢，半天不动，可能和墙有些关系，所以直接使用通过电脑下载本地，然后USB连接kindle，copy到Documents目录中即可。]]></content>
      <tags>
        <tag>信息化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker网络 Bridge and none Mode使用]]></title>
    <url>%2F2016%2F05%2F28%2FDocker%E7%BD%91%E7%BB%9C%20Bridge%20and%20none%20Mode%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Docker默认的是三种网络类型，bridge，none，host其中bridge是典型的类似VM的linux-bridge网络 具体在每次运行docker run的时候，container都会从bridge对应的网络范围中选择一个空闲的ip，然后将其设置为对应容器的eth0的ip。Docker bridge的网络ip设置对应每个容器的默认网关，提供给容器来访问外部的网络。 因为docker自己操作的容器网络名字空间并不是放在/var/run/netns中，所以ip netns无法直接查看，可以通过以下的方式来访问： 下面的过程是对none类型的容器进行网络配置的例子： 123456789101112131415161718192021222324252627$ docker inspect -f '&#123;&#123;.State.Pid&#125;&#125;' 63f36fc01b5f2778$ pid=2778$ sudo mkdir -p /var/run/netns$ sudo ln -s /proc/$pid/ns/net /var/run/netns/$pid$ ip addr show docker021: docker0: ...inet 172.17.42.1/16 scope global docker0...# Create a pair of "peer" interfaces A and B,# bind the A end to the bridge, and bring it up$ sudo ip link add A type veth peer name B$ sudo brctl addif docker0 A$ sudo ip link set A up# Place B inside the container's network namespace,# rename to eth0, and activate it with a free IP$ sudo ip link set B netns $pid$ sudo ip netns exec $pid ip link set dev B name eth0$ sudo ip netns exec $pid ip link set eth0 address 12:34:56:78:9a:bc$ sudo ip netns exec $pid ip link set eth0 up$ sudo ip netns exec $pid ip addr add 172.17.42.99/16 dev eth0$ sudo ip netns exec $pid ip route add default via 172.17.42.1]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[借助Hexo建立Github上的网站]]></title>
    <url>%2F2016%2F04%2F29%2F%E5%80%9F%E5%8A%A9Hexo%E5%BB%BA%E7%AB%8BGithub%E4%B8%8A%E7%9A%84%E7%BD%91%E7%AB%99%2F</url>
    <content type="text"><![CDATA[上一篇Hexo中，我们介绍了它是一个简单提供了快速搭建静态博客系统的软件，那么我们就想借助它来实现可以建立一个公开可访问博客网站，问题来了，如果没有自己的域名服务器，怎么实现这个要求？ 有人想到了使用公有云的虚拟机，但是域名购买还是需要的，使用ip访问？这个显然不太方便让外面用户访问，这时我们想到了github pages。 Github提供了github pages功能，借助它可以方便的实现个人博客的在线系统。 那具体操作如下：（下面的操作都是在上一篇启动的Hexo容器中操作） 建立一个公共的repository， username.github.io git clone到本地，cd 到相应的目录，建立一个新的分支，这里我们使用的名字是source，下面所有的操作都是source分支 执行hexo init初始化，生成相应的博客系统配置文件 执行 npm install安装相应的nodejs包 执行 npm install hexo-deployer-git –save，这一步配置完成hexo git deploy插件的安装 配置相应的git deploy 部署参数： 123456# Deployment## Docs: http://hexo.io/docs/deployment.htmldeploy: type: git repo: https://github.com/username/username.github.io.git branch: master 然后在source文件夹写博客 返回到主目录，执行hexo g，产生相应的博客网站需要的文件 执行hexo deploy 部署博客网站 访问 http://username.github.io/， 就是部署后的网站了。 这里借助github.io的repository就方便的实现了博客源文件管理（source分支）和快速部署（master分支）的需求，而且借助github pages实现了在线博客的运行。 参考： https://pages.github.com/ https://github.com/hexojs/hexo]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ghost和Hexo博客系统的体验]]></title>
    <url>%2F2016%2F04%2F19%2FGhost%E5%92%8CHexo%E5%8D%9A%E5%AE%A2%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%BD%93%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[一直打算部署博客系统，比较了流行的WP, Ghost, Hexo and Pelican 网上先调研了一番，发现有两篇文章比较有参考价值：一个是个人的实践 http://www.maintao.com/2014/hexo-beginner%27s-guide/另外一个是知乎的 http://www.zhihu.com/question/21981094 综合比较下来，发现还是这个Hexo满足我的最简单最小化静态博客需求，但是既然借助容器体验非常方便，那么我就也顺便体验了ghost一番 Hexo使用： 1.安装Hexo 1 docker run --name hexo -it -p 8083:80 -v `pwd`: /usr/share/nginx/html/source simplyintricate/hexo 发布一篇blog 1docker exec -it hexo hexo new "This is one post" Ghost使用 1docker run --name some-ghost -p 8085:2368 -d ghost 直接操作UI就行了，Ghost相对UI比较好，操作简单，但是依赖数据库存储，而且现有的API发布一篇markdown文档不简单 Hexo简单，UI稍微逊色，不依赖数据库，原始文档即博客数据（存在固定的文件夹下），非常方便，发布新的博客，需要重启容器，这点网上也介绍有第三方工具，实现动态更新，还没有研究。]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[static binary 安装docker遇到Devices cgroup is not mounted]]></title>
    <url>%2F2016%2F03%2F25%2Fstatic%20binary%20%E5%AE%89%E8%A3%85docker%E9%81%87%E5%88%B0Devices%20cgroup%20isn't%20mounted%2F</url>
    <content type="text"><![CDATA[实验环境： ubuntu 14.04docker 版本： 1.10.3kernel： 3.13.** 如果采用binary docker的使用方式https://github.com/docker/docker/blob/master/docs/installation/binaries.md 你会发现docker启动，报错 Devices cgroup isn&#39;t mounted 这个是因为默认的cgroup的cpu，memory等没有被挂载，需要使用一个脚本来挂载，具体使用脚本是https://github.com/tianon/cgroupfs-mount/blob/master/cgroupfs-mount 执行完上面的脚本后，然后就可以运行docker就不会报cgroup的错误了。 这个问题解决了，但是会遇到另外一个 1AppArmor enabled on system but the docker-default profile could not be loaded， 这个正在跟踪docker官方的issue，后面调查结果会随后更新]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Docker进行天气预报]]></title>
    <url>%2F2016%2F03%2F15%2F%E4%BD%BF%E7%94%A8Docker%E8%BF%9B%E8%A1%8C%E5%A4%A9%E6%B0%94%E9%A2%84%E6%8A%A5%2F</url>
    <content type="text"><![CDATA[Docker的容器化带来的一个好处是可以方便的尝试各种app的快速部署和体验，github上有一个有趣的天气预报app，https://github.com/schachmat/wego 步骤如下： 部署一个支持golang运行环境的容器docker run –rm -it golang bash 安装wego运行wego，第一次安装的时候会生成一个配置文件，~/.wegorc其中需要配置一个key，这个key是可以支持调用worldweatheronline.com网站的API，你需要到对应的网站免费注册，获得相应的免费API key，配置到上面的这个文件中。 配置城市city=Beijing 再次运行wego， 就获得了结果]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多窗口下的VIM常用的快捷键和操作]]></title>
    <url>%2F2016%2F02%2F02%2F%E5%A4%9A%E7%AA%97%E5%8F%A3%E4%B8%8B%E7%9A%84VIM%E5%B8%B8%E7%94%A8%E7%9A%84%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%92%8C%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[split vsplit 窗口分割 Ctrl +w + 窗口的上下左右调整 窗口的调整大小 123:res +5:vertical resize +5]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker btrfs的实践]]></title>
    <url>%2F2016%2F02%2F02%2FDocker%20btrfs%E7%9A%84%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[使用OpenStack部署的虚拟机，其中只有一块盘，但是docker的btrfs需要一个单独的设备，如果OpenStack没有Cinder服务，还要手动加盘，实在有点麻烦，作为实验来说有点不便。那么怎么绕过去呢，很简单，使用全能的loop device，具体如下: 创建一个空的image文件(9.6G） 1dd if=/dev/zero of=btrfs.img bs=512 count=20000000 建立loop，操作来为mount准备 1losetup /dev/loop0 btrfs.img 安装btrfs tools 1sudo apt-get install btrfs-tools 创建btrfs存储池 1sudo mkfs.btrfs -f /dev/loop0 创建docker使用的文件目录 1sudo mkdir -p /var/lib/docker 获取btrfs文件系统的UUID 1sudo blkid /dev/loop 创建对应的/etc/fstab项目，使得可以系统启动时可以自动挂载 12/dev/loop0 /var/lib/docker btrfs defaults 0 0UUID="b18ea60f-5cad-4b3d-8769-a2da818fdedb" /var/lib/docker btrfs defaults 0 0 挂载上面的新的文件系统 1sudo mount -a 重启docker 1sudo service docker start 这样就完成btrfs storage driver配置完成。 后面我们想做一个实验，想获取btrfs文件的Magic Number : 9123683e 123docker run --rm -it -v "$PWD":/usr/src/mygo -w /usr/src/mygo -v /var/lib/docker:/var/lib/docker golang bashexport GOPATH=$GOPATH:/usr 12345678910111213141516171819202122// mygo/main.gopackage mainimport ( "fmt" "log" "os" "syscall") func main() &#123; log.Printf("Args are :%s ", os.Args) var stat syscall.Statfs_t if err := syscall.Statfs("/var/lib/docker", &amp;stat); err != nil &#123; log.Fatalf("Stat error\n") &#125; fmt.Printf("The type is %x\n", uint32(stat.Type))&#125; // 在容器中运行程序，可以得到结果:2016/02/02 13:38:46 Args are :[mygo]The type is 9123683e 参考资料: http://wiki.osdev.org/Loopback_Devicehttps://www.howtoforge.com/a-beginners-guide-to-btrfshttps://github.com/docker/docker/blob/master/docs/userguide/storagedriver/btrfs-driver.md]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2016容器大会分享资料]]></title>
    <url>%2F2016%2F01%2F25%2F2016%E5%AE%B9%E5%99%A8%E5%A4%A7%E4%BC%9A%E5%88%86%E4%BA%AB%E8%B5%84%E6%96%99%2F</url>
    <content type="text"><![CDATA[在昨天这么严寒的北京日子，聚集了一帮对容器感兴趣的程序员和运维开发人员，大会还是有不少公司分享的干货的，大家可以下载大会的ppt，从中学习一些docker的实践案例。 下载地址： http://pan.baidu.com/s/1i4nN2Qh]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim Plugin 推荐]]></title>
    <url>%2F2015%2F12%2F30%2FVim%20Plugin%20%E6%8E%A8%E8%8D%90%2F</url>
    <content type="text"><![CDATA[前段时间使用vim作为Go的开发编辑环境，顺便使用了几个不错的plugin，值得推荐一下： Vim的强大之处，在于丰富的plugin生态，使用plugin必然缺不了plugin的管理器Vim plugin manager：Vundle， Neobundle 等 neocomplete 关键字补全 go development vim plugin vim-go vim-go 依赖其他的组件实现更加强大的类IDE功能 其中包括neocomplete，tagbar， tagbar 视图功能 molokai 色彩主题 nerdtree 代码目录树视图 unite 高级文件查找和显示 the_platinum_searcher 高级代码查找工具， 可以配合unite使用 综上使用，可以帮助你快速的go代码开发和阅读 参考： https://github.com/VundleVim/Vundle.vim https://github.com/Shougo/neobundle.vim https://github.com/Shougo/neocomplete.vim https://github.com/fatih/vim-go https://github.com/majutsushi/tagbar https://github.com/fatih/molokai https://github.com/scrooloose/nerdtree https://github.com/Shougo/unite.vim https://github.com/monochromegane/the_platinum_searcher]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建proxy server的尝试]]></title>
    <url>%2F2015%2F12%2F01%2F%E6%90%AD%E5%BB%BAproxy%20server%E7%9A%84%E5%B0%9D%E8%AF%95%2F</url>
    <content type="text"><![CDATA[在ubuntu下搭建一个代理服务器比较简单，ubuntu下有个squid3用的比较广泛，简单的几个步骤可以搞定。 具体实践如下: 安装 1sudo apt-get install squid3 配置 12sudo cp /etc/squid3/squid.conf /etc/squid3/squid.conf.originalsudo chmod a-w /etc/squid3/squid.conf.original sudo vim /etc/squid3/squid.conf 123456acl src ## INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS#http_access allow sudo service squid3 restart 如果启动了ufw，需要保证对应的proxy端口打开。比如你的squid设置的 12# Squid normally listens to port 8888http_port 8888 123sudo ufw allow 8888/tcpsudo ufw status 参考资料： https://help.ubuntu.com/lts/serverguide/squid.htmlhttp://www.tecmint.com/install-squid-in-ubuntu/]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[借助方便的autocutsel完成windows7和Linux之间copy-paste]]></title>
    <url>%2F2015%2F12%2F01%2F%E5%80%9F%E5%8A%A9%E6%96%B9%E4%BE%BF%E7%9A%84autocutsel%E5%AE%8C%E6%88%90windows7%E5%92%8CLinux%E4%B9%8B%E9%97%B4copy-paste%2F</url>
    <content type="text"><![CDATA[要解决的问题:有一台windows7 安装了tightvncviewer。有一个远程的Linux xfce4桌面系统。通过vncviewer来远程连接Linux桌面。因为会交互在两个系统之间操作，所以两个系统之间的copy paste是一个显而易见的需求。 曾经使用过的xcutsel似乎力不从心，发现autocutsel这个工具很好用。使用: 1sudo apt-get install autocutsel 然后就在Linux终端启动 autocutsel，这样就可以无障碍的copy paste操作了。]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HexChat Install Error "Download failed"]]></title>
    <url>%2F2015%2F11%2F30%2FHexChat%20Install%20Download%20failed%20error%2F</url>
    <content type="text"><![CDATA[HexChat是一个IRC客户端，类似XChat， 试用了一下，发现简单的安装失败，提示不能下载文件， 其实这是一个bug， https://github.com/hexchat/hexchat/issues/1264 这个问题的解决方法就是你需要手动下载 vcredist，下载链接是 https://dl.hexchat.net/misc/]]></content>
      <tags>
        <tag>WINDOWS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[借助docker log调试docker 启动timeout问题]]></title>
    <url>%2F2015%2F11%2F14%2F%E5%80%9F%E5%8A%A9docker%20log%E8%B0%83%E8%AF%95docker%20%E5%90%AF%E5%8A%A8timeout%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[我们在使用docker的过程，经常有需求要调试docker的问题，所以需要了解对应log的目录: 123456* Ubuntu - /var/log/upstart/docker.log* Boot2Docker - /var/log/docker.log* Debian GNU/Linux - /var/log/daemon.log* CentOS - /var/log/daemon.log | grep docker* Fedora - journalctl -u docker.service* Red Hat Enterprise Linux Server - /var/log/messages | grep docker 比如前几天调试docker的时候，发现docker的服务总是启动超时， 1docker.service operation timed out. Terminating. 根据log仔细排查后，发现原来docker启动过程，加入的docker-storage在初始化过程中(第一次启动过程)会比较慢， 然后修改了systemd docker服务的配置 12[Service]TimeoutStartSec=0 配置TimeoutStartSec关闭timeout限制，这样docker服务就能正常启动了。所用的时间计算了一下，发现是3~4mins，估计是因为嵌套虚拟机再启动docker的性能问题，如果裸机上的虚拟机启动docker 似乎很少遇到这种情况。 参考: http://stackoverflow.com/questions/30969435/where-is-the-docker-daemon-loghttp://container-solutions.com/running-docker-containers-with-systemd/]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Openstack neutron hit unreachable - admin prohibited问题]]></title>
    <url>%2F2015%2F11%2F13%2F%E8%A7%A3%E5%86%B3Openstack%20neutron%20hit%20unreachable%20-%20admin%20prohibited%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[使用了Redhat 7.1 搭建的devstack环境发现boot的instance无法ping通主机的public ip，后来通过抓包发现原来是类似的一个问题: https://lists.launchpad.net/openstack/msg25392.html 只需要把防火墙下面的规则去掉就行了 12-A INPUT -j REJECT --reject-with icmp-host-prohibited-A FORWARD -j REJECT --reject-with icmp-host-prohibited]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go Debugger Setup]]></title>
    <url>%2F2015%2F10%2F08%2FGo%20Debugger%20Setup%2F</url>
    <content type="text"><![CDATA[Go官方没有指定的debugger， gdb因为不能很好的调试go程序，gdb对go的支持已经不再维护，参见 123GDB does not understand Go programs well. The stack management, threading, and runtime contain aspects that differ enough from the execution model GDB expects that they can confuse the debugger, even when the program is compiled with gccgo. As a consequence, although GDB can be useful in some situations, it is not a reliable debugger for Go programs, particularly heavily concurrent ones. Moreover, it is not a priority for the Go project to address these issues, which are difficult. In short, the instructions below should be taken only as a guide to how to use GDB when it works, not as a guarantee of success.In time, a more Go-centric debugging architecture may be required. IRC问了一个go developer， 推荐 delve 或者使用fmt.Println()下面尝试使用delve， Go Env 安装 确保你本地的环境已经安装了Go并且配置GOPATH，参见上一篇我的Go Env Setup Delve 安装 1234567$ git clone https://github.com/derekparker/delve.git $GOPATH/src/github.com/derekparker/delve$ go get github.com/peterh/liner$ go get github.com/spf13/cobra$ go get golang.org/x/sys/unix$ go get gopkg.in/yaml.v2 上面的get命令是安装相应的package。这事因为在make install的会报错，提示上面的package找不到 1$ make install 调试Go程序 1234567891011121314151617181920212223$ dlv exec hello(dlv) break hello.go:6(dlv) continue&gt; main.main() ./hello.go:6 1: package main 2: 3: import "fmt" 4: 5: func main() &#123;=&gt; 6: i := 12 7: j := 13 8: t := i + j 9: fmt.Printf("hello, world\n") 10: fmt.Println(i, j, t) 11: &#125;(dlv) n(dlv) print i1 参考： https://github.com/derekparker/delve/wiki/Building https://golang.org/doc/gdb http://geekmonkey.org/2012/09/comparison-of-ides-for-google-go/ https://github.com/derekparker/delve/wiki/Building]]></content>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go language Env Setup]]></title>
    <url>%2F2015%2F10%2F08%2FGo%20language%20Env%20Setup%2F</url>
    <content type="text"><![CDATA[下面的文章内容基于ubuntu 14.04 实验因为ubuntu 默认的apt-get 安装的golang是1.1 版本，太低了，所以需要自己通过binary或者source安装。对于ubuntu 14.04 go 官方提供了合适的binary包，所以直接使用binary 安装 binary 安装比较简单如下 下载合适的binary包 1https://golang.org/dl/ 我的ubuntu系统对应的包是go1.5.1.linux-amd64.tar.gz 安装 1sudo tar -C /usr/local -xzf go1.5.1.linux-amd64.tar.gz 设置PATH和GOPATH 1vim $HOME/.profile 添加如下的内容： 12export GOPATH=$HOME/workexport PATH=$PATH:/usr/local/go/bin:$GOPATH/bin 测试 12345678910111213141516171819202122$ cd $GOPATH$ mkdir -p src/github.com/user/hello$ cd src/github.com/user/hello$ vim hello.go//--------------package mainimport "fmt"func main() &#123; fmt.Printf("hello, world\n")&#125;//------------$ go install github.com/user/hello$ $GOPATH/bin/hellohello, world 参考： https://golang.org/doc/install https://golang.org/doc/code.html]]></content>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言编程的基本学习]]></title>
    <url>%2F2015%2F10%2F07%2FGo%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A8%8B%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[指针： Go 没有指针运算，不同于C 数组： Go’s arrays are values. An array variable denotes the entire array; it is not a pointer to the first array element (as would be the case in C). This means that when you assign or pass around an array value you will make a copy of its contents. (To avoid the copy you could pass a pointer to the array, but then that’s a pointer to an array, not an array.) One way to think about arrays is as a sort of struct but with indexed rather than named fields: a fixed-size composite value. Slice: ［1］指向一个序列的值，并且包含了长度信息。 使用make函数创建A slice is a descriptor of an array segment. It consists of a pointer to the array, the length of the segment, and its capacity (the maximum length of the segment). As we slice s, observe the changes in the slice data structure and their relation to the underlying array:s = s[2:4] Range： 对于Slice和Map的for 迭代循环可使用range，可以通过_来忽略序号或者值 1234567pow := make([]int, 10)for i := range pow &#123; pow[i] = 1 &lt;&lt; uint(i)&#125;for _, value := range pow &#123; fmt.Printf("%d\n", value)&#125; Map： （待加） 闭包： Go中函数也是值，也有闭包，这个在python中比较普遍。Go例子如下 12345678func fibonacci() func() int &#123; a := 0 b := 1 return func() int &#123; a , b = b, a + b return a &#125;&#125; 方法：Go中没有类，但是可以对结构体定义方法比如： 1234567type Vertex struct &#123; X, Y float64&#125;func (v *Vertex) Abs() float64 &#123; return math.Sqrt(v.X*v.X + v.Y*v.Y)&#125; 也可以对其他类型定义方法（除了基本类型和其他包的类型） 方法中使用指针接受者，是基于［4］： 1There are two reasons to use a pointer receiver. First, to avoid copying the value on each method call (more efficient if the value type is a large struct). Second, so that the method can modify the value that its receiver points to. 关于method receiver的使用pointer还是value的问题解答［3］： 12345678910111213141516Should I define methods on values or pointers?func (s *MyStruct) pointerMethod() &#123; &#125; // method on pointerfunc (s MyStruct) valueMethod() &#123; &#125; // method on valueFor programmers unaccustomed to pointers, the distinction between these two examples can be confusing, but the situation is actually very simple. When defining a method on a type, the receiver (s in the above examples) behaves exactly as if it were an argument to the method. Whether to define the receiver as a value or as a pointer is the same question, then, as whether a function argument should be a value or a pointer. There are several considerations.First, and most important, does the method need to modify the receiver? If it does, the receiver must be a pointer. (Slices and maps act as references, so their story is a little more subtle, but for instance to change the length of a slice in a method the receiver must still be a pointer.) In the examples above, if pointerMethod modifies the fields of s, the caller will see those changes, but valueMethod is called with a copy of the caller's argument (that's the definition of passing a value), so changes it makes will be invisible to the caller.By the way, pointer receivers are identical to the situation in Java, although in Java the pointers are hidden under the covers; it's Go's value receivers that are unusual.Second is the consideration of efficiency. If the receiver is large, a big struct for instance, it will be much cheaper to use a pointer receiver.Next is consistency. If some of the methods of the type must have pointer receivers, the rest should too, so the method set is consistent regardless of how the type is used. See the section on method sets for details.For types such as basic types, slices, and small structs, a value receiver is very cheap so unless the semantics of the method requires a pointer, a value receiver is efficient and clear. 接口： Go中的接口是一组方法定义的集合 12345678910111213141516171819202122GoroutinesA goroutine is a lightweight thread managed by the Go runtime.go f(x, y, z)starts a new goroutine runningf(x, y, z)The evaluation of f, x, y, and z happens in the current goroutine and the execution of f happens in the new goroutine.ChannelsChannels are a typed conduit through which you can send and receive values with the channel operator, &lt;-.ch &lt;- v // Send v to channel ch.v := &lt;-ch // Receive from ch, and // assign value to v.Buffered ChannelsChannels can be buffered. Provide the buffer length as the second argument to make to initialize a buffered channel:ch := make(chan int, 100) 参考： http://blog.golang.org/go-slices-usage-and-internals http://nathanleclaire.com/blog/2014/08/09/dont-get-bitten-by-pointer-vs-non-pointer-method-receivers-in-golang/ https://golang.org/doc/faq https://tour.golang.org/]]></content>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenStack Kolla Project的实践-安装环境]]></title>
    <url>%2F2015%2F08%2F31%2FOpenStack%20Kolla%20Project%E7%9A%84%E5%AE%9E%E8%B7%B5-%E5%AE%89%E8%A3%85%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[OpenStack Kolla项目是一个支持Openstack的服务以容器的方式部署，借助ansible部署工具可以简单的扩展到多个节点体验Kolla项目的第一步是搭建一个简单的开发环境，环境搭建的all-in-one参考官方的github 如下 https://github.com/stackforge/kolla/blob/master/docs/dev-quickstart.rst 其中比较trick的地方需要注意不同操作系统对于kernel的需求，支持的版本等。我们以ubuntu 14.04为例，因为kernel的版本编译问题，aufs是不被3.13 kernel支持的，如果使用aufs，需要确保kernel升到3.19以上。还有一种方法是让docker使用btrfs。 我们这里谈谈方案1， 升级kernel： 升级kernel 1apt-get install linux-image-generic-lts-vivid 下载Kolla代码，pip安装 123git clone http://github.com/stackforge/kollacd kollasudo pip install -r requirements.txt 安装Docker 1curl -sSL https://get.docker.io | bash 安装Openstack client需要的一些包 1sudo apt-get install -y python-dev python-pip libffi-dev libssl-dev 安装OpenStack client 1sudo pip install -U python-openstackclient 禁止本机的libvirt启动， 如果以前没有安装，可以跳过这一步 12service libvirtd disableservice libvirtd stop 安装Ansible （或者使用pip方式） 1234sudo apt-get install software-properties-commonsudo apt-add-repository ppa:ansible/ansiblesudo apt-get updatesudo apt-get install ansible 本地Build Image， 因为远程的pull image 速度太慢 而且 Kolla 社区不是每个commit修改都把image build一遍，所以本地build image是开发最好的选择。我们使用source方式build， binary方式似乎不稳定，容易出错 1tools/build.py --base ubuntu --type source --template -T 35 部署容器 1ansible-playbook -i inventory/all-in-one -e @/etc/kolla/globals.yml -e @/etc/kolla/passwords.yml site.yml 使用docker ps 可以查看对应openstack 所有服务的容器，使用命令行一样简单的部署虚拟机，只不过我们的openstack服务都运行在容器中了，呵呵。]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chef 如何动态获取kernel版本进行yum安装]]></title>
    <url>%2F2015%2F07%2F29%2FChef%20%E5%A6%82%E4%BD%95%E5%8A%A8%E6%80%81%E8%8E%B7%E5%8F%96kernel%E7%89%88%E6%9C%AC%E8%BF%9B%E8%A1%8Cyum%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[我们使用redhat的时候，有时候对配置节点需要安装指定版本的kernel-devel，但是这个版本是动态获取的，不是hardcode的，这就出现一个简单的问题，如何编码？ Chef有Package resource可以做这个事情，package需要至少两个属性，package 的名字和版本，如果不指定版本，就按照yum repo安装最新的。可是我们对版本有要求，所以必须指定version。 其实kernel的版本多和node的属性有关系， [2]给出了一个解决方法，但是发现在我的chef-server下，那样编码不对。 需要这样做： 12345678kernel_release = node['kernel']['release']kernel_version = kernel_release.sub(".#&#123;node['kernel']['machine']&#125;", '')package 'kernel-devel' do version kernel_version action :installend 参考文献: [1] https://docs.chef.io/resource_package.html[2] http://lists.opscode.com/sympa/arc/chef/2015-03/msg00295.html]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NTP: no server suitable for synchronization found]]></title>
    <url>%2F2015%2F07%2F24%2FNTP-%20no%20server%20suitable%20for%20synchronization%20found%2F</url>
    <content type="text"><![CDATA[Ntp Server 在Redhat 7配置后，发现client 1ntpdate -u &lt;serverip&gt; 报错： no server suitable for synchronization found 检查排错后，原来是firewall的问题， 在NTP server 配置防火墙 12iptables -I INPUT -p udp --dport 123 -j ACCEPTiptables -I OUTPUT -p udp --sport 123 -j ACCEPT 这样就可以了，注意-I, 不是-A确保你的CHAIN最后一条不是Reject，因为-A是在最后添加一条新的规则。]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux Shell Escaping a dollar In cat command]]></title>
    <url>%2F2015%2F07%2F24%2FLinux%20Shell%20Escaping%20a%20dollar%20In%20cat%20command%2F</url>
    <content type="text"><![CDATA[发现社区一个脚本执行后，cat命令写入后文件里面的表达式都求值展看了，其实这个是因为$的缘故，参看这个 http://stackoverflow.com/questions/21984960/escaping-a-dollar-sign-in-unix-inside-the-cat-command 12345678910111213You can use regular quoting operators in a here document:$ cat &lt;&lt;HERE&gt; foo(\$bar)&gt; HEREfoo($bar) or you can disable expansion by quoting the here-doc delimiter:$ cat &lt;&lt;'HERE' # note single quotes&gt; foo($bar)&gt; HEREfoo($bar)]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redhat resolv.conf changes disappear!]]></title>
    <url>%2F2015%2F07%2F20%2FRedhat%20resolv.conf%20changes%20disappear!%2F</url>
    <content type="text"><![CDATA[最近使用redhat 7.1 系统，改过resolv.conf，总是发现文件修改完，重启系统，文件又变成没有修改之前的状态了。 原来查出是NetworkManager在作怪。 http://totalcae.com/blog/2013/06/prevent-etcresolv-conf-from-being-blown-away-by-rhelcentos-after-customizing/]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenStack unit测试运行tox错误： ValueError: ("Expected , or end-of-list in"]]></title>
    <url>%2F2015%2F07%2F17%2FOpenStack%20unit%E6%B5%8B%E8%AF%95%E8%BF%90%E8%A1%8Ctox%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[今天pull到最新的代码，发现错误， 1ValueError: ("Expected ',' or end-of-list in", "mock&gt;=1.1;python_version!='2.6'", 'at', ";python_version!='2.6'") 后来找到 https://bugs.launchpad.net/devstack/+bug/1468808 原来是对应的virtualenv版本太低导致，解决方法就是升级virtualenv 1pip install -U virtualenv]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenStack Swift Selinux, Permission denied]]></title>
    <url>%2F2015%2F06%2F16%2FOpenStack%20Swift%20Selinux%2C%20Permission%20denied%2F</url>
    <content type="text"><![CDATA[如果参考社区的文档，在Redhat7.1系统上安装swift，会发现陷入到无穷无尽的 1can not access directory or file, Permission Denied 什么原因呢，实际上是selinux context导致的权限问题。 这个是社区的文档http://docs.openstack.org/kilo/install-guide/install/yum/content/swift-install-storage-node.html Step6 中， 12Ensure proper ownership of the mount point directory structure:# chown -R swift:swift /srv/node 实际上这样的权限是 12#ls -Z /srv/nodedrwxr-xr-x. swift swift system_u:object_r:unlabeled_t:s0 sdb1 需要执行： 1#restorecon -R /srv/node 然后再查看： 12#ls -Z /srv/nodedrwxr-xr-x. swift swift system_u:object_r:swift_data_t:s0 sdb1 这样就不会出现问题了，对于/var/cache/swift 同样适用 下面我做了另外一个实验，不使用本地的实际硬盘，创建一个loop device，使用xfs进行格式化。然后挂载来作为swift的back storage。关于如何开机自动挂载loop device可以参考【3】 比如， 1xfs loop,noatime,nodiratime,nobarrier,logbufs=8 0 0 测试发现，如果 的前缀path是/srv/node 开始的，这样是没有问题的，但是如果换做其他的path，比如/etc/swift，就会出现Permission Denied问题（restorecon 无法解决） 据cschwede说，everything under /srv and /var/run/swift should work我没有测试/var/run/swift，但是/etc/swift是有问题的，后来ho建议了一个增加mount option的方法， 1xfs loop,noatime,nodiratime,nobarrier,logbufs=8,context=system_u:object_r:swift_data_t:s0 0 0 这样就解决问题了。 感谢：swift社区的ho(IRC nickname)的热情帮助解决问题。 参考文献： https://ask.openstack.org/en/question/60539/swift-juno-permission-denied-error/ http://wiki.centos.org/HowTos/SELinux http://itekblog.com/mount-iso-using-fstab/]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 14.04 pip package bug (ImportError: cannot import name IncompleteRead)]]></title>
    <url>%2F2015%2F05%2F18%2FUbuntu%20pip%20package%20bug-%20ImportError%20cannot%20import%20name%2F</url>
    <content type="text"><![CDATA[ubuntu 14.04 默认安装的pip package有个bug，运行pip 出现 12345678910111213141516Traceback (most recent call last): File "/usr/bin/pip", line 9, in load_entry_point('pip==1.5.4', 'console_scripts', 'pip')() File "/usr/lib/python2.7/dist-packages/pkg_resources.py", line 351, in load_entry_point return get_distribution(dist).load_entry_point(group, name) File "/usr/lib/python2.7/dist-packages/pkg_resources.py", line 2363, in load_entry_point return ep.load() File "/usr/lib/python2.7/dist-packages/pkg_resources.py", line 2088, in load entry = __import__(self.module_name, globals(),globals(), ['__name__']) File "/usr/lib/python2.7/dist-packages/pip/__init__.py", line 61, in from pip.vcs import git, mercurial, subversion, bazaar # noqa File "/usr/lib/python2.7/dist-packages/pip/vcs/mercurial.py", line 9, in from pip.download import path_to_url File "/usr/lib/python2.7/dist-packages/pip/download.py", line 25, in from requests.compat import IncompleteReadImportError: cannot import name IncompleteRead http://flexget.com/wiki/PipProblemshttp://stackoverflow.com/questions/27341064/how-do-i-fix-importerror-cannot-import-name-incompleteread 都提到了这个问题，简单fix的方法，就是升级pip版本]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker build image issue for fatal error: ffi.h: No such file or directory]]></title>
    <url>%2F2015%2F05%2F18%2FDocker%20build%20image%20ffi%20file%20issue%2F</url>
    <content type="text"><![CDATA[如果使用base的Ubuntu 14.04的image，会发现在在安装python的cryptography package,会报错， 12345 fatal error: ffi.h: No such file or directory #include ^ compilation terminated....distutils` 根据， http://www.123code.blogspot.com/2014/10/fixed-installing-python-cryptography.html,需要安装两个 libssl-dev libffi-dev包]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个简单的在线运行代码web实现]]></title>
    <url>%2F2015%2F05%2F05%2F%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E5%9C%A8%E7%BA%BF%E8%BF%90%E8%A1%8C%E4%BB%A3%E7%A0%81web%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[前几天想实验一个在线运行code的web实现，在github商店找到一个简单的事例，clone如下， https://github.com/HackToday/codelauncher 实际上，这个项目最初的实现支持包括c和python，使用Flask Web框架来进行开发，使用了模版继承等特性，具体参见这个 http://flask.pocoo.org/docs/0.10/quickstart/ 我们可以简单的添加其他语言的支持，比如ruby，go 等。以Ruby为例，简单的添加代码如下： https://github.com/HackToday/codelauncher/commit/aa912a1303460bed35537d04b027fee846c0697fhttps://github.com/HackToday/codelauncher/commit/879a10e37362218a61cdb6bae259b58c26ef2ba6 这个简单的实现，可以在此基础上做点有意思的事情，大家可以实验一下。]]></content>
      <tags>
        <tag>Html/Css</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Swarm的使用入门]]></title>
    <url>%2F2015%2F04%2F23%2FDocker%20Swarm%E7%9A%84%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Swarm是docker官方的native cluster方案，实现将Docker的host pool虚拟为一个主机，兼容docker的标准API， 保证了所有可以和docker daemon通信交互的软件，可以无缝的移植和docker swarm集群交互。 Docker的官方文档中提供了多种方式来搭建swarm nodes 官方例子使用docker hub token发现服务 静态文件方式 etcd方式 consul方式 zookeeper方式 静态ip列表方式 ip范围模式匹配方式 本文选1，2 为例介绍 实验环境，搭建两个机器，实体机或者虚拟机都可以，保证可以和外网通信。 方式1.1.1创建cluster id 1docker run --rm swarm create 1.2 在每个节点运行 docker daemon，需要以tcp端口监听方式运行 1docker -H tcp://0.0.0.0:2375 -d 在cluster中注册每个节点的ip 1docker run -d swarm join --addr= token:// 1.3 启动swarm manager 1docker run -d -p :2375 swarm manage token:// 1.4 检查集群状态 docker -H tcp:// info 检查集群节点信息 docker run –rm swarm list token:// 如下： 1234567891011121314Containers: 40Strategy: spreadFilters: affinity, health, constraint, port, dependencyNodes: 2host1: node1:2375 ?.Containers: 32 ?.Reserved CPUs: 0 / 1 ?.Reserved Memory: 0 B / 4.054 GiBhost2: node2:2375 ?.Containers: 8 ?.Reserved CPUs: 0 / 1 ?.Reserved Memory: 0 B / 4.054 GiB 1.5 使用集群，就是针对swarm manager 来操作 docker -H tcp:// run ... 方式2： 手工维护，有点麻烦，但是不依赖docker hub外部服务这里的主要区别是： 2.1 添加节点信息， 12$ echo &gt;&gt; /tmp/my_cluster$ echo &gt;&gt; /tmp/my_cluster 2.2 在每个节点运行 docker daemon， 同1.2 2.3 启动swarm manager 1docker run -it -v /tmp/:/mywork -p 6000:2375 swarm manage file:///mywork/my_cluster 2.4. 检查集群状态 1234docker -H tcp:// info``` 检查节点信息 docker run -v /tmp/:/mywork –rm swarm list file:///mywork/my_cluster` 2.5 操作集群，同1.5 参考资料： http://docs.docker.com/swarm/ https://docs.docker.com/swarm/discovery/]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redhat 7 - How to disable consistent network device naming]]></title>
    <url>%2F2015%2F04%2F07%2FRedhat%207%20-%20How%20to%20disable%20consistent%20network%20device%20naming%2F</url>
    <content type="text"><![CDATA[Redhat7官方确实给了如何沿用旧的网卡名字的方法，但是如果按照上面的操作，发现有的无法实现，不知道是不是受不同hypervisor的影响，因为我要修改的是一个Vcenter上的虚拟机？ 不太清楚，可能需要问问redhat那边的人，先记录一下这个link方便日后查阅 https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/Networking_Guide/sec-Disabling_Consistent_Network_Device_Naming.html 我只使用了最后一种方式 vim /etc/default/grub 添加启动参数 1net.ifnames=0 生成新的grub 配置 1grub2-mkconfig -o /boot/grub2/grub.cfg 注意这一步是否基于BIOS还是UEFI会有所不同，参见https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/System_Administrators_Guide/ch-Working_with_the_GRUB_2_Boot_Loader.html]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[How to install grunt on ubuntu 14.04?]]></title>
    <url>%2F2015%2F04%2F03%2FHow%20to%20install%20grunt%20on%20ubuntu%2014_04%2F</url>
    <content type="text"><![CDATA[今天要调试运行一个程序，需要grunt，发现运行grunt提示： 1 /usr/bin/env: node: No such file or directory 研究+bing后发现， grunt 需要依靠npm安装，但是npm需要nodejs版本和ubuntu默认源的版本不匹配，所以需要按照下面的步骤来安装 1http://www.tuicool.com/articles/YNJfAjU 简化说来，就是更新确保nodejs的版本合符grunt的要求。]]></content>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cannot start container: permission denied]]></title>
    <url>%2F2015%2F02%2F10%2FCannot%20start%20container-%20permission%20denied%2F</url>
    <content type="text"><![CDATA[在前一篇我们讨论的kubernetes fedora Ansible环境建立篇中，在fedora 20环境中如果运行 1234567891011121314151617181920212223cat ~/apache.json&#123; "id": "fedoraapache", "kind": "Pod", "apiVersion": "v1beta1", "desiredState": &#123; "manifest": &#123; "version": "v1beta1", "id": "fedoraapache", "containers": [&#123; "name": "fedoraapache", "image": "fedora/apache", "ports": [&#123; "containerPort": 80, "hostPort": 80 &#125;] &#125;] &#125; &#125;, "labels": &#123; "name": "fedoraapache" &#125;&#125; 1kubectl create -f apache.json 会发现minion的log中包含了Cannot start container: permission denied信息，其实这个是selinux一个相关的bug https://ask.fedoraproject.org/en/question/50871/cant-run-docker-without-privileged-on-fedora-20/ 解决方法： 方法1: 采用其他支持selinux的docker image方法2：在minion节点setenforce 0，然后重新运行kubectl命令即可 本文采用了方法2，结果如下： master节点检查 123$ kubectl get pod fedoraapacheNAME IMAGE(S) HOST LABELS STATUSfedoraapache fedora/apache a.b.c.d/ name=fedoraapache Running minion节点检查 12$ curl http://localhostApache]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes多节点环境（Fedora Ansible）]]></title>
    <url>%2F2015%2F02%2F10%2FKubernetes%E5%A4%9A%E8%8A%82%E7%82%B9%E7%8E%AF%E5%A2%83%EF%BC%88Fedora%20Ansible%EF%BC%89%2F</url>
    <content type="text"><![CDATA[昨天参照 https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/getting-started-guides/fedora/fedora_ansible_config.md官方的说明老是碰到一个问题： 12$ sudo systemctl start kubeletFailed to issue method call: Unit docker.socket failed to load: No such file or directory. Kubernetes社区和Redhat bugzilla说明了是因为package的缘故，旧的依赖是docker.socket，需要更新为新的依赖docker.service （黑体部分） 1234567891011121314151617181920212223$ cat /usr/lib/systemd/system/kubelet.service[Unit]Description=Kubernetes Kubelet ServerDocumentation=https://github.com/GoogleCloudPlatform/kubernetesAfter=docker.service cadvisor.serviceRequires=docker.service[Service]EnvironmentFile=-/etc/kubernetes/configEnvironmentFile=-/etc/kubernetes/kubeletExecStart=/usr/bin/kubelet \ $&#123;KUBE_LOGTOSTDERR&#125; \ $&#123;KUBE_LOG_LEVEL&#125; \ $&#123;KUBE_ETCD_SERVERS&#125; \ $&#123;KUBELET_ADDRESS&#125; \ $&#123;KUBELET_PORT&#125; \ $&#123;KUBELET_HOSTNAME&#125; \ $&#123;KUBE_ALLOW_PRIV&#125; \ $&#123;KUBELET_ARGS&#125;Restart=on-failure[Install]WantedBy=multi-user.target 实际上这样修改是无法直接work的，你会发现 1ansible-playbook -i inventory setup.yml 还是错误，docker.socket的问题，查了半天实在无法理解，那里来的docker.socket 最后不得已，重启机器，发现再次执行没有问题了。好诡异的fedora系统！]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Application blocked by Security Settings (Firefox)]]></title>
    <url>%2F2015%2F02%2F09%2FApplication%20blocked%20by%20Security%20Settings%20(Firefox)%2F</url>
    <content type="text"><![CDATA[最近访问IMM，发现浏览器中启动remote control，老是退出，提示 1Your security settings have blocked an untrusted application from running 这个问题实际上不是firefox中的security设置问题，而是java的security设置导致。 参见这个帖子 1https://support.mozilla.org/zh-CN/questions/983382 使用Configure Java，security tab下，将对应的URL加入exception site list中即可。]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes安装-local cluster篇]]></title>
    <url>%2F2015%2F02%2F05%2Fkubernetes%E5%AE%89%E8%A3%85-local%20cluster%E7%AF%87%2F</url>
    <content type="text"><![CDATA[如果你的操作系统是Ubuntu 14.**，那么文章的下面内容将会对你安装kubernetes提供帮助：本文的环境搭建针对的是local cluster 方式，参见 https://github.com/HackToday/kubernetes/blob/master/docs/getting-started-guides/locally.md 除了上面的一般说明外，有几点需要注意的是 ubuntu安装的docker.io默认是需要root权限使用的，为了系统安装的默认用户使用方面，下面的步骤将帮助你不再每次sudo执行docker命令，[1] 执行下面的命令： 12sudo gpasswd -a $&#123;USER&#125; dockersudo service docker.io restart 然后： 1logout and relogin 验证，docker ps 可以正常执行 安装etcd 安装etcd比较简单，就是从https://github.com/coreos/etcd/releases下载包，然后解压即可 确保对应的etcd在当前用户的$PATH设置里 安装kubenetes local cluster 这个需要注意一点，如果第1步，没有让用户docker group中，就需要使用sudo命令，但是因为sudo命令的环境变量是使用secure_path会覆盖你写在.bashrc中的设置，所以会出现etcd无法找到的问题，解决方法最好采用1，或者修改secyre_path，其他等等… 还有一个问题，因为kubernetes的etcd检查服务用到了curl命令，ubuntu默认是不安装curl，需要安装curl，避免出现etcd错误的打印服务超时的状态。 参考文献： http://askubuntu.com/questions/477551/how-can-i-use-docker-without-sudo http://unix.stackexchange.com/questions/91541/why-is-path-reset-in-a-sudo-command]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenStack的Instance私钥访问]]></title>
    <url>%2F2015%2F02%2F04%2FOpenStack%E7%9A%84Instance%E7%A7%81%E9%92%A5%E8%AE%BF%E9%97%AE%2F</url>
    <content type="text"><![CDATA[如果使用openstack的key-pair add后，产生的私钥是pem文件，这个是无法直接通过putty访问的。 需要经过类似的一个key转化的步骤，具体参加这篇bloghttp://blog.sina.com.cn/s/blog_575b2c50010198oy.html 然后就可以使用putty访问了， 本文针对的是windows下的用户，如果不用cygwin的方式。]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes安装的问题-Vagrant篇]]></title>
    <url>%2F2015%2F02%2F03%2Fkubernetes%E5%AE%89%E8%A3%85%E7%9A%84%E9%97%AE%E9%A2%98-Vagrant%E7%AF%87%2F</url>
    <content type="text"><![CDATA[如果参照安装文档， 1https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/getting-started-guides/vagrant.md 实体物理机安装应该不会有问题，但是奈何资源有限，拿起来我的VirutalBox建了一个虚拟机，Ubuntu 14.04 执行安装脚本，发现了诸多问题 问题1： 12345==&gt; default: Waiting for machine to boot. This may take a few minutes... default: SSH address: 127.0.0.1:2222 default: SSH username: vagrant default: SSH auth method: private key default: Error: Connection timeout. Retrying... 参见 http://stackoverflow.com/questions/22575261/vagrant-stuck-connection-timeout-retrying 解决方法 问题2： 问题1会引入另外一个问题，就是图形界面的virtualbox会提示你系统不支持硬件加速，无法创建虚拟机。这是因为virtualbox不支持nested virtualization 结合问题1，2，觉得使用single node 安装方法试试。 篇外音，升级virtualbox到4.3.20后，fix了4.3.10开启3D加速系统闪退的问题。]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ChefSpec的旧版本问题MatchAliases (NameError)]]></title>
    <url>%2F2014%2F12%2F23%2FChefSpec%E7%9A%84%E6%97%A7%E7%89%88%E6%9C%AC%E9%97%AE%E9%A2%98MatchAliases%20(NameError)%2F</url>
    <content type="text"><![CDATA[今天使用bundle exec strainer运行cookbook测试，发现报错， 问题1： 1uninitialized constant RSpec::Matchers::BuiltIn::RaiseError::MatchAliases (NameError) 查出原来是旧版本的兼容性问题，http://stackoverflow.com/questions/24459289/rspec-expectations-2-99-0-lib-rspec-matchers-built-in-raise-error-rb5-uninitia 修改Gemfile中的版本依赖如下：gem ‘chefspec’, ‘~&gt; 4.0’ 问题2： 旧的Rspec测试都是基于老的Rspec2，在Rspec 3对应的已经不再支持，所以运行会出现下面的问题， 1You must pass an argument rather than a block to use the provided matcher (equal true), or the matcher must implement `supports_block_expectations 具体问题参考这个帖子：http://www.wenda.io/questions/4095574/rspec-3-vs-rspec-2-matchers.htmlhttp://stackoverflow.com/questions/26118031/rspec-3-vs-rspec-2-matchers 具体新的Rspec格式要求参见文档如下：http://www.rubydoc.info/github/rspec/rspec-expectations/RSpec/Matchershttps://www.relishapp.com/rspec/rspec-expectations/docs/built-in-matchers 问题3： 1RSpec 3.0 deprecates the :should way of writing specs for expecting things to happen. 也是新的版本的问题，导致旧的语法格式有warnings，Fix 方法1）这个帖子介绍的很详细，包含fix方法，http://makandracards.com/makandra/25409-how-to-remove-rspec-old-syntax-deprecation-warnings 123456789101112Inside spec/spec_helpber.rb, set rspec-expectations’ and/or rspec-mocks’ syntax as following:RSpec.configure do |config| # ... config.mock_with :rspec do |c| c.syntax = [:should, :expect] end config.expect_with :rspec do |c| c.syntax = [:should, :expect] endend 官方说明：https://www.relishapp.com/rspec/rspec-expectations/docs/syntax-configuration Fix 方法2）还有一种fix方式是修改，转换旧的格式语法，有一个资料介绍一个自动转换工具：http://yujinakayama.me/transpec/暂时没有使用上面的方法，有空的话，可以尝试一下。]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redhat 6.5 升级 Redhat 7的经历-也是醉了]]></title>
    <url>%2F2014%2F12%2F17%2FRedhat%206.5%20%E5%8D%87%E7%BA%A7%20Redhat%207%E7%9A%84%E7%BB%8F%E5%8E%86-%E4%B9%9F%E6%98%AF%E9%86%89%E4%BA%86%2F</url>
    <content type="text"><![CDATA[https://access.redhat.com/solutions/21964Redhat 4,5,6之间的upgrade，官方不给与支持，推荐使用fresh install，然后把对应软件的配置和数据迁移到新的server上 Start from Redhat 7,Redhat 对一些特定的case给与了支持，但是支持的力度有限 https://access.redhat.com/node/637583/ 在Redhat Summit上http://rhsummit.files.wordpress.com/2014/04/cantrell_w_1650_migrating_and_upgrading_rhel.pdf Redhat官方的升级资料有个可恶的问题就是，给出的升级包没有下载的连接，不知道是不是需要什么subscription number 才能看到？所以就索性按照Damian Zaremba写的关于 centos 6.5升级到7的步骤执行： http://damianzaremba.co.uk/ 1234567891011121314151617181920212223241. yum update 2. yum localinstall preupgrade-assistant-1.0.2-36.0.1.el6.centos.x86_64.rpm3. yum localinstall preupgrade-assistant-contents-0.5.14-1.el6.centos.noarch.rpm4. yum localinstall redhat-upgrade-tool-0.7.22-3.el6.centos.noarch.rpm5. [root@testnode-***** ~]# redhat-upgrade-tool --iso=RHEL-7.0-20140507.0-Server-x86_64-dvd1.iso --forcesetting up repos...getting boot images...vmlinuz-redhat-upgrade-tool | 4.7MB 00:00 ...initramfs-redhat-upgrade-tool.img | 32MB 00:00 ...setting up update...upgradeiso/filelists_db | 3.0 MB 00:00 ...finding updates 100% [===========================================================================================]testing upgrade transactionrpm transaction 100% [===========================================================================================]rpm install 100% [===============================================================================================]setting up system for upgradeFinished. Reboot to start upgrade.6. Reboot 悲剧的是重启后，发现系统根本起不来，不能load image.因为原来系统做过快照，所以恢复一次，重试还是出现同样的问题，以亲身经历验证这个依靠centos的包升级不靠谱。除非Redhat官方大发慈悲，公布相应的下载包，要不我也是对其升级方案持有悲观态度。]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redhat7 网卡的新命令规则]]></title>
    <url>%2F2014%2F12%2F13%2FRedhat7%20%E7%BD%91%E5%8D%A1%E7%9A%84%E6%96%B0%E5%91%BD%E4%BB%A4%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[如果你最近使用Redhat7的话，会发现Redhat 7安装后的网卡名称非常怪异，不要惊慌，其实，这是Redhat公司开发的操作系统新版本的特性，同事搜到的这篇文章介绍的很详细，至少没在Redhat官方网站上看到这么详细的介绍，值得看一下： 参考文章： http://www.ehowstuff.com/new-naming-scheme-for-the-network-interface-on-rhel-7centos-7/]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu新版本14.10安装问题，及解决方案汇总]]></title>
    <url>%2F2014%2F10%2F26%2Fubuntu%E6%96%B0%E7%89%88%E6%9C%AC14.10%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98%EF%BC%8C%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[Ubuntu今年的最后一个版本14.10如期的发布了，新的版本汇集了一些新的特性，Ubuntu Desktop： 除了Unity，Xorg 及一些软件包更新的集成外，最有看点的还是Ubuntu Developer Tools Center, Ubuntu官方将其定位： 为开发者提供Ubuntu上的快速开发环境，这里的开发环境并不局限在ubuntu应用，涵盖其他的比如Android，Go，Web 等。 因为是新引入的特性，所以目前支持Android开发环境的快速搭建，期待用户的反馈再开发后续更多的支持。虽然是Ubuntu14.10引入的官方支持，但是为了更好的LTS优先原则，可以通过PPA添加的方式来在Ubuntu 14.04中使用这个特性， 具体可以参见这篇bloghttp://blog.didrocks.fr/post/Ubuntu-loves-Developers 笔者使用Virtualbox安装Ubuntu 14.10出现了如下几个问题，网上也有一些人遇到了，给出解决方法，汇总如下， 安装界面一片混乱，色彩模糊， http://askubuntu.com/questions/541006/ubuntu-14-10-does-not-install-in-virtualbox 解决方法： 1Hit Ctrl+Alt+F1 (you will see the shell) and then Ctrl+Alt+F7. You are good to proceed with the installation. Virtualbox Guest Additions 不能正确编译安装 这是因为老的版本的问题，下载最新的dkms，然后重新启动机器即可， http://www.ubuntugeek.com/fix-for-ubuntu-14-10-screen-resolution-issue-on-virtualbox.html 解决方法： 1 sudo apt-get install virtualbox-guest-dkms 参考资料： Ubuntu 14.10 Release Noteshttps://wiki.ubuntu.com/UtopicUnicorn/ReleaseNotes#Official_flavours]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker技术-cgroup]]></title>
    <url>%2F2014%2F10%2F13%2FDocker%E6%8A%80%E6%9C%AF-cgroup%2F</url>
    <content type="text"><![CDATA[Docker容器采用了linux内核中的cgroup技术来实现container的资源的隔离和控制。关于cgroup我们需要了解的它的知识点： 基本概念 cgroup涉及到几个概念如下：cgroup：以某种方式，将某些任务和subsystem进行关联subsystem：基于cgroup的资源管理器，可以看作一种资源（比如CPU，Memory， I/O等），实现对一个cgroup的task的调度和控制hierarchy：对crgoups和subsystems以某种形式进行的组织，cgroup组织形式是树结构，subsystem会关联连接到hierarchy上。 上面的概念有点抽象，看个简单的例子就明白了，比如redhat官网的一个图： 上面的就是一个1个hierarchy，有两个subsystem（cpu和memory） attach上，其中的cgroups以tree的结构组织。 既然cgroup是什么以及结构弄清楚了，那到底cgroup如何实现的资源的管理控制，cgroup是和task（乜可以看作是系统中的进程）关联的，这样不同的cgroup在subsystem中的资源控制下就能够分配到不同的份额或者设定不同的限制，同时可以统计监控资源的消耗情况。 如何使用Cgroups如果我们最原始的使用cgroup，不借助高级的docker方式，那么具体步骤如下： 123456789101112131415161718192021222324252627282930To start a new job that is to be contained within a cgroup, usingthe "cpuset" cgroup subsystem, the steps are something like: 1) mount -t tmpfs cgroup_root /sys/fs/cgroup 2) mkdir /sys/fs/cgroup/cpuset 3) mount -t cgroup -ocpuset cpuset /sys/fs/cgroup/cpuset 4) Create the new cgroup by doing mkdir's and write's (or echo's) in the /sys/fs/cgroup virtual file system. 5) Start a task that will be the "founding father" of the new job. 6) Attach that task to the new cgroup by writing its PID to the /sys/fs/cgroup/cpuset/tasks file for that cgroup. 7) fork, exec or clone the job tasks from this founding father task.For example, the following sequence of commands will setup a cgroupnamed "Charlie", containing just CPUs 2 and 3, and Memory Node 1,and then start a subshell 'sh' in that cgroup: mount -t tmpfs cgroup_root /sys/fs/cgroup mkdir /sys/fs/cgroup/cpuset mount -t cgroup cpuset -ocpuset /sys/fs/cgroup/cpuset cd /sys/fs/cgroup/cpuset mkdir Charlie cd Charlie /bin/echo 2-3 &gt; cpuset.cpus /bin/echo 1 &gt; cpuset.mems /bin/echo $$ &gt; tasks sh # The subshell 'sh' is now running in cgroup Charlie # The next line should display '/Charlie' cat /proc/self/cgroup 使用Docker，减少冗长细节的cgroup使用虽然Docker给我们带来了极大的方便，但是我们还是需要了解一些cgroup的操作使用，这样才更加有信心处理各种问题， 3.1 使用cgroup-bin 一般操作系统没有默认安装这个工具，我们自己需要安装，提供了很多有趣而且很棒的命令： 12345lssubsys 列出包含subsystem的hierarchylscgroup 列出所有的cgroup/proc/cgroups 列出了系统中cgroup的subsystem/proc//cgroup 列出进程所属的cgroup，包含了cgroup的 3.2 Docker的结合比如我们docker run了一个container， 先找出contianer的ID， 1docker ps --no-trunc 根据上面找出的ID，找到对应的tasks ID， 1cat /sys/fs/cgroup/cpu/docker//tasks 查看对应的cgroup 1cat /proc//cgroup 不同操作系统暴露的subsystem的区别ubuntu就和redhat有所不同，redhat有10中cgroup subsystem如果默认安装的ubuntu，比如14.04， 你会发现，没有net_cls和net_prio，具体如何搞出来，参看这个帖子 参考资料： Linux Kernel Doc about Cgroupshttps://www.kernel.org/doc/Documentation/cgroups/cgroups.txt Cannot find network subsystem in cgroup on Ubuntu 12.04 LTShttp://serverfault.com/questions/485919/cannot-find-network-subsystem-in-cgroup-on-ubuntu-12-04-lts Redhat cgroup https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Resource_Management_Guide/ch01.html Docker cgroup https://docs.docker.com/articles/runmetrics/#control-groups]]></content>
      <tags>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何登录到Docker的container中]]></title>
    <url>%2F2014%2F10%2F04%2F%E5%A6%82%E4%BD%95%E7%99%BB%E5%BD%95%E5%88%B0Docker%E7%9A%84container%E4%B8%AD%2F</url>
    <content type="text"><![CDATA[使用Docker部署container后，我们总有类似的需求：登录到container中进行一些操作。 常见的方式 有ssh方式，特点是不需要特别的root权限，但是container需要安装sshd 使用nsenter来从container获得一个shell实现登录 使用nsinit 本文主要介绍nsenter的使用 nsenter使用非常方便，但是有的操作系统发行版本util-linux包比较老，所以没有包含这个nsenter，那么你需要自己编译和安装，对于hacker们来说，源码编译安装不是小case嘛，走起！ 注明： 下面的命令运行以Ubuntu 14.04为例 1）下载源码 12git clone git://git.kernel.org/pub/scm/utils/util-linux/util-linux.git util-linuxcd util-linux/ 2）安装依赖包（这个具体缺少的情况，会在运行 ./autogen.sh的提示，你也可以直接运行3），根据提示来安装对应的依赖包 1234sudo apt-get install libtoolsudo apt-get install automakesudo apt-get install autopointsudo apt-get install libncurses5-dev 3）编译安装 12./autogen.sh ./configure &amp; make 4）测试安装成功 1./nsenter -V 5) 将nsenter加入系统环境可执行路径中 1sudo cp ./nsenter /usr/bin 如何使用nsenter，非常简单，1) 首先找到container对应的进程ID 1sudo docker inspect --format "&#123;&#123; .State.Pid &#125;&#125;" 2) 执行nsenter获得一个shell ，假设1）获得id是4308 1sudo nsenter --target 4308 --mount --uts --ipc --net --pid 这样就进入到了container中。好了，有的人可能会说attach不是也可以吗？为什么用这个nsenter？个人理解两个功能是完全不一样的，attach相当于找到原始的会话shell，而原始的shell可能是一个循环程序或者web server直接在shell下运行的，这样你如果执行Ctril-C，直接导致对应的container stop，所以这不是我们期望发生的。nsenter则是新创建的一个shell，这样就是新的会话。 参考资料： Why there is no nsenter in util-linux?http://askubuntu.com/questions/439056/why-there-is-no-nsenter-in-util-linux 在 UOS 上体验 CoreOShttps://www.ustack.com/blog/running-coreos-on-uos/ Attaching to a container with Docker 0.9 and libcontainerhttp://jpetazzo.github.io/2014/03/23/lxc-attach-nsinit-nsenter-docker-0-9/ Docker shell/provisioning without SSHhttps://github.com/mitchellh/vagrant/issues/4179]]></content>
      <tags>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker的操作学习-attach,detach,volume data]]></title>
    <url>%2F2014%2F10%2F01%2FDocker%E7%9A%84%E6%93%8D%E4%BD%9C%E5%AD%A6%E4%B9%A0-attach%2Cdetach%2Cvolume%20data%2F</url>
    <content type="text"><![CDATA[Docker作为另一类虚拟化技术-容器方案，已经吸引了越来越多的开发和关注，docker在各大操作系统厂商-Ubuntu，Redhat等都提供了很好的集成，更给力的是docker的官方的文档写的非常清晰易懂。下文以ubuntu 14.04为例，对docker的CLI进行简单的学习， Docker Hub上提供了大量image可以进行测试练习，所以我们随便选一个 启动进入一个shell 1sudo docker run -i -t --name web training/webapp /bin/bash Detach 上面的container 1CTRL-p CTRL-q Attach上面的container 1sudo docker attach web 以background方式运行 container 1sudo docker run -d -P training/webapp python app.py 其中 -P 是将container的ports暴露给对于主机所有的interface，比如上面的启动的container，我们可以通过sudo docker ps 查看运行的端口， 1f3ca5cd8c307 training/webapp:latest /bin/bash 24 minutes ago Up 22 minutes 0.0.0.0:49154-&gt;5000/tcp web 这样，如果Host有多块网卡，每个网卡有不同的ip，所有的ip:49154 都可以访问这个web app了。 Docker的数据管理及使用 docker的Data volumes功能可以: 对container进行方便的volume创建， 对host的目录进行快捷的mount到container 不同container之间通过volume进行数据共享 对data volume进行方便的backup，restore和migrate 例如： 创建一个名字是dbdata的container包含dbdata的volume 1sudo docker run -i -t -v /dbdata --name dbdata training/postgres /bin/bash 对上面的container的/dbdata挂载到新的container db1上 1sudo docker run -i -t --volumes-from dbdata --name db1 training/postgres /bin/bash backup 和 restore: 首先启动一个新的container来对dbdata的data volume数据打包备份到host的当前目录下 1sudo docker run --volumes-from dbdata -v $(pwd):/backup training/postgres tar cvf /backup/backup.tar /dbdata 创建一个用来restore上面数据的container，名字是dbdata2 1sudo docker run -v /dbdata --name dbdata2 training/postgres /bin/bash un-tar到新创建的container的data volume中 1sudo docker run --volumes-from dbdata2 -v $(pwd):/backup training/postgres tar xvf /backup/backup.tar 很明显，上面的几个步骤通过Host来实现了文件的转存。 作为外延，读者可以参考更多的资料： Docker的技术预览http://www.infoq.com/cn/articles/docker-core-technology-preview Docker的源码分析http://www.infoq.com/cn/articles/docker-source-code-analysis-part1?utm_campaign=infoq_content&amp;utm_source=infoq&amp;utm_medium=feed&amp;utm_term=global&amp;utm_reader=feedly Docker的CLIhttp://docs.docker.com/reference/commandline/cli/http://docs.docker.com/userguide/dockervolumes/http://docs.docker.com/userguide/usingdocker/]]></content>
      <tags>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Enable 3D acceleration cause Virtual Box guest crash]]></title>
    <url>%2F2014%2F09%2F30%2FEnable%203D%20acceleration%20cause%20Virtual%20Box%20guest%20crash%2F</url>
    <content type="text"><![CDATA[最近遇到的一个问题，每次只要在guest的配置中enable 3D acceleration，就会出现， VirtualBox Manager Stop working，导致guest无法正常的图形界面启动，google 了一下，有个帖子讨论是Virtulbox 的最近版本回归的一个Bug， 讨论link如下： https://forums.virtualbox.org/viewtopic.php?f=6&amp;t=62633https://www.virtualbox.org/ticket/12772]]></content>
      <tags>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack keystone的policy设计处理分析]]></title>
    <url>%2F2014%2F07%2F31%2FOpenstack%20keystone%E7%9A%84policy%E8%AE%BE%E8%AE%A1%E5%A4%84%E7%90%86%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[keystone设计的policy role based access controls(RBAC)非常有意思，最终暴露给用户的是一种简单的可编辑的语义规则。举个例子如下： 123456&#123; ... "admin_required": "role:admin or is_admin:1", "identity:get_user": "rule:admin_required", ...&#125; keystone的policy使用的driver默认配置是如下：driver = keystone.policy.backends.sql.Policy 每个相应的API的访问请求都会经过相应RBAC的检测，在keystone中的API是通过filterprotected，protected的decorator来作用的，调用入口： 123self.policy_api.enforce(creds, action, authorization.flatten(policy_dict)) 具体的时序图以get_user为例如下： Enforcer这个类其中的enforce方法逻辑如下： 123456789101112131415161718 .... self.load_rules() # Allow the rule to be a Check tree if isinstance(rule, BaseCheck): result = rule(target, creds, self) elif not self.rules: # No rules to reference means we're going to fail closed result = False else: try: # Evaluate the rule result = self.rules[rule](target, creds, self) except KeyError: LOG.debug(_("Rule [%s] doesn't exist") % rule) # If the rule doesn't exist, fail closed result = False... 其中各种rule的就是各种规则来实现不同角色的权限管理，具体的rule类层次结构如下： 下次我们将对其policy语言的解析处理进行详细的分析]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[chef-server的架构简介]]></title>
    <url>%2F2014%2F07%2F15%2Fchef-server%E7%9A%84%E6%9E%B6%E6%9E%84%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[chef采用的C/S架构，主要包括chef-server还有chef-client 总体架构chef-server，控制节点，主要存储相关的cookbook,配置节点的策略，描述注册节点的元数据安装节点，使用chef-client来向server节点获取配置信息，包括recipe，templates，file等，完成节点的配置工作。 chef为了更好的支持并发，分布式环境，在11.X版本前段的server采用了erlang开发，也就是上面的Erchef 部分。 各个组件的部分， (1)Nginx，前端的http请求的负载均衡(2) WebUI，提供更友好的GUI方式使用chef(3)Erchef，Chef-server的API实现层(4) Bookshelf， 是一种对象存储。按照文件的checksum存储，所以同样的文件只会存取一次，这样不同版本的cookbook的重复的文件不会存储多次。具体可以查看 /var/opt/chef-server/bookshelf/data/bookshelf/目录下的文件(5) Message Queues，采用的rabbitmq， chef-expander 从消息队列里取出消息，处理成对应的格式，提供给chef-solr做索引 chef-solr对apache solr包装，提供可以进行索引和查找的REST API 索引数据存储的位置是 /var/opt/chef-server/chef-solr/data(6) PostgreSQL, chef-server的数据存储， 查看具体数据库表结构： export PATH=$PATH:/opt/chef-server/embedded/bin/ psql -U opscode_chef \l 列出所有数据库 \dt 列出当前连接数据库的表 数据库相关的存储数据， /var/opt/chef-server/postgresql/data 核心API server的组件架构 Erchef具体架构细节： 根据上面的结构图，可以看到对象的更新时chef_objects和bookshelf的完成chef_authn：实现了chef相关的http请求的签名和验证协议chef-index：和apache solr的交互，对象的增删改，和rabbimq交互。 例如： 1234567891011121314%% @doc Delete an object from Solr.%% @end%%%% Note that the guard for this function recapitulates the chef_indexable_type()%% custom type. This is done out of an abundance of caution and%% paranoia :)delete(VHost, Type, ID, DatabaseName, SolrUrl) when Type =:= 'client'; Type =:= 'data_bag'; Type =:= 'data_bag_item'; Type =:= 'environment'; Type =:= 'node'; Type =:= 'role' -&gt; PackagedData = package_for_delete(Type, ID, DatabaseName, SolrUrl), publish(VHost, PackagedData, routing_key(ID)). chef_objects：定义了chef内部的一些对象，environment，node，data bag等chef_db: chef-server的数据库层逻辑，chef_wm： 包含了erchef的rest api实现和路由定义 Chef-client执行流程： A “chef-client run” is the term used to describe a series of steps that are taken by the chef-client when it is configuring a node. The following diagram shows the various stages that occur during the chef-client run, and then the list below the diagram describes in greater detail each of those stages. 参考资料: chef-server.rb Optional Settings http://docs.opscode.com/config_rb_chef_server_optional_settings.html Monitor http://docs.opscode.com/server_monitor.html chef-client http://docs.opscode.com/chef_client.html Erchef https://github.com/opscode/erchef chef-server http://docs.opscode.com/server_components.html]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redhat 7的kernel新看点]]></title>
    <url>%2F2014%2F06%2F22%2FRedhat%207%E7%9A%84kernel%E6%96%B0%E7%9C%8B%E7%82%B9%2F</url>
    <content type="text"><![CDATA[Redhat 2014的summit关于RHEL 的roadmap中，关于kernel的部分，讲了很有意思的一些新特点，主要包括，架构，内存管理，调度和锁机制的改进，性能提升，debug，还有container…. 12345678910111213141516171819RHEL 7 Kernel Architecture Support1） ArchitecturesSupport the following 64 bits ArchitecturesX86_64, Power, and s390with 32bit user space compatibility support2） Theoretical Limits on X86_64–Logical CPU – maximum 5120 logical CPUs–Memory – maximum 64TResource Management Improvements1）Linux Containers (LXC) – Fully Supported in RHEL 7 RC2）Control Groups: cpu, cpuset, memory, block io, network, network prio3）Libcgroup has been deprecated, replacing with systemd's scope and slices4）Namespaces: mount, UTS, IPC, PID, network5）User Namespace – in later releases6）SELinux – security protection for containers7）SystemD – provide unit file to help setup container’s resources8）Docker CLI 其实container才是我感兴趣的地方，Docker公司最近发布的1.0可谓在业界风生水起， What is Docker&apos;s architecture? Docker uses a client-server architecture. The Docker client talks to the Docker daemon, which does the heavy lifting of building, running, and distributing your Docker containers. Both the Docker client and the daemon can run on the same system, or you can connect a Docker client to a remote Docker daemon. The Docker client and service communicate via sockets or through a RESTful API. The Docker daemon As shown in the diagram above, the Docker daemon runs on a host machine. The user does not directly interact with the daemon, but instead through the Docker client. The Docker client The Docker client, in the form of the docker binary, is the primary user interface to Docker. It accepts commands from the user and communicates back and forth with a Docker daemon. Inside Docker To understand Docker&apos;s internals, you need to know about three components: - Docker images. - Docker registries. - Docker containers. 参考资料： http://docs.docker.com/introduction/understanding-docker/#what-is-dockers-architecture Redhat 2014 Summit]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu 14.04虚拟机无法挂载vboxsf的问题]]></title>
    <url>%2F2014%2F06%2F17%2Fubuntu%2014.04%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%97%A0%E6%B3%95%E6%8C%82%E8%BD%BDvboxsf%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[环境：virtualbox 4.3.10虚拟机： ubuntu 14.04 问题： 今天要挂载一个share folders 突然发现无法挂载，然后查了一下，原来是bad link导致的问题，修复后，正常使用。 1234567test@test-VirtualBox1404:~$ sudo mount -t vboxsf vm-mount /mnt/sharemount: wrong fs type, bad option, bad superblock on vm-mount, missing codepage or helper program, or other error (for several filesystems (e.g. nfs, cifs) you might need a /sbin/mount. helper program) In some cases useful info is found in syslog - try dmesg | tail or so 解决方法： 1sudo ln -s /opt/VBoxGuestAdditions-4.3.10/lib/VBoxGuestAdditions /usr/lib/VBoxGuestAdditions 参考帖子： http://askubuntu.com/questions/458286/getting-an-error-wrong-fs-type-bad-option-bad-superblock-on-ubuntushared]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Local Area Connection doesn't have a valid IP configuration]]></title>
    <url>%2F2014%2F05%2F31%2FLocal%20Area%20Connection%20doesn't%20have%20a%20valid%20IP%20configuration%20%2F</url>
    <content type="text"><![CDATA[今天办公突然发现windows7网络链接有问题了，检查网线，网线接口都没有问题，那肯定出在操作系统这边， 网络诊断提示: 1Local Area Connection doesn't have a valid IP configuration 莫名其妙，google一下，发现有些干货，真的很给力，解决了问题，这样你就不用苦恼的重装系统了（最笨最郁闷的方法） 帖子内容如下：（黑体字体部分就是解决方法） Hey everyone, I’ve had this problem for days with my home router on windows7. Try these two commands and restart. it worked for me.Link of Website is below also. Reset WinSock and TCP/IP StackOpen a Command Prompt as administrator:Reset WINSOCK entries: netsh winsock reset catalog Reset TCP/IP stack:netsh int ip reset reset.log Reboot the machine(you can run both commands first, I tend to put multiple commands in notepad and then copy and paste into the command window).I can also confirm that this is the only solution that worked for me. I entered the second command and rebooted computer. Upon restart my internet functionality was returned.You can find the original article on the microsoft website at: http://support.microsoft.com/kb/299357 感谢分享，世界才变得更美好。 参考资料： http://social.technet.microsoft.com/Forums/windows/en-US/55aa9f24-e8ea-4743-8e04-120decfb6122/local-area-connection-doesnt-have-a-valid-ip-configuration-w7?forum=w7itpronetworking]]></content>
      <tags>
        <tag>WINDOWS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu 14.04 运行devstack]]></title>
    <url>%2F2014%2F05%2F16%2Fubuntu%2014.04%20%E8%BF%90%E8%A1%8Cdevstack%2F</url>
    <content type="text"><![CDATA[前段时间的ubuntu的14.04的发布，可谓一直就想试试新的用户体验，软件工程师要有尝试新鲜事物的精神是吧，不是“神精” 下载iso，挂载virtualbox的新创建的虚拟机上， 下载代码 1git clone https://github.com/openstack-dev/devstack.git 这个是master的branch就是针对openstack Juno的分支 配置 （根据自己的环境配置相应的***地方） 1234567891011121314151617181920[[local|localrc]]ENABLED_SERVICES="$ENABLED_SERVICES,-rabbit,-zeromq,qpid"ENABLED_SERVICES="$ENABLED_SERVICES,-n-net,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-metering,neutron,tempest"ADMIN_PASSWORD=***MYSQL_PASSWORD=***SERVICE_PASSWORD=$ADMIN_PASSWORDLOGFILE=$DEST/logs/stack.sh.logHOST_IP=*****KEYSTONE_CATALOG_BACKEND=sqlSERVICE_TOKEN=***QPID_USERNAME=***QPID_PASSWORD=***FLOATING_RANGE=***FIXED_RANGE=***FIXED_NETWORK_SIZE=**FLAT_INTERFACE=eth1NETWORK_GATEWAY=****PUBLIC_NETWORK_GATEWAY=*** 运行 1./stack.sh 执行完毕，openstack的一切服务运行良好 虽然devstack的主页没写支持ubuntu 14.04，但细细想想ubuntu多年前押宝到openstack，作为社区广泛流行的支持OS LTS的版本自然要相当重视，应该是ubuntu团队对devstack贡献了不少代码，保证发布的14.04完美支持吧]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL6031N 在 db2nodes.cfg 文件的行号"1" 上出错]]></title>
    <url>%2F2014%2F04%2F19%2FSQL6031N%E5%9C%A8db2nodes.cfg%E6%96%87%E4%BB%B6%E4%B8%8A%E7%9A%84%E5%87%BA%E9%94%99%2F</url>
    <content type="text"><![CDATA[问题是来源，迁移云环境后，最初发现keystone的log里，都是SQL链接的错误，很明显是keystone和DB2的通信出现了一点问题，于是切换到DB2下，发现db2无法正常执行一些简单的命令比如stop，报错 1SQL6031N 在 db2nodes.cfg 文件的行号 "1" 上出错.... 显然错误的原因很明显，那就研究一下这个db2nodes.cfg 查了一下 DB2的官方文档，http://pic.dhe.ibm.com/infocenter/db2luw/v9r7/index.jsp?topic=%2Fcom.ibm.db2.luw.qb.server.doc%2Fdoc%2Fr0006351.html 这里面涉及到了一个hostname配置，也就是说你要是主机名修改了，这个地方原来的配置hostname就会有实效的问题，这篇blog http://blog.csdn.net/kimmking/article/details/1613430也提到了类似的问题 修改成主机新的hostname后，就没有问题了，如果改成localhost，似乎不行，/etc/hosts 有解析, 不太清楚localhost的问题，改天再研究一下。]]></content>
      <tags>
        <tag>DB2/Informix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[追踪无法umount的来源]]></title>
    <url>%2F2014%2F04%2F19%2F%E8%BF%BD%E8%B8%AA%E6%97%A0%E6%B3%95umount%E7%9A%84%E6%9D%A5%E6%BA%90%2F</url>
    <content type="text"><![CDATA[前段时间执行一个cookbook，发现节点执行完后，每次总是有个路径没有正常umount，于是我就陷入深深的郁闷中，可是工程师的职责就是解决问题的，别人不帮你解决，那就得自己搞定。 首先，要让完整的异常信息给抛出来，到底是什么原因导致的无法umount如果你查看过 chef 的代码说明 https://github.com/opscode/chef/blob/master/lib/chef/mixin/shell_out.rb 12shell_out 可是对错误不报警的shell_out! 绝对不容忍命令执行错误，绝对抛出异常 使用shell_out!， cookbook执行后，把错误面目暴露出来了， device is busy很显然是某个进程使用这个设备 然后，我们就需要找到哪个进程在用这个device， fuser 或者lsof 就是干这事的，做调查的比如fuser 1sh -c fuser -m /tmp/mytest ; ps aux 将上面的命令输出结果在cookbook执行时，打印出来，就可以抓到进程了 最后，上一步既然获得了进程也知道是chef-client在用，那就是cookbook中存在使用目录的情况，后面的就简单了，一般就是打开文件，没有关闭，或者进入到了要卸载的目录 grep 找到open file的地方，发现有一个地方没有close，就是它了。 Fix问题后，重新运行cookbook，发现所有umoun就顺利完成了，问题就解决了。]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[不同console下的vim之间的copy]]></title>
    <url>%2F2014%2F04%2F13%2F%E4%B8%8D%E5%90%8Cconsole%E4%B8%8B%E7%9A%84vim%E4%B9%8B%E9%97%B4%E7%9A%84copy%2F</url>
    <content type="text"><![CDATA[以前都是一个vim下的tabnew或者vsp之前的操作，因为是一个vim实例，所以快捷键copy和cut，paste是没有问题今天发现不同console下的vim如果按照老套路是不能工作的，也就是说我们需要解决不同vim之间的内容如何copy，cut，paste呢 ？ 其实vim的教程里说明了这一点，需要系统剪切板的支持，但是普通的vim，一般系统默认装的可能并不支持， 1vim --version | grep clipboard 如果输出有： 1-xterm_clipboard 那么说明你的vim有点弱，需要增强版的vim，那么可以安装vim-gnome或者vim-gtk安装后，vim –version, 就会有+xterm_clipboard 那么就尽情的享用快捷命令吧： “+2yy – copy two lines to X11 clipboard“+dd – cut line to X11 clipboard“+p – paste X11 clipboard 具体更多参考： http://vim.wikia.com/wiki/Accessing_the_system_clipboard]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim来浏览markdown文档]]></title>
    <url>%2F2014%2F04%2F11%2Fvim%E6%9D%A5%E6%B5%8F%E8%A7%88markdown%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[如果没有vim安装相应的插件，看markdown文档会遇到一些高亮无法正常显示的现象，比如引号识别 https://github.com/tpope/vim-markdown/issues/29 这个讨论的了这个问题 要想解决这个问题，就使用 http://calefy.org/2012/03/01/set-vim-markdown-syntax-highlight.html安装相应的插件]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cookbook 引发的 undefined method for {} Hash]]></title>
    <url>%2F2014%2F04%2F01%2Fcookbook%20%E5%BC%95%E5%8F%91%E7%9A%84%20undefined%20method%20for%20%7B%7D%20Hash%2F</url>
    <content type="text"><![CDATA[在写cookbook的时候，发现strainer test 一直有问题undefined method `&lt;&lt;’ for {}:Hash 比如network的cookbook在havana中spec_helper.rb是 12# README(galstrom21): This will remove any coverage warnings from dependent cookbooksChefSpec::Coverage.filters &lt;&lt; '*/openstack-network' 出错的地方，是filters这个地方 调查发现，原来社区的cookbook在icehouse将chefspec的version升级到3.4了而havana是使用的3.1.4 查看chefspec的ruby class 说明：chefspec 3.1.4 资料[1] 12345# File 'lib/chefspec/coverage.rb', line 16def initialize @collection = &#123;&#125; @filters = []end 这个是array chefspec 3.4 资料[2] 12345# File 'lib/chefspec/coverage.rb', line 28def initialize @collection = &#123;&#125; @filters = &#123;&#125;end 已经变为hash了，所以显然如果仅仅更新GemFile，还是基于havana的spec_helper直接运行，那么就会报上面的错误，所以社区已经修改使用了如下的调用 1ChefSpec::Coverage.start! &#123; add_filter 'openstack-network' &#125; 更多参考可以看社区的 blueprint http://rubydoc.info/gems/chefspec/3.1.4/frames http://rubydoc.info/gems/chefspec/ChefSpec/Coverage#filters-instance_method https://review.openstack.org/#/c/83712/ https://launchpad.net/openstack-chef]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ruby的warning: already initialized constant问题]]></title>
    <url>%2F2014%2F03%2F30%2Fruby-warning-already_initialized_constant%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[如果使用1.8的ruby，项目编译运行经常会遇到如下的警告 1warning: already initialized constant 这个就是因为load多次造成，为什么会load多次呢？ http://stackoverflow.com/questions/4532405/what-is-the-right-way-to-initialize-a-constant-in-ruby 给了解释。比如下面这个测试程序（比如命名machine.rb,这个文件在~/test目录下) 123module MyWork IPADDR = 0x16dfend 我们在另外一个主rb文件(mytestmod.rb，和machine.rb在同一目录下)需要用到上面模块中的常量 123456789101112require './machine'require '../test/machine'class Book attr_reader :name, :price def initialize(name, price) @name = name @price = price endendbook = Book.new('hello world', 120)puts book.name 注意上面的例子，我们对同一个文件require了两次，如果使用ruby1.8,就会有 12../test/machine.rb:4: warning: already initialized constant IPADDRhello world 但是ruby1.9,不会出现这个问题 1hello world]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rubocop的规则和rspec的打架和解]]></title>
    <url>%2F2014%2F03%2F30%2Frubocop%E7%9A%84%E8%A7%84%E5%88%99%E5%92%8Crspec%E7%9A%84%E6%89%93%E6%9E%B6%E5%92%8C%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[rubocop是根据社区流行的ruby编码规范写的一个静态代码分析工具，rpsec是ruby界流行的BDD测试工具 rpsec里有类似断言的关键字，expect，比如1）判定某个变量等于123expect(actual).to eq(123)2）判断某个boolean值为trueexpect(actual).to be true expect还支持raise，throw错误的断言，采用block方式，如下 1expect &#123; dosomething &#125;.to raise_error 介绍了这么多，我们的问题是什么，rubocop里默认有个multi-line规则，就是代码里如果有block 方式 { …}, 1234[1, 2, 3].each &#123; |i| puts i.to_s ...&#125; rubocop 会提示上面的例子{.. }的warning，推荐你采用single-line 或者 do .. end的block方式， 采用do.. end 为例 1234[1, 2, 3].each do |i| puts i.to_s ...end 但是，实际测试expect断言的block中，很可能长度有超过80字符的长度的时候，那么，就得采取几种方法，避过可恶的rubocop警告 方法1： 在.rubocop.yml文件禁掉Blocks，因为默认的是 12345Blocks: Enabled: true 这个方法显然是有点过了，因为它会将这个检查对整个代码都生效了，所以不是很好 方法2：使用其他block方式，绕过{}, 比如 12345expected = expect do ... ...endexpected.to raise_error 或者 1234expect do ... ...end.to raise_error 参考资料： https://github.com/bbatsov/rubocop#configuration https://github.com/bbatsov/rubocop/blob/master/config/enabled.yml http://stackoverflow.com/questions/13274708/how-to-format-multiline-rspec-expect-to-change]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[chef的文件传输]]></title>
    <url>%2F2014%2F03%2F23%2Fchef%E7%9A%84%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%2F</url>
    <content type="text"><![CDATA[chef有两类resource支持文件传输，一个是remote_file, 还有一个是cookbook_file，这两个的区别是 如果要传输的文件是放在cookbooks中的file目录下的，那么需要使用cookbook_file，顾名思义，就是文件放在cookbook里如果要传输的文件是在放在远程的一个地方，那么使用remote_file， 其实这里的远程比较广，支持 12The location (URI) of the source file.This value may also specify HTTP (http://), FTP (ftp://), or local (file://) source file locations 我们举个简单的使用场景，比如，你要对机房管理的机器，安装一个软件包，由于内网限制或者没有软件配置源，我们提前把要安装的软件包下载到本地，然后使用cookbook功能完成传输文件，然后安装， 简单的一个recipe 比如： 123456789101112cookbook_file "/tmp/test.gem" do mode 0644 owner 'root' group 'root' action :createendgem_package "test" do gem_binary("/opt/chef/embedded/bin/gem") source "/tmp/test.gem" action :installend 如果remote_file,就是需要制定相应的uri，但是需要保证node是可以访问对应的资源的，都算可行的方法]]></content>
      <tags>
        <tag>系统运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ruby和python的ini纠纷]]></title>
    <url>%2F2014%2F03%2F09%2Fruby%E5%92%8Cpython%E7%9A%84ini%E7%BA%A0%E7%BA%B7%2F</url>
    <content type="text"><![CDATA[ruby有两个gem在ini文件的解析处理上用的比较多，一个是inifile，还有另外一个扩展的iniparse 根据 [1]介绍，iniparse相比inifile主要有三个优点（1） 支持重复option项，这个在一些开源项目的ini文件可以看到（2）ini 文件写的时候保留空格和缩进行（3）保持对section和option的顺序 如果你不需要这些功能，iniparse建议你还是inifile吧。 其实 iniparse和inifile在对ini文件的解析上的不同还在约定上有点区别，（1） = 的区别比如下面的一个section 12[MYWORK]test = nice=3 上面的这个形式，iniparse是支持的，会认为 option是test对应的value是， nice=3,但是inifile就会报错，不支持上面的解析格式 为什么会提到这种写法呢， 这时因为有些ini文件配置的数据库地址connection = mysql://*?charset=utf-8 显然inifile爱莫能助，因为它的解析中，12345678910...elsif scanner.scan(%r/#&#123;@param&#125;/) if property.empty? property = string.strip string.slice!(0, string.length) else parse_error end.... 第一次， property赋值connection，但是往后解析再次遇到=，他会认为，有两个property存在，所以就parse_error了 （2）对于奇葩的ini混合式写法， ruby的ini解析都有问题比如，有些python的ini文件，这样写 123[composite:metadata]use = egg:Paste#urlmap/: meta 采用的是混合式写法，:和=都可以作为分隔符 inifile和iniparse搞不定这个（也许我没找到正确的调用方式，不过inifile的源码好像不支持）pyhton的ConfigParser可以搞定上面的混合式写法的解析处理 （3）inifile的调用的可选参数 123456789def initialize( content = nil, opts = &#123;&#125; ) opts, content = content, nil if Hash === content @content = content @comment = opts.fetch(:comment, ';#') @param = opts.fetch(:parameter, '=') @encoding = opts.fetch(:encoding, nil) @escape = opts.fetch(:escape, true) @default = opts.fetch(:default, 'global') @filename = opts.fetch(:filename, nil) 可以看到，默认的comment的是;=两种，所以一些ini文件比如 12[composite:metadata]use = egg:Paste#urlmap 如果你不传入 {:comment =&gt; ‘;’}, 就会将#urlmap作为注释了综上，可见ruby和python的ini解析还有有不少坑的 参考资料: http://www.ruby-doc.org/gems/docs/i/iniparse-1.1.5/README_rdoc.html http://docs.python.org/2.7/library/configparser.html]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ruby - 字符串占位符]]></title>
    <url>%2F2014%2F03%2F03%2FRuby%20-%20%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8D%A0%E4%BD%8D%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[Ruby中的字符串占位符的替换值是操作字符串的常用方法，使用#进行变量或者ruby代码的求值，从而替换结果插入字符串中 1234567#/usr/bin/env rubybook_mark = "znw123"# following replace and insertputs "The book mark is #&#123;book_mark&#125;"#following run ruby code, string length and insertputs "The book mark length is #&#123;book_mark.length&#125;"]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keystone的PKI token 长度引发的 HTTP 400]]></title>
    <url>%2F2014%2F02%2F21%2Fkeystone%E7%9A%84PKI%20token%20%E9%95%BF%E5%BA%A6%E5%BC%95%E5%8F%91%E7%9A%84%20HTTP%20400%2F</url>
    <content type="text"><![CDATA[openstack keystone的PKI token从grizzly版本开始支持，PKI token相比如传统的UUID的token，长度要增加不少，而且如果keystone的endpoint 和service catalog越多，相应的token长度都会有所增加。 在python的eventlet默认支持长度有个限制，如果要更长的header，需要对一个属性就行修改， 1eventlet.wsgi.MAX_HEADER_LINE 于是就爆发了一个在各个项目需要修复的bug - https://bugs.launchpad.net/keystone/+bug/1190149 社区目前采取的方式是让header的支持长度可配置： 12345cfg.IntOpt('max_header_line', default=16384, help=_('Maximum line size of message headers to be accepted. ' 'max_header_line may need to be increased when using ' 'large tokens (typically those generated by the ' 'Keystone v3 API with big service catalogs')),]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keystone-manage pkg_resources.DistributionNotFound 的问题]]></title>
    <url>%2F2014%2F02%2F21%2Fkeystone-manage%20pkg_resources.DistributionNotFound%20%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[因为devstack安装后，需要经常pull新的代码，由于自己的开发环境不是每次都是fresh的，所以再次运行stack.sh有时会遇到一些问题。 在运行的时候，发现keystone的token的一个问题，怀疑pki的相关问题，使用keystone-manage发现，提示 1pkg_resources.DistributionNotFound:keystone==2014.1.*** 于是检查keystone-manage的代码，发现这个里面的代码还有 require(“keystone**“) 版本依赖，这个内容和keystone-manage的源码完全不一样。难道是偶尔运行ubuntu的apt-get install keystone导致的？根据使用习惯，我是从来不用ubuntu的apt方式来装openstack。所以，要想解决这个问题，就修改keystone-manage为原来的代码。 再次运行，就没有问题了。]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[putty color setting]]></title>
    <url>%2F2014%2F02%2F14%2Fputty%20color%20setting%2F</url>
    <content type="text"><![CDATA[原来一直用secure shell client， 现在改用putty了，里面的默认配色方案不太好，就查了一下，文章 http://www.coder4.com/archives/1506http://www.ldisp.com/a/primary/2013/1571.shtml 介绍的可以采用， 你可以建个reg文件，直接import， 这样putty的颜色就显示的舒服一点了]]></content>
      <tags>
        <tag>WINDOWS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IT人生：2013年过去，2014年新的开始和规划]]></title>
    <url>%2F2014%2F01%2F01%2FIT%E4%BA%BA%E7%94%9F%EF%BC%9A2013%E5%B9%B4%E8%BF%87%E5%8E%BB%EF%BC%8C2014%E5%B9%B4%E6%96%B0%E7%9A%84%E5%BC%80%E5%A7%8B%E5%92%8C%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[今天阅读了8点1氪晚间版：年终安慰大盘点，很有意思。 http://www.36kr.com/t/208796，互联网大佬子在2013年都收获了不同的喜怒哀乐，围绕互联网一团乱战，难分高下。各家IT名博主都晒出了2013年总结和2014年的期望。那我也借上这股新风，小小总结和展望。 2013年依旧在云计算学习上花费了很多时间，自己很看这个领域未来几年后深刻改变人的生活的方式和服务接入方式。实现了一年一次的长途旅游规划，扩大了眼界。学会了开车，一个很基本的技能基本坚持了一个星期4天跑步的习惯，但是有时因为工作忙，找借口偷懒，这个需要在2014年坚决改正。庆幸认识到一个互相珍惜的人 2014坚决贯彻学习云计算衍生的周围技术实现另外一次长途旅游计划珍惜自己的身体，坚持锻炼珍惜和善待身边的人，更多的包容和理解人生大事努力筹划，具体不再展开…. 另外祝福所有的身边人能在马年一切顺利，马到成功。]]></content>
      <tags>
        <tag>IT职场</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[screen的使用记录]]></title>
    <url>%2F2013%2F12%2F11%2Fscreen%E7%9A%84%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[如果你用过devstack的话，会发现执行完stack.sh后，实际上启动一个screen会话，实现了多个进程共享一个物理终端的窗口管理器。这个screen会话里面包含了多个screen窗口，如下 1$ n-api 6$ q-svc 7$ q-agt 8$ q-dhcp 9$ q-l3 10$ q-meta 11$ q-metering 12$ n-cpu 13$ n-cond 14$ n-crt 15-$ n-sch 16$ n-novnc 17$ n-xvnc* 18$ n-cauth 19$ n-obj 20$ c-api 21$ c-sch 22$ c-vol 这样的好处很明显， 1.最大程度上实现一个物理终端的管理，简单直观。 可以实现不同人之间的协作共享 …. 那么看到上面的说明，我们直观的想法是创建一个类似devstack的多screen窗口会话，那么怎么创建呢，具体如下： (1) 首先要有screen会话的配置文件，目的是为了显示screen窗口的名字，这样比较直观。简单的配置如下，创建一个文件名为.screenrc 1hardstatus alwayslastline '%&#123;= .&#125; %-Lw%&#123;= .&#125;%&gt; %n%f %t*%&#123;= .&#125;%+Lw%&lt; %-=%&#123;g&#125;(%&#123;d&#125;%H/%l%&#123;g&#125;)' (2) 启动一个screen 会话 1screen -dmS test1 -c .screenrc (3) attach到对应的screen 1screen -r test1 (4) 对应的会显示如下： 10$ bash* (5) 创建一个新窗口 1CTRL+a c 显示如下： 10-$ bash 1$ bash* (6) 以此类推，可以创建2,3，…窗口 (7)对窗口重命名为自己喜欢的名字 1CTRL+a A 输入windows1 显示如下： 10-$ bash 1$ windows1* (8) 关闭当前窗口 1CTRL+a K (9) 进入拷贝/回滚模式 1CTRL+a ESC ESC 退出拷贝/回滚模式 更多使用： 1234CTRL+a n 切换到下一个窗口CTRL+a p 切换到前一个窗口CTRL+a d 暂时断开screen会话... (10) CTRL +a “ 从窗口列表选择要跳转的窗口 CTRL + a &apos; 会提示输入数字，切换窗口 CTRL +a N （1-9） 切换到对应的 1-9 窗口 更多的使用可以参考下面的参考资料： http://www.cnblogs.com/taosim/articles/3270336.html http://www.cnblogs.com/mchina/archive/2013/01/30/2880680.html http://www.ibm.com/developerworks/cn/aix/library/au-gnu_screen/ http://ningg.top/linux-cmd-screen/]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Eclipse Juno in Ubuntu 12.04 优化配置]]></title>
    <url>%2F2013%2F11%2F10%2FEclipse%20Juno%20in%20Ubuntu%2012.04%20%E4%BC%98%E5%8C%96%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[如果你在用Ubuntu 12.04和eclipse 开发环境，希望这篇文章包含的信息对你有帮助 前提： 本文是在virtualbox的虚拟机里运行的Ubuntu 12.04 问题： eclipse Juno 4.2的性能问题网上讨论的可谓多如牛毛，有兴趣的可以自行google 默认的eclipse 配置 + 默认的Ubuntu 配置会有些问题a) eclipse 有点慢， 切换tab， 代码跳转等。 （eclipse配置）b) 当鼠标停在某处，显示javadoc 或者pydoc的开不清楚。 （Ubuntu 配置） 解决：资料[1]给出了详细的解决方法，为了方便参看，特摘要如下： 问题1： 修改 eclipse.ini配置，增加如下几项 1234 -server -Xmn128m -Xms1024m -Xmx1024m 问题2： 三种方法（资料1给出了两种方法，下面的方法2,3） 方法1： 修改Ubuntu的theme， 见资料[2].，主要是安装gnome-tweak-tool，修改默认的配置theme： Ambiance为其他 方法2： 不修改theme， 修改颜色配置， 安装 gnome-color-chooser， change colors by going to Specific→Tooltips options 打开 方法3： 不修改theme，不安装gnome-color-chooser，直接修改theme的配置文件 /usr/share/themes/Ambiance/gtk-2.0/gtkrc 修改如下两种配置属性 （黑色字体，黄色背景） tooltip_fg_color:#000000 tooltip_bg_color:#f5f5c5 其他问题： 还有virtualbox本身的性能调整，具体不在这里展开了，资料[3]给出了一些说明 参考资料： http://ubuntu-user-tricks.blogspot.com/2012/09/3-things-to-do-after-installing-eclipse.html http://www.wikihow.com/Change-Themes-on-Ubuntu-with-Gnome-Tweak-Tool http://blog.jdpfu.com/2012/09/14/solution-for-slow-ubuntu-in-virtualbox]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[qpid的地址解析]]></title>
    <url>%2F2013%2F11%2F09%2Fqpid%E7%9A%84%E5%9C%B0%E5%9D%80%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[qpid的地址字符串按照一定语法进行匹配，确定相应的name subject和option 12345678910address := name [ SLASH subject ] [ ";" options ] name := ( part | quoted )+subject := ( part | quoted | SLASH )* quoted := STRING / ESC part := LBRACE / RBRACE / COLON / COMMA / NUMBER / ID / SYMoptions := map map := "&#123;" ( keyval ( "," keyval )* )? "&#125;" keyval "= ID ":" value value := NUMBER / STRING / ID / map / list list := "[" ( value ( "," value )* )? "]" 其中相应的pattern如下： 1234567891011121314LBRACE: \\&#123;RBRACE: \\&#125;LBRACK: \\[RBRACK: \\]COLON: :SEMI: ;SLASH: /COMMA: ,NUMBER: [+-]?[0-9]*\\.?[0-9]+ID: [a-zA-Z_](?:[a-zA-Z0-9_-]*[a-zA-Z0-9_])?STRING: "(?:[^\\\\"]|\\\\.)*"|\'(?:[^\\\\\']|\\\\.)*\'ESC: \\\\[^ux]|\\\\x[0-9a-fA-F][0-9a-fA-F]|\\\\u[0-9a-fA-F][0-9a-fA-F][0-9a-fA-F][0-9a-fA-F]SYM: [.#*%@$^!+-]WSPACE: [ \\n\\r\\t]+ 在qpid messaging的API实现中，python版本是如下解析： 12345678910111213141516171819202122 def address(self):#获取name name = toks2str(self.eat_until(SLASH, SEMI, EOF)) if name is None: raise ParseError(self.next()) #获取subject if self.matches(SLASH): self.eat(SLASH) subject = toks2str(self.eat_until(SEMI, EOF)) else: subject = None #获取option if self.matches(SEMI): self.eat(SEMI) options = self.map() else: options = None return name, subject, options 显然其中的分割符 SLASH 和SEMI进行了相应的划分如果我们在qpid构造地址的字符串编程中传入了违法的字符，那么地址解析验证中就会报错 参考资料： http://qpid.apache.org/releases/qpid-0.14/books/Programming-In-Apache-Qpid/html/ch02s04.html#table-node-properties http://qpid.apache.org/components/messaging-api/index.html]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux文件系统只读Read-only file system的快速解决方法]]></title>
    <url>%2F2013%2F10%2F29%2FLinux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8F%AA%E8%AF%BBRead-only%20file%20system%E7%9A%84%E5%BF%AB%E9%80%9F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[一个使用fsck来解决read-only file system的问题 http://www.ha97.com/5428.html 其实，遇到这个问题时，有时自己重启机器也可以解决，具体原因不知， 是否文件自身的修复还是其他？]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VM cannot start because the saved state Error]]></title>
    <url>%2F2013%2F10%2F22%2FVM%20cannot%20start%20because%20the%20saved%20state%20Error%2F</url>
    <content type="text"><![CDATA[今天遇到这个问题，发现有些人找到了解决办法，如下 解决办法: Oracle VM VirtualBox管理器主界面（GUI）控制-&gt;清除保存的状态(I) http://blog.sina.com.cn/s/blog_4c451e0e0101635c.html 其实这个状态一般可能是主机的不正常关机或者虚拟在保存过程中的强行退出容易出现的。多谢上面的一位兄弟指出的解决方法]]></content>
      <tags>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[qpid 接收消息编程]]></title>
    <url>%2F2013%2F10%2F18%2Fqpid%20%E6%8E%A5%E6%94%B6%E6%B6%88%E6%81%AF%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[qpid 是符合AMQP规范的apache 许可证的消息中间件，目前在openstack中作为一种可选的消息中间件服务配置，其他还有rabbitmq和zeroMQ 如果看过qpid的编程API文档的话，会看到比较简单的一个例子， 如下（接收消息打印消息内容） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#following code is from# http://qpid.apache.org/releases/qpid-0.24/messaging-api/python/examples/drain.htmlimport optparsefrom qpid.messaging import *from qpid.util import URLfrom qpid.log import enable, DEBUG, WARNparser = optparse.OptionParser(usage="usage: %prog [options] ADDRESS ...", description="Drain messages from the supplied address.")parser.add_option("-b", "--broker", default="localhost", help="connect to specified BROKER (default %default)")parser.add_option("-c", "--count", type="int", help="number of messages to drain")parser.add_option("-f", "--forever", action="store_true", help="ignore timeout and wait forever")parser.add_option("-r", "--reconnect", action="store_true", help="enable auto reconnect")parser.add_option("-i", "--reconnect-interval", type="float", default=3, help="interval between reconnect attempts")parser.add_option("-l", "--reconnect-limit", type="int", help="maximum number of reconnect attempts")parser.add_option("-t", "--timeout", type="float", default=0, help="timeout in seconds to wait before exiting (default %default)")parser.add_option("-p", "--print", dest="format", default="%(M)s", help="format string for printing messages (default %default)")parser.add_option("-v", dest="verbose", action="store_true", help="enable logging")opts, args = parser.parse_args()if opts.verbose: enable("qpid", DEBUG)else: enable("qpid", WARN)if args: addr = args.pop(0)else: parser.error("address is required")if opts.forever: timeout = Noneelse: timeout = opts.timeoutclass Formatter: def __init__(self, message): self.message = message self.environ = &#123;"M": self.message, "P": self.message.properties, "C": self.message.content&#125; def __getitem__(self, st): return eval(st, self.environ)conn = Connection(opts.broker, reconnect=opts.reconnect, reconnect_interval=opts.reconnect_interval, reconnect_limit=opts.reconnect_limit)try: conn.open() ssn = conn.session() rcv = ssn.receiver(addr) count = 0 while not opts.count or count &lt; opts.count: try: msg = rcv.fetch(timeout=timeout) print opts.format % Formatter(msg) count += 1 ssn.acknowledge() except Empty: breakexcept ReceiverError, e: print eexcept KeyboardInterrupt: passconn.close() connection和session是1对多的关系，每个session保证消息的顺序接收，让session创建对应的sender和receiver，这里我们只需要创建receiver 这个程序看起来很好，如果直接传一个地址， 比如（我们想要接收openstack glance的message）运行如下：python drain.py -b admin/qpid@localhost glance 如果我们想要实现连接断掉后重新自动连接，我们可以传入参数 -r上面的程序有个问题，如果没有收到消息就断开连接了。 新需求1： 我们要实现持续的监听接收消息， 改一下 1234567try: msg = rcv.fetch(timeout=timeout) print opts.format % Formatter(msg) count += 1 ssn.acknowledge()except Empty: time.sleep(0.5) 这样就可以了。 还不行， 新需求2：我们要实现断后重新自动连接， 可以， 传入参数 -r， 解决了 问题出现了，你会发现在service qpidd restart后，程序会抛出exceptionqpid.messaging.exceptions.NotFound: no such queue: glance 新需求3：显然这是由于我们创建的queue不是durable的，所以需要在qpid restart后能够正常运行，而不是退出。这就需要我们创建的queue能够在接收到消息的时候自动创建完成， 解决方法： rcv = ssn.receiver(addr + “; {create: always}”) 这样就完成queue的按需创建 新需求4： qpid 默认的reconnect上面的是基于固定interval，我们想改变重新建立连接的算法，实现2的指数式建立连接解决方法： 我们写入自己的自动重连方法， 一个简单的例子如下： 12345678910111213141516171819202122232425def reconnect(): global rcv global ssn attempt = 0 delay = 1 while True: if conn.opened(): try: conn.close() except exceptions.ConnectionError: pass attempt += 1 print "The %s time attempt for reconnecting qpid server" % str(attempt) try: connection_init() conn.open() except exceptions.ConnectionError, e: delay = min(2 * delay, 60) time.sleep(delay) pass else: break print "qpid server reconnection created" ssn = conn.session() rcv = ssn.receiver(addr + "; &#123;create: always&#125;") 这样就OK了 总结： 经过上面的需求变化，我们新的接收消息程序如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129import optparseimport timefrom qpid.messaging import *from qpid.util import URLfrom qpid.log import enable, DEBUG, WARNparser = optparse.OptionParser(usage="usage: %prog [options] ADDRESS ...", description="Drain messages from the supplied address.")parser.add_option("-b", "--broker", default="localhost", help="connect to specified BROKER (default %default)")parser.add_option("-c", "--count", type="int", help="number of messages to drain")parser.add_option("-f", "--forever", action="store_true", help="ignore timeout and wait forever")parser.add_option("-r", "--reconnect", action="store_true", help="enable auto reconnect")parser.add_option("-i", "--reconnect-interval", type="float", default=3, help="interval between reconnect attempts")parser.add_option("-l", "--reconnect-limit", type="int", help="maximum number of reconnect attempts")parser.add_option("-t", "--timeout", type="float", default=0, help="timeout in seconds to wait before exiting (default %default)")parser.add_option("-p", "--print", dest="format", default="%(M)s", help="format string for printing messages (default %default)")parser.add_option("-v", dest="verbose", action="store_true", help="enable logging")opts, args = parser.parse_args()if opts.verbose: enable("qpid", DEBUG)else: enable("qpid", WARN)if args: addr = args.pop(0)else: parser.error("address is required")if opts.forever: timeout = Noneelse: timeout = opts.timeoutcount = 0rcv = Noneconn = Nonessn = Noneclass Formatter: def __init__(self, message): self.message = message self.environ = &#123;"M": self.message, "P": self.message.properties, "C": self.message.content&#125; def __getitem__(self, st): return eval(st, self.environ)def reconnect(): global rcv global ssn attempt = 0 delay = 1 while True: if conn.opened(): try: conn.close() except exceptions.ConnectionError: pass attempt += 1 print "The %s time attempt for reconnecting qpid server" % str(attempt) try: connection_init() conn.open() except exceptions.ConnectionError, e: delay = min(2 * delay, 60) time.sleep(delay) pass else: break print "qpid server reconnection created" ssn = conn.session() rcv = ssn.receiver(addr + "; &#123;create: always&#125;")def fetch(): global count while not opts.count or count &lt; opts.count: try: msg = rcv.fetch(timeout=timeout) print opts.format % Formatter(msg) count += 1 ssn.acknowledge() except Empty: time.sleep(0.5) except exceptions.ConnectionError, e: reconnect() except Exception, e: print e raise edef connection_init(): global conn conn = Connection(opts.broker, reconnect=opts.reconnect, reconnect_interval=opts.reconnect_interval, reconnect_limit=opts.reconnect_limit)try: connection_init() conn.open() ssn = conn.session() rcv = ssn.receiver(addr + "; &#123;create: always&#125;") fetch()except ReceiverError, e: print eexcept KeyboardInterrupt: passexcept exceptions.ConnectionError, e: reconnect()conn.close()]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DevOps-chef的hello-world cookbook]]></title>
    <url>%2F2013%2F09%2F20%2FDevOps-chef%E7%9A%84hello-world%20cookbook%2F</url>
    <content type="text"><![CDATA[在上一篇的文章中，我们简单了介绍chef的环境搭建，那么现在你肯定就跃跃欲试如何创建一个cookbook，真正体会自动化的配置管理的便捷之处。废话少说，我们选取简单的hello-world为例子， 需求： 1.在workstation可以让多个节点自动化创建hello-world.txt文件2.文件的owner是test， group是test 假设： test用户和组是在节点上已经存在 实施：（下面的步骤如果没有特殊说明，都是在workstation上运行的） 创建cookbook 1knife cookbook create hello_world 添加内容到reciperecipe就是主要的控制内容，让节点完成具体的操作。 cat recipes/default.rb 如下： 123456789101112131415## Cookbook Name:: hello_world# Recipe:: default## Copyright 2013, YOUR_COMPANY_NAME## All rights reserved - Do Not Redistribute## recipes/default.rbtemplate "#&#123;ENV['HOME']&#125;/hello-world.txt" do source 'hello-world.txt.erb' mode '0644' owner 'test' group 'test'end 上面的指令是：在用户对应的目录（Linux/Unix：~ Windows: %HOMEPATH%）下创建一个文件hello-world.txt：内容是放在hello-world.txt.erb模板里面。 添加对应的模板 123456789 cat templates/default/hello-world.txt.erb 如下：&lt;% # templates/default/hello-world.txt.erb %&gt;Hello World!Chef Version: &lt;%= node[:chef_packages][:chef][:version] %&gt;Platform: &lt;%= node[:platform] %&gt;Version: &lt;%= node[:platform_version] %&gt; 上传cookbook到chef server 1knife cookbook upload 'hello_world' 将相应的cookbook添加到对应节点run_list 1knife node run_list add 'hello_world' 其中的node name，可以通过knife node list查看 检查相应的run list是否被node包含 123456789 $ knife node show Node Name: Environment: _defaultFQDN: IP: Run List: recipe[hello_world]Roles: Recipes: hello_worldPlatform: ubuntu 12.04 节点应用cookbook 1knife ssh name: -x -P "sudo chef-client" 验证node是否正确配置， 登录到node节点，检查 12345678 cat ~/hello-world.txt 如下：Hello World!Chef Version: 11.6.0Platform: ubuntuVersion: 12.04 可见按照上面的步骤我们就顺利的完成了一个很简单的cookbook开发，熟悉了流程后，后面可以继续研究复杂cookbook的编写。 其他参考： http://technology.customink.com/blog/2012/05/28/provision-your-laptop-with-chef-part-1/ https://wiki.opscode.com/plugins/viewsource/viewpagesrc.action?pageId=18645173]]></content>
      <tags>
        <tag>系统运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DevOps-chef的多节点环境搭建]]></title>
    <url>%2F2013%2F09%2F20%2FDevOps-chef%E7%9A%84%E5%A4%9A%E8%8A%82%E7%82%B9%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[前言：前段时间一直想试验一下DevOps的一些配置管理工具，后来因为某些原因，就重点研究了chef。以自己的机器搭建了一个典型的多节点实验环境。 架构：根据官方的chef的架构介绍，主要包括三大部分， chef-server chef workstation chef-node source:http://docs.opscode.com/chef_overview.html 上面的这个图很清晰的表达了各部分的联系，所以推测我们需要安装的主要是server和workstation部分，而node应该是通过客户端来让chef自动化安装的 实施： 下面我们介绍如何实施一个代表性的环境 环境的前提配置: 安装的OS环境： Ubuntu 12.04 虚拟化软件： VirtualBox 使用的网络类型： Host-Only NAT 假设用户都自己配置好了， 主机对应的FQDN server 的安装 http://docs.opscode.com/install_server.html 过程比较简单， 就是安装包，然后运行配置命令。具体如下：chef_11.6.0-1.ubuntu.12.04_amd64.deb 安装： 1sudo dpkg -i chef-server_11.0.8-1.ubuntu.12.04_amd64.deb 配置: 1sudo chef-server-ctl reconfigure 验证安装： 1sudo chef-server-ctl test 其实这个似乎不能全部pass，感觉chef的集成测试集可能有些问题 workstation 的安装 （http://docs.opscode.com/chef/install_workstation.html）过程稍微比server安装复杂，但还算简单明了， 主要是安装client ，配置client到server访问。具体如下： 2.1 安装client： 1sudo dpkg -i chef_11.6.0-1.ubuntu.12.04_amd64.deb 2.2 安装配置chef-repo: 1git clone git://github.com/opscode/chef-repo.git 因为chef-repo是存放cookbooks的地方，knife命令行工具会从chef-repo上传数据到chef-server， 这样chef-client就从server可以应用相应的cookbooks了，所以我们可以知道，chef-repo需要配置和server的访问, 主要包括，.pem files and knife.rb files 2.3 创建.chef目录 在 chef-repo目录下，创建.chef目录，并且修改.gitignore文件，添加 .chef 2.4 配置： 1knife configure --initial 注意： 输入相关的信息，主要是server的url，client的key，client注册server所需要的validator和 validator private key（默认的是chef-validator和server端 /etc/chef/validation.pem 文件） 还有admin的private key，所以我们需要从server端copy两个文件到workstation机器上， （才能在运行knife configure输入恰当的private key 信息） admin 和 validator的private key 文件，即： admin.pem validation.pem， 12scp root@:/etc/chef/admin.pem ./scp root@:/etc/chef/validation.pem ./ 2.5 将knife.rb和pem文件移到 chef-repo的.chef目录下 1cp ** /.chef 2.6 验证 client 是否工作 123knife client listknife user list 就可以输出相关的server端的信息了 Node 的自动化安装 （http://docs.opscode.com/install_bootstrap.html） 下面的是在workstation上运行的，比较简单： 3.1 bootstrap 1knife bootstrap -x -P --sudo 3.2 验证 node 1knife client list 正确的话，就会输出你的node节点的名字FQDN。 注意： 因为workstation 在bootstrap的时候是需要ssh到node的，而且node也是需要到server访问的 （依靠FQDN，就是你配置的server url),那么就意味着， node需要安装ssh server； node是可以解析server的FQDN的， 可以在/etc/hosts添加相应的信息 总结： 经过1,2,3步骤，我们就搭建一个典型的chef 环境，包括三个节点，server， workstation和node后面我们会给出一篇文章来说明如何创建一个cookbook，并且让node应用这个cookbook。 其他参考资料： http://www.opscode.com/blog/2013/03/11/chef-11-server-up-and-running/ http://dev.classmethod.jp/server-side/chef-server-install/ http://docs.opscode.com/install.html http://docs.opscode.com/chef_overview.html http://jtimberman.housepub.org/blog/2013/02/10/install-chef-11-server-on-centos-6/]]></content>
      <tags>
        <tag>系统运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell的command和function分工]]></title>
    <url>%2F2013%2F09%2F08%2Fshell%E7%9A%84command%E5%92%8Cfunction%E5%88%86%E5%B7%A5%2F</url>
    <content type="text"><![CDATA[如果你经常编写shell脚本，有时会碰到类似的问题：shell中定义了一个函数，这个函数和系统内建的命令同名， 例如 1234function cp() &#123; echo "This is a test" cp &#125; 显然上面的是一个递归函数，这个递归没有退出条件，最后必然是导致Segmentation fault 如果我们不希望cp()里的继续调用自己，而是系统拷贝的命令，怎么办？答案就是使用command命令，代码如下 1234function cp() &#123; echo "This is a test" command cp ...&#125; 这样就保证了系统命令覆盖函数的优先使用权。]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于监控远端主机开放端口的3种方法]]></title>
    <url>%2F2013%2F09%2F03%2F%E5%85%B3%E4%BA%8E%E7%9B%91%E6%8E%A7%E8%BF%9C%E7%AB%AF%E4%B8%BB%E6%9C%BA%E5%BC%80%E6%94%BE%E7%AB%AF%E5%8F%A3%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[telnet 1telnet nc 1nc -z -w5 ; echo $? nmap 1sudo nmap -sS -v -p 优缺点： nc nmap便于脚本化 nmap需要单独安装，nc一般ubuntu下自己安装了 telnet 在windows下用的比较多]]></content>
      <tags>
        <tag>系统运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Devstack安装碰到python package的版本问题]]></title>
    <url>%2F2013%2F09%2F03%2FDevstack%E5%AE%89%E8%A3%85%E7%A2%B0%E5%88%B0python%20package%E7%9A%84%E7%89%88%E6%9C%AC%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[因为一直在用devstack在一台虚拟机器上进行安装，openstack的havana的开发过程相关的依赖版本会不时的更新，最近安装devstack发现总会出现一些service启动不了直接查看log一般是 version 不匹配，或者缺少相关的module，显然是相关的package安装不匹配的缘故，如何解决 1sudo pip install --upgrade -r /opt/stack/nova/requirements.txt 如果安装还是失败，报version不匹配，那就在 /usr/local/lib/python2.7/dist-packages/ 删除相应的package，（如果你的pip uninstall可以work的话， 那就最好用pip uninstall）再运行上面的命令。]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[qpid service 的root引发的权限问题]]></title>
    <url>%2F2013%2F08%2F29%2Fqpid%20service%20%E7%9A%84root%E5%BC%95%E5%8F%91%E7%9A%84%E6%9D%83%E9%99%90%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[最近使用的一台虚拟机是root登录操作的，使用yum安装完qpid后，设置可以访问的用户名和密码时候，犯了一个低级错误，直接使用下面的命令 1saslpasswd2 -f /var/lib/qpidd/qpidd.sasldb -u QPID qpid 使用qpid-tools查看queues的时候，发现老是出现认证无法通过，但是直接qpidd运行没有问题，查看了一下log发现，/var/log/messages 1unable to open Berkeley db /var/lib/qpidd/qpidd.sasldb: Permission denied 检查了一下/var/lib/qpidd/qpidd.sasldb的权限，发现用户为root（rw)，难怪如此，因为service 启动是以qpidd用户来运行的，没有w的权限。 解决方法： 设置 /var/lib/qpidd 用户和用户组为qpidd:qpidd 其实原来自己写过一篇qpid的setup的文章，都记录要配置这个，只是实际用起来偶犯健忘了。]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[eclipse36，eclipse42，java的融合问题]]></title>
    <url>%2F2013%2F08%2F24%2Feclipse36%EF%BC%8Ceclipse42%EF%BC%8Cjava%E7%9A%84%E8%9E%8D%E5%90%88%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[昨天被Junit搞的精疲力尽，使用的eclipse3.6一路出现莫名其妙的jvm运行错误， 最初怀疑java配置的问题，因为所有的代码都是在java7运行的，虽然在eclipse设置installed jre是java7，但是系统（windows）的系统java_home没有更改，还是原来的java6。所以更改系统的java_home，发现仍然存在问题，于是再仔细看了一下stack trace： 123456789101112131415161718192021222324252627282930313233343536373839404142at java.lang.J9VMInternals.initialize(J9VMInternals.java:176)at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:68)at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)at java.lang.reflect.Constructor.newInstance(Constructor.java:528)at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187)at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236)at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)at org.junit.runners.ParentRunner.run(ParentRunner.java:300)at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:49)at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)at org.eclipse.pde.internal.junit.runtime.RemotePluginTestRunner.main(RemotePluginTestRunner.java:62)at org.eclipse.pde.internal.junit.runtime.CoreTestApplication.run(CoreTestApplication.java:23)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:76)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:602)at org.eclipse.equinox.internal.app.EclipseAppContainer.callMethodWithException(EclipseAppContainer.java:587)at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:198)at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:353)at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:180)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:76)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:602)at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:629)at org.eclipse.equinox.launcher.Main.basicRun(Main.java:584)at org.eclipse.equinox.launcher.Main.run(Main.java:1438)at org.eclipse.equinox.launcher.Main.main(Main.java:1414) 发现和equinox相关，检查target的Equinox是对应eclipse42的，会不会eclipse42的equinox在eclipse36跑会有问题，于是，切换eclipse环境，用了eclipse42后，发现确实没有问题了。 虽然不敢肯定根本原因是不是这个，但是确实eclipse会提示运行不匹配的版本会有潜在问题。之所有一直用eclipse36，是因为原来没发现类似的问题，好吧，那就迁到eclipse42吧。]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pep8的问题(ubuntu12.04和Redhat 6.4)]]></title>
    <url>%2F2013%2F08%2F17%2Fpep8%E7%9A%84%E9%97%AE%E9%A2%98(ubuntu12.04%E5%92%8CRedhat%206.4)%2F</url>
    <content type="text"><![CDATA[前几天调试一个build失败的问题，发现服务器上的pep8检查总是无法通过，但是开发环境确没什么问题。经过调查发现，Openstack的pep8已经采用了1.4.5的版本，开发环境用的原来的1.1，新的pep8采用了更严格的格式检查，所以导致开发环境无法检查出这些问题。 ubuntu 12.04和Redhat 6.4对应的pep8源版本过旧，所以如果你用的默认的pep8，那么也会有这个问题。 而且eclipse的pydev插件用的也是旧的pep8检查。 解决方法： 升级对应的pep8， 1pip install --upgrade pep8==1.4.5 如果你用的是python的虚拟环境，要检查对应的pep8版本是否一致，不一致的话，那就是requires文件里的版本配置的不对]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux shell你所不知道的$($*和$@)]]></title>
    <url>%2F2013%2F07%2F30%2FLinux-shell-%E7%89%B9%E6%AE%8A%24%E7%AC%A6%E5%8F%B7%2F</url>
    <content type="text"><![CDATA[在$的相关的特殊符号中，有以下的几种需要注意的区别 1） 和 @在shell中虽然都是展开位置参数可以用$@和$，但是两种有很大的差别，特别是在双引号的扩展下，比如 (a) 123for i in $*; do echo "--$i"done (b) 123for i in $@; do echo "**$i"done 如果传入的参数是”hi ni” 对于(a), 12-- hi-- ni 对于(b)， 12** hi** ni 但是如果你说我传入的“hi ni”是一个参数（$1)，我不希望它输出为多个参数那么我们更改脚本，改为 123for i in "$*"; do echo "--$1"done 123for i in "$@"; do echo "**$i"done 如果传入的参数是”hi ni” 12-- hi ni** hi ni 现在是相同的，没问题，但是如果传入的参数是空，那么你会发现下面的输出结果 1-- 这是因为（man bash) 12"$*" is equivalent to "$1c$2c...", where c is the first character of the value of the IFS variable."$@" is equivalent to "$1" "$2" ... 显然是”$*”的展开是包含了一个空格，关于IFS的介绍，可以参看参考[1] 同样，我们可以知道如果设置IFS的话，那么多个参数的情况下，”$*”和”$@”输出是不一致的，比如(如果设置IFS=”,”)输入参数， &quot;hi ni&quot; &quot;you&quot; 123-- hi ni,you** hi ni** you 参考：http://en.wikipedia.org/wiki/Internal_field_separator]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于virtualbox的 4.2.0的一个问题（guest os redhat 6.4)]]></title>
    <url>%2F2013%2F07%2F20%2F%E5%85%B3%E4%BA%8Evirtualbox%E7%9A%84%204.2.0%E7%9A%84%E4%B8%80%E4%B8%AA%E9%97%AE%E9%A2%98%EF%BC%88guest%20os%20redhat%206.4)%2F</url>
    <content type="text"><![CDATA[问题：如果你使用virtualbox 4.2.0会发现一个问题，安装完redhat 6.4操作系统后，安装增强功能时，无法正常的编译， 1error: unknown field ‘reclaim_buffers’ specified in initializer 这个是virtualbox的一个bug，参看 https://www.virtualbox.org/ticket/11586 解决方法： link中提到了，修改 1sudo vi /usr/src/vboxguest-4.2.0/vboxvideo/vboxvideo_drm.c 如下 123109 #if LINUX_VERSION_CODE &lt; KERNEL_VERSION(3, 6, 0)110 // .reclaim_buffers = drm_core_reclaim_buffers,111 #endif 然后，运行 1/etc/init.d/vboxadd setup 这样就可以正常的编译了。你不可以运行那个install脚本，因为那样会把修改的再次用原始的代码覆盖，编译还是会失败。 其他问题： 好像这个版本的增强功能，还有其他问题，编译成功也无法使用无缝模式的。估计这个版本没有对redhat 6.4测试过或者不正式支持，无从得知。]]></content>
      <tags>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建ISO映像解决问题]]></title>
    <url>%2F2013%2F07%2F20%2F%E5%88%9B%E5%BB%BAISO%E6%98%A0%E5%83%8F%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题来源： 我找不到原始的iso镜像了，只在一台机器上发现拷贝的文件，所以我需要利用这些文件制作成iso来安装。 最初的参考资料： 如果参考 http://linuxlookup.com/howto/create_iso_image_file_linux中的mkisofs方法在制作ISO的时候会遇到问题，无法正常的boot 123456789101112131415Steps to followCreate an ISO image from optical mediaIn this example, we're going to copy the contents of a disk in the CD/DVD drive (/dev/cdrom) to an ISO image file. Open a terminal window and type the following at the command line.dd if=/dev/cdrom of=/directory/example.isoNotations:- dd is the program used to convert and copy a file.- if defines an input file.- of defines an output file.- iso is the resulting ISO image file.Create an ISO image from files in a directoryTo create an ISO image from files within a directory is just as simple. State an output directory and name of the ISO to create, along with a source directory. For example:mkisofs -o /home/linuxlookup/example.iso /source/directory/ 问题: 关于从directory制作iso会遇到几个问题， “mkisofs: Uh oh, I cant find the boot catalog directory “ 需要确保，isolinux/isolinux.bin 和 isolinux/boot.cat 相对应的iso目录正确参考：http://www.linuxquestions.org/questions/linux-software-2/mkisofs-returns-error-mkisofs-uh-oh-i-cant-find-the-boot-catalog-directory-844905/ boot image ‘./isolinux/isolinux.bin’ has not an allowable size. 这个是因为默认的是floppy，解决方法你需要加入: -hard-disk-boot 或者 -no-emul-boot.参考：http://www.linuxquestions.org/questions/red-hat-31/mkisofs-error-boot-image-%27-isolinux-isolinux-bin%27-has-not-an-allowable-size-358439/ 解决方法: 我的例子（redhat x86_64 6.4 ISO)： 1sudo mkisofs -o ~/images/rhels64.iso -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-info-table -l -r -J -v -allow-lowercase ~/images/rhels6.4/x86_64/ 说明：关于link中给出的 -boot-load-size 4，这个我的没有指出也可以，是因为， 12-boot-load-size load_sectors Specifies the number of "virtual" (512-byte) sectors to load in no-emulation mode. The default is to load the entire boot file. Some BIOSes may have problems if this is not a multiple of 4.]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈谈Nova(osapi_compute)-extension]]></title>
    <url>%2F2013%2F07%2F04%2F%E8%B0%88%E8%B0%88Nova(osapi_compute)-extension%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617[composite:osapi_compute]use = call:nova.api.openstack.urlmap:urlmap_factory/: oscomputeversions/v1.1: openstack_compute_api_v2/v2: openstack_compute_api_v2[composite:openstack_compute_api_v2]use = call:nova.api.auth:pipeline_factorynoauth = faultwrap sizelimit noauth ratelimit osapi_compute_app_v2keystone = faultwrap sizelimit authtoken keystonecontext ratelimit osapi_compute_app_v2keystone_nolimit = faultwrap sizelimit authtoken keystonecontext osapi_compute_app_v2[app:osapi_compute_app_v2]paste.app_factory = nova.api.openstack.compute:APIRouter.factory 1) #create wsgi service 1server = service.WSGIService('osapi_compute') ---&gt; 2)# load WSGI applications from paste configurations 12wsgi.Loader()self.app = self.loader.load_app(name) ---&gt; 3) # urlmap_factory, 1234for path, app_name in local_conf.items(): path = paste.urlmap.parse_path_expression(path) app = loader.get_app(app_name, global_conf=global_conf) ---&gt; urlmap[path] = app 4) #pipeline_factory 12345app = loader.get_app(pipeline[-1]) --&gt;filters.reverse()for filter in filters: app = filter(app)return app 这里的重要之处在于，通过app = filter(app) 将后面的filter app作为前面的middleware的构造初始化，从而形成整个call stack，比如 12keystone = faultwrap sizelimit authtoken keystonecontext ratelimit osapi_compute_app_v2app = ratelimit(osapi_compute_app_v2) 这样ratelimit middleware的就会call osapi_compute_app_v2，所以 3) 返回了第一个middleware的urlmap，从而 WSGI server可以在接收到/v2/***进入middleware的 call stack ，最终根据APIRouter的url和controller的映射配置，进行API 的request的具体处理。 5) #APIRouter 12345678910111213141516171819202122232425262728293031323334353637383940414243 class APIRouter(nova.api.openstack.APIRouter): ExtensionManager = extensions.ExtensionManager nova.api.openstack.APIRouter ---&gt; if ext_mgr is None: if self.ExtensionManager: ext_mgr = self.ExtensionManager() ---&gt; else: raise Exception(_("Must specify an ExtensionManager class")) mapper = ProjectMapper() self.resources = &#123;&#125; self._setup_routes(mapper, ext_mgr) (6) self._setup_ext_routes(mapper, ext_mgr) (7) self._setup_extensions(ext_mgr) (8) :ExtensionManagerself._load_extensions() ---&gt;load_extension() ---&gt; :ExtensionDescriptor ext_mgr.register(self):ExtensionManagerdef _load_extensions(self): """Load extensions specified on the command line.""" extensions = list(self.cls_list) for ext_factory in extensions: try: self.load_extension(ext_factory) except Exception as exc: LOG.warn(_('Failed to load extension %(ext_factory)s: ' '%(exc)s') % locals())After all extensions have been loaded, (those extensions are configured in nova.conf, for example,osapi_compute_extension=nova.api.openstack.compute.contrib.standard_extensions 6) self._setup_routes(mapper, ext_mgr) 1for openstack core api, setup necessary routes 7) self._setup_ext_routes(mapper, ext_mgr) 123456789101112for each resource in ext_mgr.get_resources() wsgi_resource = wsgi.Resource(resource.controller, inherits=inherits) :Resource self.register_actions(controller)# Generate routes for a controller resource# mapping a resource is about handling creating, viewing, and editing that resource mapper.resource(resource.collection, resource.collection, **kargs) 8) self._setup_extensions(ext_mgr) 123456789101112131415161718192021222324252627for each extension in returned ControllerExtension objects get_controller_extensions ... resource = self.resources[collection] resource.register_actions(controller) resource.register_extensions(controller):ExtensionDescriptor (append here for easy reference) def get_resources(self): """List of extensions.ResourceExtension extension objects. Resources define new nouns, and are accessible through URLs. """ resources = [] return resources def get_controller_extensions(self): """List of extensions.ControllerExtension extension objects. Controller extensions are used to extend existing controllers. """ controller_exts = [] return controller_exts 9) manage a WSGI server, serving a WSGI application —&gt; 12345self.server = wsgi.Server(name, self.app, host=self.host, port=self.port)service.serve(server, workers=server.workers)]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[devstack 的 glance-api启动失败的原因]]></title>
    <url>%2F2013%2F06%2F20%2Fdevstack%20%E7%9A%84%20glance-api%E5%90%AF%E5%8A%A8%E5%A4%B1%E8%B4%A5%E7%9A%84%E5%8E%9F%E5%9B%A0%2F</url>
    <content type="text"><![CDATA[devstack 更新了一下，在recllone的时候，发现有个现象 glance-api 无法响应请求。 经过调查发现，原来自己的在glance文件目录下创建过bin （glance 从havana取消bin目录了）当时是import 到eclipse工程中用来调试用的。 devstack reclone 不会删除新创建的目录，所以导致glance-manage db_sync失败，导致没有数据库glance。所以api请求导致meta query失败，500错误。]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智能钱包的故事]]></title>
    <url>%2F2013%2F05%2F14%2F%E6%99%BA%E8%83%BD%E9%92%B1%E5%8C%85%E7%9A%84%E6%95%85%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[爱范网一个不错的文章介绍了胡俊峰团队的智能钱包设计，很有意思。 物联网虽然提了很久，感觉好多是些原型系统。感知计算以Google class为代表引发了一系列的革新，智能手表，智能腕带等。在这个移动互联网横行的年代，越来越多的创新来自于移动生活，smart life 就是给你带了生活方式的一种改变，这种改变给人们普通的生活增添了一些乐趣和互动，我觉得这便是很大的进步了。 期待看到更多类似智能钱包的产品出现，移动正在改变生活。]]></content>
      <tags>
        <tag>IT业界</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Devstack下的ceilometer无法统计cinder数据]]></title>
    <url>%2F2013%2F05%2F07%2FDevstack%E4%B8%8B%E7%9A%84ceilometer%E6%97%A0%E6%B3%95%E7%BB%9F%E8%AE%A1cinder%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[前言解释： Devstack：快捷搭建openstack开发环境的工具ceilometer： Openstack下的一个project，用于统计各种资源，比如instance，image等的使用情况。 问题： 启动ceilometer后会发现相关的cinder的部分没有统计。 原因： devstack关于cinder的配置部分和ceilometer在notification相关的的exchange name的配置不同。在cinder.conf中， 1control_exchange=openstack 而在ceilometer的ceilometer.conf中，默认的是 1cinder_control_exchange=cinder devstack没有对这里进行特殊配置，两个exchange不一致，当然cinder的notification就不会被收到。 ceilometer就无法更新cinder使用的情况。 解决方法： 修改cinder.conf中的exchange name为cinder，重新启动cinder相关的服务，即可。]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[追寻生命的意义]]></title>
    <url>%2F2013%2F04%2F27%2F%E8%BF%BD%E5%AF%BB%E7%94%9F%E5%91%BD%E7%9A%84%E6%84%8F%E4%B9%89%2F</url>
    <content type="text"><![CDATA[弗兰克尔继弗洛伊德精神分析，阿德勒个体心理学之后的 “维也纳第三心理治疗学派”的意义治疗的创始人。 追寻生命的意义一书以作者在纳粹集中营的经历为例，介绍了意义治疗的方法和理论，对于理解不同心理状态案例治疗和人生的重新认识具有很好的说明指导作用。 IT人们读了也对自己的人生有了新的理解。 注：博文站点没有合适的分类，只能选个尽可能接近的，下次得向管理员反映一下。呵呵。]]></content>
      <tags>
        <tag>闲散</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows 技巧可以运用在工作中]]></title>
    <url>%2F2013%2F04%2F18%2FWindows%20%E6%8A%80%E5%B7%A7%E5%8F%AF%E4%BB%A5%E8%BF%90%E7%94%A8%E5%9C%A8%E5%B7%A5%E4%BD%9C%E4%B8%AD%2F</url>
    <content type="text"><![CDATA[http://www.zhihu.com/question/20592820/answer/16134146 很不错的介绍，虽然用windows 7， 但有的还真不知道快捷切换。]]></content>
      <tags>
        <tag>WINDOWS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DB2 修改字段允许为NULL]]></title>
    <url>%2F2013%2F04%2F16%2FDB2%20%E4%BF%AE%E6%94%B9%E5%AD%97%E6%AE%B5%E5%85%81%E8%AE%B8%E4%B8%BANULL%2F</url>
    <content type="text"><![CDATA[DB2 修改允许 null 因为有的column会有constraint约束，所以无法直接drop not null必须先删除constraint，具体如下： select CONSTNAME, type from SYSCAT.TABCONST where TABNAME=’T’ T 是table的名字，大写 找到对应的constraint名字 然后执行， 1alter table T drop unique 'unique name' 然后对表的字段drop not null 1alter table T ALTER 'field name' drop not null 然后reorg table 1reorg table T 参考资料： http://bytes.com/topic/db2/answers/690847-how-change-column-not-null-null]]></content>
      <tags>
        <tag>DB2/Informix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[百望山到植物园徒步穿越]]></title>
    <url>%2F2013%2F04%2F04%2F%E7%99%BE%E6%9C%9B%E5%B1%B1%E5%88%B0%E6%A4%8D%E7%89%A9%E5%9B%AD%E5%BE%92%E6%AD%A5%E7%A9%BF%E8%B6%8A%2F</url>
    <content type="text"><![CDATA[从黑山扈出发，（这个口进去不用门票）沿着百望山脉一直走，林中前人踏出来的路不是很宽敞，而且多地都不平坦，所以很多路程还是考验耐力和体力的。 也记不清楚到底翻过几座山了，走的最快的是沿着山脊的那几段，后面走了一段迂回路。在路上遇上了一群学生和家长，有段下山的坡比较陡，他们的队伍就拉好绳子一个一个下，十几个人大概用了半个多小时下坡。我们在他们后面，考虑到前面那条路被他们的人占据了，而且因为年龄小的学生走的比较慢，于是我们绕过他们走的那条道下去，所以绕了一段距离。 3个小时后，我们就翻山到植物园的地界了，临近12:30，我们补充了一下水和食物。继续行进，后面的一段距离很多盘山路，所以很耗费体力，大概1个多小时后，就到植物园里面了，然后我们找到去香山的山路，准备继续前行。大概走了不到1个小时，天工作雨，不一会就下大了。考虑到雨天山路滑，而且到香山的距离还有两座山，现在的体力恐怕不够支撑。我们商量了决定返回植物园，结束行程。 回来的路上虽有点遗憾，但基本完成了穿越行程，身体拉了炼，玩的比较尽兴。好了，吃火锅，不写了。]]></content>
      <tags>
        <tag>探索</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM default locale的问题]]></title>
    <url>%2F2013%2F04%2F01%2FJVM%20default%20locale%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[前几天调试一个问题，搜集了一些关于JVM locale资料介绍，总结如下： Windows 7 Before Java 7对于java 7之前的JVM的default locale和操作系统format的设置相关，具体配置在，控制面板–》地区和语言–》Formats Java 7java7 采用根据windows 7中的display language具体配置在，控制面板–》地区和语言–》keyboards and language一般的系统如果没装Language Interface Pack，这个不会显示。具体可以点击里面的 How do I get additional display languages?参看微软的说明 Linux的配置， 简单，分为永久设置 和 登录会话临时设置， vi /etc/sysconfig/i18n 修改如下 1LANG="zh_CN.UTF-8" 临时，export LANG=zh_CN.UTF-8 怎么确认JVM的default locale， 12345678import java.util.Locale;public class LocaleTest &#123; public static void main(String[] args) &#123; System.out.println(Locale.getDefault()); &#125;&#125; 参考资料: http://stefanhendriks.wordpress.com/2012/02/http://stackoverflow.com/questions/7107972/java-7-default-localehttp://stackoverflow.com/questions/10707238/locale-getdefault-returns-en-alwayshttp://blog.ej-technologies.com/2011/12/default-locale-changes-in-java-7.html]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PKI token 不工作的解决]]></title>
    <url>%2F2013%2F03%2F13%2FPKI%20token%20%E4%B8%8D%E5%B7%A5%E4%BD%9C%E7%9A%84%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[在keystone设置PKI的token方式下，出现一个奇怪的问题， keystone自己能工作，但是其他的service 比如 glance，nova 就是不能正常使用，起初怀疑是conf文件的参数配置问题，后来经过多次尝试，终于发现问题的原因在于PKI的keystone-signing有错误了，我原来用过一次其他的设置 /etc/keystone/ssl/， 后来又改变了，所以都混乱了。 解决办法： 找到对应的keystone的keystone-signing， 删除掉，重新启动keystone。 因为我的glance用的是这个，所以必须重启glance nova的如果设置了，删除掉对应的keystone-signing-nova/ 这样nova， glance的都能在PKI的token下工作了。]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FC iSCSI FCoe NAS 存储比较]]></title>
    <url>%2F2013%2F03%2F10%2FFC%20iSCSI%20FCoe%20NAS%20%E5%AD%98%E5%82%A8%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[前言： 了解存储相关的协议，技术和区别对于理解云计算中的存储虚拟化具有重要意义，所以整理了相关的资料，给出了大概的介绍，如果要了解更多知识，可以参看后面附上的文献。 基于FC的存储FC最初的设计是基于高性能，低延迟，无损的数据通信。一般应用到企业级对数据读写性能要求较高的环境中。 基于以太网的存储：iSCSI和各种NAS协议， 主要利用了现有的以太网架构。 FC 123高性能， 4GB/s 8GB/s稳定性硬件HBA卡支持 iSCSI 123456789101112131415161718iSCSI借助IP协议来完成SCSI命令和数据的封包，发送。相比较FC，1）增加了封包的处理流程和时间2）受限于以太网的低速 1GbpsiSCSI相比SCSI和SAS突破了传输距离（server到storage）的限制。iSCSI的结构如下：iSCSI Initiator &lt;---&gt; TCP connection &lt;----&gt; iSCSI targetiSCSI technology can use a hardware initiator, a host bus adapter (HBA), or asoftware initiator to issue requests to target devices有软件，硬件实现FcoE：主要是实现通过以太网来传送FC的帧，为了实现FC的无损传送，对现有的以太网协议传送进行了改进和扩展 聚合以太网和FC，减少机器不同adapte，线缆的数量需要相应的软件，硬件支持 NAS 12345NAS协议比如 NFS，CIFS，相比iSCSI的不同在于，iSCSI封装的是block-level的dataNFS则是基于file级别的访问，所以相对iSCSI而言增加了文件系统一级的处理，软件实现 参考：http://en.wikipedia.org/wiki/ISCSI#Software_initiatorhttp://www.redbooks.ibm.com/redpapers/pdfs/redp4493.pdfhttp://www.lsi.com/downloads/public/sas%20switch/sas%20switch%20common%20files/channel_hostinterfacepositioningguide_pg_120310.pdfhttp://www.cisco.com/en/US/netsol/ns1060/index.htmlhttp://www.vmware.com/files/pdf/techpaper/Storage_Protocol_Comparison.pdf]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SAS 和 SATA 比较]]></title>
    <url>%2F2013%2F03%2F10%2FSAS%20%E5%92%8C%20SATA%20%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[SAS和SATA有相似的技术点，都是对传统的并行接口进行了改进，SCSI, ATA 12345678910111213141516应用领域 容量 性能 可靠性 价格 SAS 服务器 （企业级） 最高都达到 4TB 6GB/s 1.4 million hour MTBF 高 可持续顺序 数据速率 182 MB/s SATA 桌面，工作站 同上 3GB/s， 6GB/s 1.2 million hour MTBF 低 可持续顺序 数据速率 171 MB/sSAS drive cables can extend up to six times the length of SATA drive cables, and SAS drives are dual ported while SATA drives can only communicate via one port 参考资料: http://blog.lewan.com/2009/09/14/sas-vs-sata-differences-technology-and-cost/ http://download.intel.com/design/iio/docs/31512701.pdf http://www.wdc.com/en/products/products.aspx?id=580 http://www.wdc.com/en/products/products.aspx?id=30]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典storage 示意图]]></title>
    <url>%2F2013%2F03%2F09%2F%E7%BB%8F%E5%85%B8storage%20%E7%A4%BA%E6%84%8F%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[SINA的一篇slide里有一个很形象的storage方案说明，采用了饮用机为原型，很有意思。（图片来源 SINA sides) 原文地址，请参看：http://www.snia.org/sites/default/education/tutorials/2012/fall/green/SW_Green%20Storage_Big_Picture_9-12.pdf]]></content>
      <tags>
        <tag>服务器与存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sublime 快捷配置]]></title>
    <url>%2F2013%2F03%2F04%2FSublime%20%E5%BF%AB%E6%8D%B7%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[最近使用了sublime，前段时间编辑encoding中含有GBK，后来打开发现有问题了，到网上搜索发现，sublime有强大的package安装和管理功能，根据官方的说明，非常容易安装配置。 安装 如果防火墙禁止了对应的应用，那么方式1就无法安装 Installation is through the Sublime Text 2 console. 方式2，手动安装 a. Click the Preferences &gt; Browse Packages… menu entryb. Browse up a folder and then into the Installed Packages folderc. Download Package Control.sublime-package from link: https://sublime.wbond.net/Package%20Control.sublime-package and copy it into the Installed Packages directoryd. Restart Sublime Text 使用 ctrl + shift +p 命令行模式，输入 Install Package 回车，就可以看到列出的所有package 选择packages，安装下面两个就可以解决切换相应编码的问题了 ConvertToUTF8 GBK Encoding Support” 其他的很多插件有待各位自己摸索……….. 参考资料： http://www.fuzhaopeng.com/2012/sublime-text-2-with-gb2312-gbk-support/ http://wbond.net/sublime_packages/package_control/installation]]></content>
      <tags>
        <tag>WINDOWS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keystone v3 API的新特征]]></title>
    <url>%2F2013%2F02%2F24%2Fkeystone%20v3%20API%E7%9A%84%E6%96%B0%E7%89%B9%E5%BE%81%2F</url>
    <content type="text"><![CDATA[keystone的v3 API与v2.0相比有很大的不同，从API的请求格式到response的返回结果都有差别，主要几点如下： 引入了domain的概念，domain是在project，user， group之上抽象出的一个概念，是指 container for projects, users and groups v3中用project代替了以前的v2.0的tenant概念 v3的验证/auth/tokens,相比v2.0的/tokens，token的ID不再在body中包含，而是在返回header中的X-Subject-Token v3还在验证上引入plugin方式， 1234[auth]methods = password,tokenpassword = keystone.auth.methods.password.Passwordtoken = keystone.auth.methods.token.Token 可以添加自己的plugin来对keystone自己的auth方式进行定制化，关于auth这一部分：因为token有scoped和non-scoped的区别： 12345678910111213Scoped1. project If a project is specified by name, then the domain of the project must also be specified in order to uniquely identify the project2. domainAlternatively, a domain name may be used to uniquely identify the project.A token scoped to a project will also have a service catalog, along with the user's roles applicable to the project. Example response:A token scoped to a domain will also have a service catalog along with the user's roles applicable to the domain. Example response:Non-scoped1. userIf the user is specified by name, then the domain of the user must also be specified in order to uniquely identify the user 因为社区的开发方式，keystoneclient的开发和keystone并不是完全同步，加上keystone的v3还没有完全开发完毕，所以现在用的keystoneclient还不完全支持v3 keystone。如果你要提前用keystoneclient，那就需要修改其中v3的client的代码 5.兼容性 为了让v2.0 的scheme迁移到v3，v2.0会默认的使用(keystone,conf) 1# default_domain_id = default 更多的参考资料，可以参看： v3 API design https://etherpad.openstack.org/grizzly-keystone-v3api v3 API doc https://github.com/openstack/identity-api/blob/master/openstack-identity-api/src/markdown/identity-api-v3.md]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redhat 6.3 openstack的cinder安装配置]]></title>
    <url>%2F2013%2F01%2F31%2FRedhat%206.3%20openstack%E7%9A%84cinder%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[cinder 配置 安装： 1） 下载source code2） pip install3） yum install scsi-target-utils4） yum install iscsi-initiator-utils.x86_64 (这两个相当于ubuntu下的 open-iscsi和tgt）5） edit cinder config filenormally it includes : database config keystone access config volumes config message queue configalso enable cinder api in nova.conf 6) edit/etc/lvm/lvm.confAdd volume_list entry to /etc/lvm/lvm.conf to keep LVM from activating logical volumes created in VMs.volume_list = [“VolGroup”, “cinder-volumes” ] volume_list should include your os related volume group. 7）add volumes dir in /etc/tgt/targets.conf include /var/lib/cinder/volumes/* 8) restart tgtd service 9) init cinder dbcinder-manage db sync 10) test if cinder works 10.1 create one test loop file and mount it dd if=/dev/zero of=cinder-volumes bs=1 count=0 seek=2G losetup /dev/loop2 cinder-volumes 10.2 init pv and create vgpvcreate /dev/loop2 vgcreate cinder-volumes /dev/loop2 10.3 check if volume is createdpvscan 10.4 restart cinder service:cinder api, scheduler, volume 10.5 use cinder to create volumecinder create –display_name test 1 10.6 verify volume created successfullycinder list volume should in “available” status]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenStack Grizzly 源码安装中遇到的几个问题]]></title>
    <url>%2F2013%2F01%2F31%2FOpenStack%20Grizzly%20%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[Grizzly Update 问题1： When you keystone endpoint-list, hit issue,(ENVOSTest)[root@localhost bin]# keystone endpoint-listFailed to load keyring modules. it missing keyring lib in python, use pip install to fix it. pip install keyring Blog http://blog.dynamichosting.biz/category/openstack/ seems not work with yum ways 问题2： 问题已经解决， 由于@wuwenxiang “PKI需要Openssl加密token，估计你没有在配置目录加上ssl的密钥” [signing] #token_format = PKI把PKI改成UUID refer：https://gist.github.com/4070200否则会出现problem fulfilling your request. Command ‘openssl’ returned non-zero 问题3： openstack bugNameError: global name ‘service_ref’ is not definedhttps://bugs.launchpad.net/nova/+bug/1102596]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sudo 执行时的变量设置保留]]></title>
    <url>%2F2012%2F12%2F26%2Fsudo%20%E6%89%A7%E8%A1%8C%E6%97%B6%E7%9A%84%E5%8F%98%E9%87%8F%E8%AE%BE%E7%BD%AE%E4%BF%9D%E7%95%99%2F</url>
    <content type="text"><![CDATA[现象： 我们在linux下使用sudo命令的时候，经常发现缺少一些变量，导致程序执行报错. 比如python程序fly，当前的用户是tom， 执行fly需要sudo权限执行，那么直接sudo fly 会报错，缺少相应的模块，只是因为对应的pythonpath的设置缺少，但是如果你仅仅export当前环境，执行sudo还是会报错， 原因： 问题就在于sudo的执行使得的环境变量进行了重置，所以相应的执行环境中无法找到对应的pythonpath， 解决： 简单的一种方法是，修改/etc/sudoers文件, 添加如下的设置 Defaults env_keep += PYTHONPATH 这里的PYTHONPATH只要是tom用户可以看到就行，比如你在~/.bashrc或profile中设置类似的变量。 参考资料: http://superuser.com/questions/232231/how-do-i-make-sudo-preserve-my-environment-variables http://stackoverflow.com/questions/7969540/pythonpath-not-working-for-sudo-on-gnu-linux-works-for-root]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSGI的tracking service使用]]></title>
    <url>%2F2012%2F12%2F16%2FOSGI%E7%9A%84tracking%20service%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[在eclipse的OSGI框架中，tracking service是OSGI很重要的一个功能，通过对服务的查询来动态的获取相应服务，例子： 我们建立两个bundle，一个是提供sayHello的服务，另外一个bundle来使用sayHello服务 12345678910111213141516bundle 1： com.javaworld.sample.service结构如下：├── META-INF│ └── MANIFEST.MF└── src └── com └── javaworld └── sample └── service ├── HelloService.java └── impl ├── HelloServiceActivator.java ├── HelloServiceFactory.java └── HelloServiceImpl.java 123456789101112131415161718192021222324252627282930bundle 2： com.javaworld.sample.helloworld├── build.properties├── META-INF│ └── MANIFEST.MF└── src └── com └── javaworld └── sample └── helloworld ├── Activator.java └── HelloServiceTracker.javaHelloServiceTracker 继承 osgi的ServiceTracker， 通过构造函数中说明需要track哪些服务， public HelloServiceTracker(BundleContext context) &#123; super(context, HelloService.class.getName(), null); &#125; public Object addingService(ServiceReference reference) &#123; System.out.println("Inside HelloServiceTracker.addingService " + reference.getBundle()); return super.addingService(reference); &#125; public void removedService(ServiceReference reference, Object service) &#123; System.out.println("Inside HelloServiceTracker.removedService " + reference.getBundle()); super.removedService(reference, service); &#125; 在helloservice中，HelloServiceActivator的bundle启动过程中会注册服务，helloServiceRegistration = context.registerService(HelloService.class.getName(), helloServiceFactory, null); helloworld的bundle就可以通过service tracker的 getService来返回相应的service对象 1234567891011121314151617181920 /* * (non-Javadoc) * @see org.osgi.framework.BundleActivator#start(org.osgi.framework.BundleContext) */ public void start(BundleContext context) throws Exception &#123; System.out.println("Hello World!!"); helloServiceTracker= new HelloServiceTracker(context); helloServiceTracker.open(); HelloService helloService = (HelloService)helloServiceTracker.getService(); System.out.println(helloService.sayHello()); &#125; /* * (non-Javadoc) * @see org.osgi.framework.BundleActivator#stop(org.osgi.framework.BundleContext) */ public void stop(BundleContext context) throws Exception &#123; System.out.println("Goodbye World!!"); helloServiceTracker.close(); &#125; 上次写了忘记给参考资料，实在抱歉。 参考资料： http://www.javaworld.com/javaworld/jw-03-2008/jw-03-osgi1.html?page=5]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven的POM介绍]]></title>
    <url>%2F2012%2F12%2F15%2FMaven%E7%9A%84POM%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[POM： Project Object Model 是maven项目架构里重要的基本单元 最小的POM需具备以下的元素： project root modelVersion - should be set to 4.0.0 groupId - the id of the project’s group. artifactId - the id of the artifact (project) version - the version of the artifact under the specified group 例如： 12344.0.0 com.mycompany.appmy-app 1 POM 使用 :: 来唯一标记一个项目，它们是maven的因为软件经常涉及到很多projects，那么如何来维护projects之间的关系非常重要，POM中有两个非常重要的特性：project inheritance和project aggregation，两者主要是看待projects之间的关系的角度不同，其实是殊途同归。 假设前提，我们有两个projects，com.mycompany.app:my-module:1 com.mycompany.app:my-app:1其中 com.mycompany.app:my-app:1 是com.mycompany.app:my-module:1 的 parent artifact (1) 组织形式如下的时候 123. |-- my-module | `-- pom.xml `-- pom.xml 首先看看project inheritance： my-module的pom需要加入parent的元素，com.mycompany.app:my-module:1’s POM 如下 12345678 com.mycompany.app my-app 1 4.0.0 com.mycompany.app my-module 1 对于project aggregation：通过在my-app中指定相应的子module，从而使得 parent project 知道所有的 modules 里面很重要的一点是在packaging里指出为pom 12345674.0.0com.mycompany.app my-app1 pom my-module (2) 组织形式如下的时候： 1234. |-- my-module | `-- pom.xml `-- parent `-- pom.xml 首先看看project inheritance：通过relativepath来配合设置相应的目录结构 12345678com.mycompany.app my-app 1 .../parent/pom.xml 4.0.0my-module 对于project aggregation： 123456789101112131415161718 4.0.0 com.mycompany.app my-app 1 pom ../my-module ``` (3) 你也可以将inheritance和aggregation联合起来，应用下面三条： Specify in every child POM who their parent POM is.Change the parent POMs packaging to the value "pom" .Specify in the parent POM the directories of its modules (children POMs) 对于如下的形式： . |– my-module | -- pom.xml– parent `– pom.xml 12com.mycompany.app:my-app:1's POM 4.0.0 com.mycompany.app my-app 1 pom ../my-module12com.mycompany.app:my-module:1's POM com.mycompany.app my-app 1 ../parent/pom.xml 4.0.0 my-module ` 参考资料： http://maven.apache.org/guides/introduction/introduction-to-the-pom.html http://www.oracle.com/technetwork/cn/community/java/apache-maven-getting-started-1-406235-zhs.html]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openstack nova的unit测试 ----确保配置合适debug的sqlite]]></title>
    <url>%2F2012%2F12%2F02%2Fopenstack%20nova%E7%9A%84unit%E6%B5%8B%E8%AF%95%20----%E7%A1%AE%E4%BF%9D%E9%85%8D%E7%BD%AE%E5%90%88%E9%80%82debug%E7%9A%84sqlite%2F</url>
    <content type="text"><![CDATA[问题 在你进行unittest的时候，尤其涉及到database相关的调试，总发现nova的没有生成database，其实主要是nova默认的会使用sqlite的内存内型数据库 参考sqlite的资料发现e = create_engine(‘sqlite://‘) The sqlite :memory: identifier is the default if no filepath is present. Specify sqlite:// and nothing else: 解决 为了调试数据库更加简单，你可以配置不使用内存型的数据库 在 nova 的TestCase (nova/nova/test.py) fake_flags.set_defaults(FLAGS) —&gt; 配置类似如下的sql连接，nova.sqlite是对应的sqlite数据库文件 1conf.set_default('sql_connection', "sqlite:////var/lib/nova/nova.sqlite") 配置前面的前提是你自己的环境已经有这个数据库文件，如果没有的话，你需要手动创建一个步骤如下： (1) change your sql connection in nova.conf to be sqlite(2) nova-manage db sync这样你对应的nova.conf设置的位置生成相应的数据库文件(3) cp nova.sqlite clean.sqlite 完毕，这样进行unit测试最后的结果就会写到sqlite数据库文件里的。 附加资料 如何查看sqlite数据库？ 很多工具可以查看， 我用了两个都还可以，一个是sqliteman，前面的一篇文章已经写过了。另外一个是SQLite Manager，这个就是一个firefox的插件，https://addons.mozilla.org/en-us/firefox/addon/sqlite-manager/很容易就可以安装为firefox的插件。]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装sqliteman]]></title>
    <url>%2F2012%2F11%2F28%2F%E5%AE%89%E8%A3%85sqliteman%2F</url>
    <content type="text"><![CDATA[sqliteman 是一款小巧的图形化管理sqlite 数据库的软件，安装相对简单因为自己使用redhat6.3，从官方给的那个源死活yum不行，就使用源代码编译安装了。 具体如下：sqliteman的编译安装依赖： 12cmakeqt 还有stdlibc的东东 注明： 如果没有 Qscintilla2 libraries and header files， 需要使用编译选项来从源代码安装 安装过程如下： 安装依赖的软件 1）yum install cmake.x86_642）yum install compat-libstdc++-33.x86_643）yum install qt-devel.x86_64 编译 4）cmake -DWANT_INTERNAL_QSCINTILLA=1 5）make 6) make install 然后就可以使用了]]></content>
      <tags>
        <tag>SQLite/嵌入式数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redhat6.3 安装mysql-workbench]]></title>
    <url>%2F2012%2F11%2F09%2Fredhat6.3%20%E5%AE%89%E8%A3%85mysql-workbench%2F</url>
    <content type="text"><![CDATA[redhat6.3缺少 libzip.so.1, 而这个是 mysql-workbench所需要的, 所以你需要首先安装 libzip包. 方法： 下载rpm包 http://rpm.pbone.net/index.php3/stat/4/idpl/17359193/dir/fedora_16/com/libzip-0.9.3-3.fc15.x86_64.rpm.html yum install libzip-0.9.3-3.fc15.x86_64.rpm yum install mysql-workbench-gpl-5.2.44-1el6.x86_64.rpm 参考资料: http://databaseblog.myname.nl/2011/03/mysql-workbench-on-rhel6.html]]></content>
      <tags>
        <tag>Mysql/postgreSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu 12.04 install python 2.6]]></title>
    <url>%2F2012%2F10%2F20%2Fubuntu%2012.04%20%20install%20python%202.6%2F</url>
    <content type="text"><![CDATA[http://www.ubuntututorials.com/install-python-2-6-ubuntu-12-04/ Run below command to add PPA to your repository 1sudo add-apt-repository ppa:fkrull/deadsnakes Then you can update your repository and install Python 2.6 12sudo apt-get updatesudo apt-get install python2.6 python2.6-dev]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rabbitmq epmd error for host]]></title>
    <url>%2F2012%2F10%2F16%2Frabbitmq%20epmd%20error%20%20for%20host%2F</url>
    <content type="text"><![CDATA[今天迁移虚拟机，发现死活rabbitmq起不来，提示， 1ERROR: epmd error for host "****": timeout (timed out establishing tcp connection) 后来google发现， https://gist.github.com/2522701 主机名和ip不匹配了，需要更改/etc/hosts 1127.0.0.1 yournewhostname]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[eclipse中openstack一些模块的unresolved]]></title>
    <url>%2F2012%2F09%2F23%2Feclipse%E4%B8%ADopenstack%E4%B8%80%E4%BA%9B%E6%A8%A1%E5%9D%97%E7%9A%84unresolved%2F</url>
    <content type="text"><![CDATA[openstack的git下载的源码导入到eclipse中有时会一些模块unresolved比如paste，发现使用pip下载后的paste的package中没有init.py ，很奇怪 于是就从网上下载对应版本paste源码包，然后将init.py 导入, 执行python setup.py install就会对其编译，生成init.pyc重启eclispe，可以源码跳转到paste了，但是还是有个 Unresolved import: deploy 具体还没想出怎么回事，不过暂时不影响使用。]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openstack winpdb调试]]></title>
    <url>%2F2012%2F09%2F23%2Fopenstack%20winpdb%E8%B0%83%E8%AF%95%2F</url>
    <content type="text"><![CDATA[http://lists.openstack.org/pipermail/openstack-dev/2012-August/000794.html看到了关于winpdb的相关调试： Launch Winpdb GUI # winpdb Start Debugging 12# cd /home/openstack-dev/workspace/nova/bin # winpdb -d -r Set Password: openstack Attach to Process 1) In Winpdb GUI, select File -&gt; Attach2) Enter password from step 4, should display files associated with that password3) Select process/file then select OK To Stop Debug or Make Changes and Restart 1) File -&gt; Stop to detach current debugger2) Make changes in Eclipse and Save (make sure development user has write privileges to repository)3) kill and restart winpdb debugging process started above 4) Re-attach to the process in the Winpdb GUI 也许自己不太会用，感觉比较难用。而且有时就崩溃了。还是eclipse方便些。]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux误删系统文件修复]]></title>
    <url>%2F2012%2F08%2F25%2FLinux%E8%AF%AF%E5%88%A0%E7%B3%BB%E7%BB%9F%E6%96%87%E4%BB%B6%E4%BF%AE%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[因不注意删除了 /var/lib 下的文件，所以需要找个方法解决, 虽然，在删除资料后，不推荐在对磁盘的写操作，但是机器的硬盘的因为特殊原因不能自行拆卸，也没有实现安装修复软件。所以只能先搞安装修复软件了。 首先，原来的/var/lib下有yum相关的文件，导致无法yum安装，解决如下： 123456789101112131415161718192021222324252627http://www.ogre.com/taxonomy/term/33yum failures with missing $releaseverPosted June 15th, 2011 by leif Fedora LinuxDuring an upgrade (yum update) on a Fedora VM, something went horribly wrong, and it crashed in the middle of the update. After rebooting, and cleaning up the mess, yum still was very unhappy. Running an update would give me errors likeCould not parse metalink https://mirrors.fedoraproject.org/metalink?repo=fedora-$releasever&amp;arch=x86_64 error was No repomd fileError: Cannot retrieve repository metadata (repomd.xml) for repository: fedora. Please verify its path and try againVery odd. It turns out, $releasever was not properly set, and I could not figure out why. Poking around, I realized that $reelasever is supposed to come from examining the version number of a particular RPM package, in my case fedora-release. Well, lo and behold, this package was no longer installed on my box, yum must have uninstalled it, but crashed before installing the new update (or something...). I mounted the Fedora Core DVD, and simple reinstalled the missing package, and things are happy joy joy again. Here's the command:$ sudo rpm -i ./Packages/fedora-release-13-1.noarch.rpm 其次，找到 http://hi.baidu.com/cnjxxf/item/7b92070f59a09390a3df4392extundelete 修复ext4 ext3那么就可以安装这个软件，然后修复了。 修复后的会放在 RECOVERED_FILES一个目录里，然后我copy到/var/lib，毕竟对磁盘做了一些写操作（安装上述的软件及依赖），所以有些文件估计恢复不了。 然后，我检查了恢复差不多，然后在重启机器前，把所有的数据备份好，以防止机器起不来。 好在机器能起来，但是无法进入桌面系统。 好像gdm出问题了，重装gdm也不行，最后想到kdm。安装kdm后，重启后就可以进入桌面了。]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JNI 问题 wrong ELF class]]></title>
    <url>%2F2012%2F07%2F24%2FJNI%20%E9%97%AE%E9%A2%98%20wrong%20ELF%20class%2F</url>
    <content type="text"><![CDATA[使用JNI发现一个问题， wrong ELF class: ELFCLASS64)主要是机器是64位的OS，默认编译的.so是64位 而java设置的默认是32位 JDK， 所以会出现这个问题。那么就采用编译成32位的.so， 安装 glibc-devel.i686然后编译指定 -m32 就可以了， 如果执行出现Not found in java.library.path)，这是因为JVM没有找到相应的native library，那么就需要设置相应的 path 可以通过 1java -Djava.library.path='.' HelloWorld 或者 123LD_LIBRARY_PATH=`pwd`export LD_LIBRARY_PATHJava HelloWorld 这样就搞定了 JNI简单过程： 1234561）创建一个Java程序，定义原生的c/c++函数2）javac编译3）javah -jni声称.h文件4）创建对应的.c文件，实现对应的.h定义的函数5）编译.c 生成.so6) 运行java程序 参考资料： http://www.cnblogs.com/xiaoxiaoboke/archive/2012/02/13/2349775.htmlhttp://java.sun.com/developer/onlineTraining/Programming/JDCBook/jniexamp.html#examphttp://blog.csdn.net/mdemonhunter/article/details/6254478]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java classloader 原理]]></title>
    <url>%2F2012%2F07%2F15%2Fjava%20classloader%20%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[转自： http://blog.sina.com.cn/s/blog_6383597b0100fsiw.html 简单明了的文章，留下。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475一．简述javaJVM和跨平台性 这个问题方的很久的一直没有关系过，常常有人忽略的技术，但是又是相当总要的技术。作为开始我想先谈谈为什么java会这么强大。主要基于java两个特点：1）java源程序编译后产生的不是机械码，而是一种和平台太无关的字节码。 然后通过各个平台的解释器解释执行。2）java采用泄后联编技术。即对域和内存的管理都是在执行的时候根据需要动态的分配。 这样就是说java编译产生的字节码才是跨平台的。二．classLoader的介绍及加载过程 接下来我们就来说说classLoader，为什么要classLoader呢？与普通程序不同的是，Java程序（class文件）并不是本地的可执行程序。当运行Java程序时，首先运行JVM（Java虚拟机），然后再把Javaclass加载到JVM里头运行，负责加载Java class的这部分就叫做Class Loader。所以 classLoader的目的在于把class文件装入到jvm中。那么classLoader又在那里的啦？又由谁调用呢？其实classLoader只是jvm的一个实现的一部分。Jvm提供的一个顶级的classLoader（bootStrap classLoader），bootStrap classLoader负责加载java核心的API 以满足java程序最基本的需求。Jvm还提供的两个classLoader，其中Extension ClassLoader负责加载扩展的Java class（例如所有javax.*开头的类和存放在JRE的ext目录下的类），Application ClassLoader负责加载应用程序自身的类。而Extension ClassLoader和Application ClassLoader 则由bootStrap classLoader加载。三．classLoader加载的基本流程 当运行一个程序的时候，JVM启动，运行bootstrapclassloader，该ClassLoader加载java核心API（ExtClassLoader和AppClassLoader也在此时被加载），然后调用ExtClassLoader加载扩展API，最后AppClassLoader加载CLASSPATH目录下定义的Class，这就是一个程序最基本的加载流程。四．classLoader加载的方式 其实classLoader在加载class文件的时候就采用的双亲委托模式。每一个自定义ClassLoader都必须继承ClassLoader这个抽象类，而每个ClassLoader都会有一个parent ClassLoader，我们可以看一下ClassLoader这个抽象类中有一个getParent()方法，这个方法用来返回当前ClassLoader的parent，注意，这个parent不是指的被继承的类，而是在实例化该ClassLoader时指定的一个ClassLoader，如果这个parent为null，那么就默认该ClassLoader的parent是bootstrap classloader，这个parent有什么用呢？我们可以考虑这样一种情况，假设我们自定义了一个ClientDefClassLoader，我们使用这个自定义的ClassLoader加载java.lang.String，那么这里String是否会被这个ClassLoader加载呢？事实上java.lang.String这个类并不是被这个ClientDefClassLoader加载，而是由bootstrap classloader进行加载，为什么会这样？实际上这就是双亲委托模式的原因，因为在任何一个自定义ClassLoader加载一个类之前，它都会先委托它的父亲ClassLoader进行加载，只有当父亲ClassLoader无法加载成功后，才会由自己加载，在上面这个例子里，因为java.lang.String是属于java核心API的一个类，所以当使用ClientDefClassLoader 加载它的时候，该ClassLoader会先委托它的父亲ClassLoader进行加载，上面讲过，当ClassLoader的parent为null时，ClassLoader的parent就是bootstrapclassloader，所以在ClassLoader的最顶层就是bootstrapclassloader，因此最终委托到bootstrap classloader的时候，bootstrapclassloader就会返回String的Class。五.对于classLoader加载的一些细节说明。 我们来讲解ClassLoader中的两个loadClass方法，都是用来加载class的，但是两者在作用上却有所区别。 Class loadClass(String name)Class loadClass(String name, boolean resolve)我们看到上面两个方法声明，第二个方法的第二个参数是用于设置加载类的时候是否连接该类，true就连接，否则就不连接。说到连接，不得不在此做一下解释，在JVM加载类的时候，需要经过三个步骤，装载、连接、初始化。装载就是找到相应的class文件，读入JVM，初始化就不用说了，最主要就说说连接。连接分三步，第一步是验证class是否符合规格，第二步是准备，就是为类变量分配内存同时设置默认初始值，第三步就是解释，而这步就是可选的，根据上面loadClass方法的第二个参数来判定是否需要解释，所谓的解释根据《深入JVM》这本书的定义就是根据类中的符号引用查找相应的实体，再把符号引用替换成一个直接引用的过程。有点深奥吧，呵呵，在此就不多做解释了，想具体了解就翻翻《深入JVM吧》，呵呵，再这样一步步解释下去，那就不知道什么时候才能解释得完了。我们再来看看那个两个参数的loadClass方法，在JAVA API 文档中，该方法的定义是protected，那也就是说该方法是被保护的，而用户真正应该使用的方法是一个参数的那个，一个参数的loadclass方法实际上就是调用了两个参数的方法，而第二个参数默认为false，因此在这里可以看出通过loadClass加载类实际上就是加载的时候并不对该类进行解释，因此也不会初始化该类。而Class类的forName方法则是相反，使用forName加载的时候就会将Class进行解释和初始化，forName也有另外一个版本的方法，可以设置是否初始化以及设置ClassLoader，在此就不多讲了。]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fedora 16 的fcitx配置]]></title>
    <url>%2F2012%2F06%2F10%2Ffedora%2016%20%E7%9A%84fcitx%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[转自：http://hzy5000.blog.163.com/blog/static/74596452012064452485/ 1234567891011121314151. 第一步安装fcitx yum install fcitx.x86_642. 设置fcitx为默认输入法alternatives --config xinputrc选择fcitx对应的序号3. 设置启动的环境变量编辑/etc/profile,在其中加入如下几行export XMODIFIERS=”@im=fcitx”export QT_IM_MODULE=fcitxexport GTK_IM_MODULE=fcitx4. 重启Fedora, 按Ctrl+回车就可以看到fcitx的输入界面了。]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟化技术系列2--X86 的虚拟化历史]]></title>
    <url>%2F2012%2F06%2F08%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF%E7%B3%BB%E5%88%972--X86%20%E7%9A%84%E8%99%9A%E6%8B%9F%E5%8C%96%E5%8E%86%E5%8F%B2%2F</url>
    <content type="text"><![CDATA[X86处理器引入的一个很重要的虚拟化支持就是Non-Root模式和Root模式。VMM运行在Root模式，guest OS都运行在Non-Root模式。 为什么引入这种特殊的模式呢？ 这要从X86的毛病说起，因为X86架构在2005年之前都对虚拟化没有相应的支持：在于， 首先，X86的处理器指令有一部分是特权指令，在用户模式下，它们会被trap，如果在内核模式，不会trap。 除此之外，还有一部分指令很特殊（sensitive instruction），会涉及到对系统资源的访问，比如对标志寄存器的修改。这些指令在用户模式下不会被trap。这样会造成guest OS 认为状态更改了，但是Hardware本身忽略这些修改。所以需要通过一种手段来截获这些特殊的敏感指令，在VMM层进行相应的模拟，例如二进制翻译。 虽然在VMware在软件层次的全虚拟化方法性能上不错，但是离开了硬件上的虚拟化支持还是有所打折。2005年——2006年，Intel/AMD推出了VT/SVM，CPU引入了Non-Root模式和Root模式，使得敏感指令在guest OS执行时，会被VMM截获，直接转换等价的硬件指令执行。 KVM最初的出发点就是利用硬件技术的虚拟化，来实现Linux host OS的全虚拟化方案， 而 Vmware直到2007年才推出第一款利用 Hardware虚拟化的 Hypervisor。 参考资料： KVM: Kernel-based Virtualization DriverUnderstanding Full Virtualization, Paravirtualization, and Hardware Assist]]></content>
      <tags>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux-Unix 需要熟悉的系统性能分析工具]]></title>
    <url>%2F2012%2F05%2F01%2FLinux-Unix%20%E9%9C%80%E8%A6%81%E7%86%9F%E6%82%89%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[Linux下的性能分析工具主要是sysstat工具集： 1） nicstat: 搜集和监控网卡的I/O 1234# ./nicstat.sh -i em1 5 Time Int rKB/s wKB/s rPk/s wPk/s rAvs wAvs %Util Sat11:36:57 em1 13.05 0.75 11.12 7.44 1202.4 103.2 0.11 0.0011:37:02 em1 0.11 0.11 1.60 1.60 67.75 70.00 0.00 0.00 下载地址：http://sourceforge.net/projects/nicstat/files/可以用于分析分布式的java应用程序的网络I/O瓶颈 2）iostat ： 分析硬盘I/O利用率 1234# iostat -xd 5Linux 3.3.2-6.fc16.x86_64 (localhost.localdomain) 05/01/2012 _x86_64_ (4 CPU)Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilsda 1.99 4.42 7.66 3.12 148.28 80.20 42.39 0.33 30.76 12.18 76.45 4.90 5.28 3）vmstat： 分析内存的利用率 12345# vmstatprocs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 60692 172812 175668 1690636 0 1 36 20 226 25 3 1 95 1 0 si,so 内存的换入换出数据是初步衡量性能的依据 4）vmstat, top 分析CPU的利用率： 1234# vmstatprocs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st1 0 64812 166964 176412 1694400 0 1 36 20 226 47 3 1 95 1 0 r 是衡量当前cpu的等待执行的进程队列长度 5）pidstat: 分析潜在进程的竞争resource问题（比如lock） 123# pidstat -w -I -p 1231 512:03:07 PM PID cswch/s nvcswch/s Command12:03:12 PM 1231 38.60 0.20 libvirtd AIX: http://www.ibm.com/developerworks/cn/aix/library/au-aix7optimize1/index.htmlSysstat: http://sebastien.godard.pagesperso-orange.fr/ 附注：如果在64位操作系统，编译nicstat会报类似的错： 1gnu/stubs-32.h: No such file or directory 方案1： 编译选项改成 -m64方案2： 安装相关的32位库， 具体参考： http://docs.redhat.com/docs/en-US/JBoss_Enterprise_SOA_Platform/4.3/html/Getting_Started_Guide/appe-install_jdk_rhel.html#sect-use_alternatives_to_set_default_JDK]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[灵山游记]]></title>
    <url>%2F2012%2F04%2F30%2F%E7%81%B5%E5%B1%B1%E6%B8%B8%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[如果到灵山游玩选择的是公交出行的话，这篇文章可以给你提供一些帮助信息。 到灵山专线是892路公交车，始发站是苹果园地铁站。由于路程比较长，所以尽量赶最早的班车，如果赶不上7：00的，那就等下一班7：30的。灵山的这个线路比较有意思，班车会在斋堂站让你下来，你在这里等上山路线的班车，因为892路车要进总站，会在站里停”好”一段时间。我们7：30从苹果园出发，到斋堂接近10：10，然后被莫名其妙的等上山的班车大概1小时。斋堂到双塘涧灵山风景区也接近一个小时路程。 四月份的北京灵山的景区基本可以用一个字形容，秃，听开车的师傅说最好的时候是7，8月份，或者秋季的9月份，那时上山的高原景观会比较有看头。罢了，既来之，则安之。 忘了附上一句:北京灵山风景区站，离灵山山脚很远，约20公里的路程。那里的村民有自己的车专门接待游人，找辆车不是件困难的事情，价钱大概40左右（几个人一起的话，算比较便宜了，想一想中石油的涨价 ～）。 灵山的山脚下有很多村民经营的旅馆，在四月份这个季节，双人间，40元/人，条件就是一般般。 灵山虽然海拔在2303米，但山脚已经1400多米了，而且以高山草原地势为主，所以爬到山顶不会很费事，我们接近1点开始爬，悠闲的爬到山顶大概在4：00左右。 由于安排了两天的行程，比较轻松。当天的晚上在山脚的饭店吃的，一海碗面条+一个炒菜，足够两个人吃的，才34元，烤肉之类的比较贵，我们没点。 第二天早上，赶早车回京。 总结一下：旅馆的住宿条件不怎好，四月份的季节不太适合对高山草原报有很大期望的人。 ：）]]></content>
  </entry>
  <entry>
    <title><![CDATA[ntp 同步配置]]></title>
    <url>%2F2012%2F04%2F18%2Fntp%20%E5%90%8C%E6%AD%A5%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[以Fedora为例， 1）找到对应对ntp软件包，比如我的OS是64位，那么对应的是ntp.x86_64 1yum search ntp 2） 安装ntp包 1sudo yum install ntp.x86_64 3）开始配置ntp的 server： sudo vim /etc/ntp.conf 12345678# Permit all access over the loopback interface. This could# be tightened as well, but to do so would effect some of# the administrative functions.restrict 127.0.0.1 restrict -6 ::1# Hosts on local network are less restricted.restrict 172.16.66.0 mask 255.255.255.0 nomodify notrap 上面这行是允许相关的client机器可以来和server（本机）同步， server 172.16.15.183 配置局域网里用作NTP服务器的IP，其他的 1234server 0.fedora.pool.ntp.org iburstserver 1.fedora.pool.ntp.org iburstserver 2.fedora.pool.ntp.org iburstserver 3.fedora.pool.ntp.org iburst 根据的机器可以访问公网，可以有选择的注释掉。 4）配置ntp服务机器启动后自动运行， 为了使NTP服务可以在系统引导的时候自动启动，执行： 1chkconfig ntpd on 启动ntpd： 12service ntpd start 5）检查对应的同步信息， tail -f /var/log/messages 6) 配置client端，修改 /etc/ntp.conf加上对应的server ip即可, 1server 172.16.15.183 同样对client机器执行 4） 7） 使用 ntpstat 来检查同步状态 参考：http://www.51testing.com/?uid-130600-action-viewspace-itemid-122930http://www.cyberciti.biz/faq/rhel-fedora-centos-configure-ntp-client-server/]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sudoers 的理解]]></title>
    <url>%2F2012%2F03%2F24%2Fsudoers%20%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[转载： http://apps.hi.baidu.com/share/detail/33864699 用sudo时提示”xxx is not in the sudoers file. This incident will be reported.其中XXX是你的用户名，也就是你的用户名没有权限使用sudo,我们只要修改一下/etc/sudoers文件就行了。 下面是修改方法 1）进入超级用户模式。也就是输入”su -“,系统会让你输入超级用户密码，输入密码后就进入了超级用户模式。（当然，你也可以直接用root用）2）添加文件的写权限。也就是输入命令”chmod u+w /etc/sudoers”。3）编辑/etc/sudoers文件。也就是输入命令”vim /etc/sudoers”,输入”i”进入编辑模式，找到这一 行：”rootALL=(ALL) ALL”在起下面添加”xxx ALL=(ALL) ALL”(这里的xxx是你的用户名)，然后保存（就是先按一下Esc键，然后输入”:wq”）退出。4）撤销文件的写权限。也就是输入命令”chmod u-w /etc/sudoers”。原文档介绍的其他的很多，不再转载，这里仅仅留作记录查看。]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Notes的"The remote server is not a known tcp-IP host"问题的方法]]></title>
    <url>%2F2012%2F03%2F24%2F%E8%A7%A3%E5%86%B3Notes%E7%9A%84not-known-tcp-IP-host%E9%97%AE%E9%A2%98%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[转载：http://www.cnblogs.com/tohen/archive/2006/10/26/540216.html 方法一：在场所中的连接中，把该服务器连接删除，重新建一个。方法二：文件—&gt;设置场所—&gt;编辑当前场所—&gt;连接配置向导，重新配置服务器连接一遍。方法三：在host文件中加上该服务器IP与服务器名字的解释。(host文件提供的是个静态解析,对与win系统，通常存放在c:\window\system32\drivers\etc里面) 注意：重新登录一次Notes! 我使用了方法2，很简单，ok.]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Abstract Class and Interface]]></title>
    <url>%2F2012%2F02%2F25%2FAbstract%20Class%20and%20Interface%2F</url>
    <content type="text"><![CDATA[发现一篇文章关于Abstract Class and Interface的问答。很好。 参考地址： http://interview-questions-java.com/abstract-class-interface.htm]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Registered UUID problem in Virtual Box]]></title>
    <url>%2F2012%2F02%2F18%2FRegistered%20UUID%20problem%20in%20Virtual%20Box%2F</url>
    <content type="text"><![CDATA[前段时间, 将虚拟盘从一个分区拷到另外一个分区上，打开虚拟机挂载这个虚拟盘老是报错， 12VBoxManage: error: Cannot register the hard disk '/media/New Volume/ubuntu-dev/Ubuntu-dev.vdi' &#123;fa106a76-0866-4ab4-8b61-e8a054373555&#125; because a hard disk '/media/4E5780F3589D6099/ubuntu-dev/Ubuntu-dev.vdi' with UUID &#123;fa106a76-0866-4ab4-8b61-e8a054373555&#125; already exists 搜索发现，原来注册的UUID记录已经存在，UUID嵌入到了VM的这个虚拟盘中，所以挂载这个转移的分区时候，会检测到UUID 和原来注册的一样，就冲突了。UUID 是用来唯一标志的。 所以解决办法需要重新生成新的UUID，virtualbox有这个命令，vboxmanage internalcommands sethduuid Ubuntu-dev.vdi这样vdi虚拟盘救生成了新的UUID，可以挂载了。 很有用的一篇文章，http://michail.flouris.net/2011/11/virtualbox-vm-disk-clone-uuid-problem/]]></content>
      <tags>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu默认的dash问题]]></title>
    <url>%2F2012%2F01%2F06%2Fubuntu%E9%BB%98%E8%AE%A4%E7%9A%84dash%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[有时别人写好的shell脚本，拿到ubuntu下执行会出现莫名其妙的错误，Syntax error: “之类的，源自于， ubuntu采用了 效率高的dash，而不是传统的bash，功能相比bash要少很多，语法严格遵守POSIX标准。 所以别人机器调试好的shell脚本跑到dash下就有问题， 查看： ls -l /bin/sh 发现： /bin/sh -&gt; dash 更改： 运行 sudo dpkg-reconfigure dash之后选择“No”， 参考： http://blog.chinaunix.net/space.php?uid=14753126&amp;do=blog&amp;id=429323http://www.igigo.net/archives/169]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Using AT&T Network Client VPN with Ubuntu 64bit- Fedora16(64Bit)]]></title>
    <url>%2F2012%2F01%2F06%2FUsing%20AT%26T%20Network%20Client%20VPN%20with%20Ubuntu%2064bit-%20Fedora16(64Bit)%2F</url>
    <content type="text"><![CDATA[转自： http://www.andrewferrier.com/blog/2009/01/12/using-att-network-client-vpn-with-ubuntu-64bit/ 12345678910111213141516171819202122232425262728293031Ubuntu64Install the ia32-libs package and all it’s dependencies:sudo apt-get install ia32-libsInstall the AT&amp;T client itself (IBM colleagues can obtain this from the OCDC website):sudo dpkg -i --force-architecture agnclient_1.0~2.0.1.3000-3_i386.deb Add some symlinks:sudo ln -s /usr/lib32/libssl.so.0.9.8 /usr/lib32/libssl.so.4sudo ln -s /usr/lib32/libcrypto.so.0.9.8 /usr/lib32/libcrypto.so.4还有使用这个AT&amp;T 有时会莫名其妙的连不上了，基本都是CPU莫明其妙的100%了，只好kill掉agnclientd，然后重启，才能解决，不知道是什么原因Fedora(64bit):rpm -ivh agnclient-1.0-2.0.1.3003.i386出现：error: Failed dependencies:libcrypto.so.4 is needed by agnclient-1.0-2.0.1.3003.i386libcurl.so.3 is needed by agnclient-1.0-2.0.1.3003.i386libssl.so.4 is needed by agnclient-1.0-2.0.1.3003.i386(1) Create the necessary link for the lib$ sudo yum install libcurl.i686 $ cd /lib $ sudo ln -s libcrypto.so.1.0.0g libcrypto.so.4$ cd /usr/lib $ sudo ln -s libssl.so.1.0.0g libssl.so.4 $ sudo ln -s libcurl.so.4.2.0 libcurl.so.3 $ sudo ldconfig(2)$ sudo rpm -Uvh --nodeps agnclient-1.0-2.0.1.3002a.i386.rpm(3)$ sudo service agnclientd status $ sudo service agnLogd status $ sudo service agnclientd start $ sudo service agnLogd startFedora 参考：http://huang.yunsong.net/2011/att-agnclient-fedora-64.html]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables 学习]]></title>
    <url>%2F2012%2F01%2F03%2Fiptables%20%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Linux下通过iptables设置可以开启相应的端口，有选择的开启访问权限。设置不同机器之间的互访。 (1)查看本机关于IPTABLES的设置情况 1 # iptables -L -n (2) 开启相应的端口（以22端口为例） 1 # iptables -A INPUT -p tcp --dport 22 -j ACCEPT Ubuntu下增加了ufw更加方便的tool来进行设置， (1) 开启 1 sudo ufw enable (2) 允许外部访问80端口 1sudo ufw allow 80 更多参考：1. http://www.uplinux.com/shizi/wenxian/4113.html2. http://wiki.ubuntu.org.cn/UFW%E9%98%B2%E7%81%AB%E5%A2%99%E7%AE%80%E5%8D%95%E8%AE%BE%E7%BD%AE]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[八达岭滑雪]]></title>
    <url>%2F2012%2F01%2F01%2F%E5%85%AB%E8%BE%BE%E5%B2%AD%E6%BB%91%E9%9B%AA%2F</url>
    <content type="text"><![CDATA[2012年的第一天起的比以往都早些，因为今天要去滑雪，从来没有到滑雪场去过。记得儿时顶多也就是在大雪地里磨呀磨，也不亦乐乎。 滑雪场地的游客蛮多，可能大多数都是第一次来，因为不论是从滑雪的姿势和还是滑雪的“效果”来看，确实不怎么高。 领到雪具，就开始练习了，非常认真，一板一眼，而且摔跤很大方，丝毫不吝惜。初级雪道的人比较容易扎堆，被撞上概率也比较大。不过只要自己注意一些，知道摔跤和撞人孰轻孰重，就没什么问题了。 在初级雪道慢慢练习，大概10个来回，有点感觉了，基本不会摔跤了，也能够躲闪别人了，就跑到中级雪道练习了，其实只要感觉到了，基本滑雪没什么问题，只可能是姿势不太标准，可不够酷。 今天练习感觉滑雪这项活动很不错，下次，要学习些新的技巧，多多练习。]]></content>
  </entry>
  <entry>
    <title><![CDATA[64位操作系统的java开发环境搭建]]></title>
    <url>%2F2011%2F12%2F26%2F64%E4%BD%8D%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84java%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[查看CPU支持long mode， 1# cat /proc/cpuinfo | grep flags | grep ' lm ' cpu支持64位，可以安装32位，64操作系统 如果自己的机器安装的是32位操作系统，但是虚拟机上需要安装64位操作系统注意，需要在BIOS开启CPU的虚拟化支持，否则是无法安装64位操作系统。 java开发人员一般需要安装jdk，目前的jdk有32位和64位， 对于32位的jdk，如果安装在64位系统上会出现 file not found之类的错误，这是因为你没有安装对应的32位lib，一般需要安装 libc6-i386， ia32-libs，可以参考这个链接 http://ubuntuforums.org/archive/index.php/t-1054621.html但是必须提醒一点，即使安装java安装成功了，但是后面使用eclipse还是会有点问题。因为 我选择eclipse需要选择64位还是32位，那么a) 64jdk –》 64位eclipse OKb) 32jdk –》64位eclipse failedc) 32 jdk –》32位eclipse OK， 但是运行会有 failed to load module: /usr/lib/gio/modules/libgvfsdbus.so 这是因为eclipse并不是完全用java相关的开发，有一些代码是和操作系统lib相关的，那么64位操作系统默认使用64位lib，所以会出现这种问题。网上搜了很多帖子，还没有找到解决方案。 d) 64jdk –》32位eclipse 没试过，估计failed 最终选择方案a) , ok 3.7的eclipse可以正常工作，那么如果我需要开发32位java程序呢？ eclipse配置会有installed jre这个应该可以设置编译使用的环境。 注：以上仅个人的一点实践，如有不对之处，请指出。]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机配置 Activation Engine 软件学习]]></title>
    <url>%2F2011%2F12%2F18%2F%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%85%8D%E7%BD%AE%20Activation%20Engine%20%E8%BD%AF%E4%BB%B6%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[大家都知道OVF作为业界广泛支持的虚拟机开放规范，可以实现虚拟机的快速安装和部署.在OVF学习一文中，我们提到了OVF package包括5类文件（有些文件是可选的），其中包括一个 ovf-env.xml 文件。这个文件主要帮助虚拟机实现相应的软件化配置，比如网络配置，应用软件配置等 当新部署的虚拟机第一次启动的时候，Activation Engine（AE）会执行相应配置过程，包括自启动和协调启动。它们都会从ovf-env.xml提取参数进行配置 OVF 环境文件那么AE是如何定位ovf环境文件的呢？你可以把它理解为先在一个默认的目录下寻找，如果没有找到，它会从所有的块设备进行遍历查找（除了RAM disk，RFID设备，回环设备），找到后，会把文件复制到一个临时的目录。 Activation 逻辑文件可以理解为需要注册启动的一些服务，这些服务可以完成一些软件配置，这些服务配置需要的参数是从环境文件中提取的。 Activation 程序这个Activation程序，就是对应逻辑文件中XML中的Program元素中href属性，这些href指出对应程序脚本的位置。 AE的作用，AE就是在系统启动时，提取Activation逻辑文件中的对应配置程序，和环境文件中的对应参数，按照启动的优先级及依赖关系来启动程序，从而实现了相关的配置。 我们可以理解，1）是原材料 2）是车间生产配置清单 3）车间工人AE 就是总的管理者。AE下达命令，按照配置清单，让不同的车间工人加工不同的原材料，这样就生产出了活生生的虚拟机（配置好的) 参考资料： Activation Engine User’s Guide]]></content>
      <tags>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ovf学习1--虚拟化的映像的开放标准格式]]></title>
    <url>%2F2011%2F12%2F18%2Fovf%E5%AD%A6%E4%B9%A01--%E8%99%9A%E6%8B%9F%E5%8C%96%E7%9A%84%E6%98%A0%E5%83%8F%E7%9A%84%E5%BC%80%E6%94%BE%E6%A0%87%E5%87%86%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Open Virtualization Format(OVF)是针对虚拟机快速发布，部署的一项业界标准协议，它以一种开放，可移植，安全的特点被越来越多的云计算厂商所支持。 OVF协议中最重要的一个概念就是OVF Package，使用它就可以快速的完成虚拟机的快速安装和配置，它包括以下部分：1) ovf 描述符文件, 后缀名是 .ovf。 一个XML格式文档，关于package的metadata和内容。描述的是虚拟化硬件的配置需求，产品细节，和许可证等 2) ovf清单文件，后缀名是.mf， 主要是关于package内文件的SHA-1摘要 3) ovf证书，后缀是.cert，通过对.mf文件的数字化签名来确保package有效性 4) disk映像文件，这个就是核心的安装了操作系统，应用软件的磁盘映像，有多种厂商的格式 5) 其他的一些资源文件，比如iso镜像文件 它主要包含的是关于虚拟机的软件化配置， ovf-env.xml是一种xml格式文件，一般位于ISO映像的根目录 OVF package可以以单个文件存在，后缀名是.ova 许多厂商的虚拟化管理软件都支持OVF，比如IBM的System Director, Vmware的Vsphere，通过专门的映像制作工具，可以制作相应的OVF packge，这样就可以方便的到不同的环境中进行导入和导出。 参考信息： 弯曲评论， ovf协议：虚拟机的mp3格式 DMTF， OVF 规范]]></content>
      <tags>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IBM i5-os ip 配置]]></title>
    <url>%2F2011%2F12%2F12%2FIBM%20i5-os%20ip%20%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[转自：http://www.ifeeling.net/article.asp?id=565 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162一、配置网卡的IP地址1、查看网卡的资源名称输入DSPHDWRSC *CMN ，显示通信资源信息：引用内容 引用内容 Display Communication Resources System: Type options, press Enter. 5=Display configuration descriptions 7=Display resource detail Opt Resource Type Status Text CMB01 286D Operational Combined function IOP LIN01 2771 Operational Comm Adapter CMN01 2771 Operational Comm Port CMN02 2771 Operational V.24 Port LIN02 2838 Operational LAN Adapter CMN03 2838 Operational Ethernet Port Bottom F3=Exit F5=Refresh F6=Print F12=Cancel 根据Text的描述，找到Ethernet Port的资源名就是网卡。系统可能会有几个Ethernet port，此处为CMN03。2、为该网卡资源创建线描述输入CRTLINETH，在出现的提示框中输入：Line Description:TCPIPResource name: CMN03回车，继续设置速度与双工，一般都设为*AUTO，回车后，出现“ Line description TCPIP created.” 提示，说明创建成功了。3、查看线描述，并VARY ON 线描述输入WRKLIND ,在TCPIP前输入8 (=Work with status)，查看当前状态为VARIED OFF.输入1(=Vary on)并回车，显示为VARY ON PENDINGF12退回，再次查看，已经是VARY ON的状态了。4、配置IP地址输入ADDTCPIFC，在界面中输入IP地址，掩码和线描述TCPIP，回车后提示： TCP/IP interface added successfully. 5、查看并激活IP地址CFGTCP回车，选择 1. Work with TCP/IP interfaces，可以看到刚才设置好的IP地址。按 F11=Display interface status，可以看到当前IP的状态是INACTIVE选9=Start，提示： Activating TCPIP to start IP 192.168.33.3 for QSECOFR in 000979/QSECOFR/D...F12回退，再显示IP状态，已经是Active。此时TCPIP已经创建，IP地址已经激活。找个同网段的主机Ping一下，测试成功。二、设置AS400的路由1、设置默认路由输入CFGTCP 再选择 2. Work with TCP/IP routes 在 Work with TCP/IP Routes 界面中，输入1=ADD，添加一条默认路由。注意默认路由的写法。Route destination:输入 *DFTROUTE 注意不能带单引号Subnet mask：输入 *NONE 注意不能带单引号Next Hop：输入网关的IP地址确认回车后可以看到新添加的默认路由。2、添加其它路由同上，直接输入相应的设置，输入时无需单引号。]]></content>
      <tags>
        <tag>系统运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VirtualBox中有4中网络连接方式]]></title>
    <url>%2F2011%2F12%2F11%2FVirtualBox%E4%B8%AD%E6%9C%894%E4%B8%AD%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[解释很好的一篇文章，来源：http://penpenguanguan.com/997.htmlVirtualBox中有4中网络连接方式： NAT Bridged Adapter Internal Host-only AdapterVMWare中有三种，其实他跟VMWare 的网络连接方式都是一样概念，只是比VMWare多了Internal方式。要让自己（或别人）理解深刻，方法就是做比较和打比方，比较之间的不同和相同，拿熟知的事物打比方。先来一张图，通过这张图就很容易看出这4种方式的区别： （注：此图直接取至Finalbug的Blog，表示感谢）再来用文字做详细的解释（其实归结起来就是上面的那张图）：1、NATNAT：Network Address Translation，网络地址转换NAT模式是最简单的实现虚拟机上网的方式，你可以这样理解：Guest访问网络的所有数据都是由主机提供的，Guest并不真实存在于网络中，主机与网络中的任何机器都不能查看和访问到Guest的存在。Guest可以访问主机能访问到的所有网络，但是对于主机以及主机网络上的其他机器，Guest又是不可见的，甚至主机也访问不到Guest。 虚拟机与主机的关系：只能单向访问，虚拟机可以通过网络访问到主机，主机无法通过网络访问到虚拟机。虚拟机与网络中其他主机的关系：只能单向访问，虚拟机可以访问到网络中其他主机，其他主机不能通过网络访问到虚拟机。虚拟机与虚拟机的关系：相互不能访问，虚拟机与虚拟机各自完全独立，相互间无法通过网络访问彼此。2、Bridged Adapter（网桥模式）网桥模式，你可以这样理解：它是通过主机网卡，架设了一条桥，直接连入到网络中了。因此，它使得虚拟机能被分配到一个网络中独立的IP，所有网络功能完全和在网络中的真实机器一样。网桥模式下的虚拟机，你把它认为是真实计算机就行了。 虚拟机与主机的关系：可以相互访问，因为虚拟机在真实网络段中有独立IP，主机与虚拟机处于同一网络段中，彼此可以通过各自IP相互访问。虚拟机于网络中其他主机的关系：可以相互访问，同样因为虚拟机在真实网络段中有独立IP，虚拟机与所有网络其他主机处于同一网络段中，彼此可以通过各自IP相互访问。虚拟机与虚拟机的关系：可以相互访问，原因同上。3、Internal（内网模式）内网模式，顾名思义就是内部网络模式：虚拟机与外网完全断开，只实现虚拟机于虚拟机之间的内部网络模式。 虚拟机与主机的关系：不能相互访问，彼此不属于同一个网络，无法相互访问。虚拟机与网络中其他主机的关系：不能相互访问，理由同上。虚拟机与虚拟机的关系：可以相互访问，前提是在设置网络时，两台虚拟机设置同一网络名称。如上配置图中，名称为intnet。4、Host-only Adapter（主机模式）主机模式，这是一种比较复杂的模式，需要有比较扎实的网络基础知识才能玩转。可以说前面几种模式所实现的功能，在这种模式下，通过虚拟机及网卡的设置都可以被实现。我们可以理解为Guest在主机中模拟出一张专供虚拟机使用的网卡，所有虚拟机都是连接到该网卡上的，我们可以通过设置这张网卡来实现上网及其他很多功能，比如（网卡共享、网卡桥接等）。 虚拟机与主机的关系：默认不能相互访问，双方不属于同一IP段，host-only网卡默认IP段为192.168.56.X 子网掩码为255.255.255.0，后面的虚拟机被分配到的也都是这个网段。通过网卡共享、网卡桥接等，可以实现虚拟机于主机相互访问。虚拟机与网络主机的关系：默认不能相互访问，原因同上，通过设置，可以实现相互访问。虚拟机与虚拟机的关系：默认可以相互访问，都是同处于一个网段。以上关于这4种连接方式的文字解释，基本上抄自于(转)VirtualBox网络设置与应用详解（图解+文字）这篇文章，但没有找到此文的原始出处。关于这几种连接方式，理解VMWare的三种网络连接模式(bridged、NAT、host-only)里的解释只是换了文字来表述，虽然显得重复，但为了理解，干脆就写成了这两篇Blog。 Update：我刚装上VirtualBox的时候所有的网络连接方式都试过了，但虚拟机和虚拟机之间就是不能相互访问，Ping都Ping不通，我在想难道VirtualBox的网络设置有这么复杂吗，后来想到是不是WindowsXP的防火墙的问题，关闭之，一切就正常了，Fuck！]]></content>
      <tags>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kate 软件使用，开启console]]></title>
    <url>%2F2011%2F12%2F11%2FKate%20%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8%EF%BC%8C%E5%BC%80%E5%90%AFconsole%2F</url>
    <content type="text"><![CDATA[Kate 不错的编辑工具： 当安装到ubuntu下，可能console开启不了，解决方案如下： When you click the Terminal button in Kate, but a terminal does not show up, it’s simply because Kate requires the Konsole terminal and you don’t have it installed yet. To install it just do: sudo apt-get install konsole]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python __init__.py]]></title>
    <url>%2F2011%2F12%2F04%2Fpython%20__init__.py%2F</url>
    <content type="text"><![CDATA[最近接触了python，看到init.py 感到很奇怪。经过查资料发现，这是python引进的package管理机制的产物。 cnblog有篇文章写的比较清晰，转载与此，仅作个人资料查看。 http://www.cnblogs.com/tqsummer/archive/2011/01/24/1943273.html 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677python中的Module是比较重要的概念。常见的情况是，事先写好一个.py文 件，在另一个文件中需要import时，将事先写好的.py文件拷贝 到当前目录，或者是在sys.path中增加事先写好的.py文件所在的目录，然后import。这样的做法，对于少数文件是可行的，但如果程序数目很 多，层级很复杂，就很吃力了。有没有办法，像Java的Package一样，将多个.py文件组织起来，以便在外部统一调用，和在内部互相调用呢？答案是有的。主要是用到python的包的概念，python __init__.py在包里起一个比较重要的作用要弄明白这个问题，首先要知道，python在执行import语句时，到底进行了什么操作，按照python的文档，它执行了如下操作：第1步，创建一个新的，空的module对象（它可能包含多个module）；第2步，把这个module对象插入sys.module中第3步，装载module的代码（如果需要，首先必须编译）第4步，执行新的module中对应的代码。在执行第3步时，首先要找到module程序所在的位置，其原理为：如 果需要导入的module的名字是m1，则解释器必须找到m1.py，它首先在当前目录查找，然后是在环境变量PYTHONPATH中查找。 PYTHONPATH可以视为系统的PATH变量一类的东西，其中包含若干个目录。如果PYTHONPATH没有设定，或者找不到m1.py，则继续搜索 与python的安装设置相关的默认路径，在Unix下，通常是/usr/local/lib/python。事实上，搜索的顺序是：当前路径 （以及从当前目录指定的sys.path），然后是PYTHONPATH，然后是python的安装设置相关的默认路径。正因为存在这样的顺序，如果当前路径或PYTHONPATH中存在与标准module同样的module，则会覆盖标准module。也就是说，如果当前目录下存在xml.py，那么执 行import xml时，导入的是当前目录下的module，而不是系统标准的xml。了解了这些，我们就可以先构建一个package，以普通module的方式导入，就可以直接访问此package中的各个module了。Python中的package定义很简单，其层次结构与程序所在目录的层次结构相同，这一点与Java类似，唯一不同的地方在于，python中的package必须包含一个__init__.py的文件。例如，我们可以这样组织一个package:package1/ __init__.py subPack1/ __init__.py module_11.py module_12.py module_13.py subPack2/ __init__.py module_21.py module_22.py ……__init__.py可以为空，只要它存在，就表明此目录应被作为一个package处理。当然，__init__.py中也可以设置相应的内容，下文详细介绍。好了，现在我们在module_11.py中定义一个函数：def funA(): print "funcA in module_11" return在顶层目录（也就是package1所在的目录，当然也参考上面的介绍，将package1放在解释器能够搜索到的地方）运行python:&gt;&gt;&gt;from package1.subPack1.module_11 import funcA&gt;&gt;&gt;funcA()funcA in module_11这样，我们就按照package的层次关系，正确调用了module_11中的函数。细心的用户会发现，有时在import语句中会出现通配符*，导入某个module中的所有元素，这是怎么实现的呢？答案就在__init__.py中。我们在subPack1的__init__.py文件中写__all__ = ['module_13', 'module_12']然后进入python&gt;&gt;&gt;from package1.subPack1 import *&gt;&gt;&gt;module_11.funcA()Traceback (most recent call last): File "", line 1, in ImportError: No module named module_11也就是说，以*导入时，package内的module是受__init__.py限制的。好了，最后来看看，如何在package内部互相调用。如果希望调用同一个package中的module，则直接import即可。也就是说，在module_12.py中，可以直接使用import module_11如果不在同一个package中，例如我们希望在module_21.py中调用module_11.py中的FuncA，则应该这样：from module_11包名.module_11 import funcA]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Network-manager Panel没有的问题，如何配置]]></title>
    <url>%2F2011%2F11%2F15%2FNetwork-manager%20Panel%E6%B2%A1%E6%9C%89%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%8C%E5%A6%82%E4%BD%95%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[解决办法:编辑nm-system- settings.conf文件,将managed = false改为 truesudo gedit /etc/NetworkManager/nm-system-settings.conf[ifupdown]managed=truesudo /etc/init.d/network-manger restart 就可以看到状态为已经连接了. 注：还有一个信息和上面的无关，为了简单就记在这里，（ubuntu 10.04 更改最大化最小化关闭按钮位置 ），见参考资料2 Alt + F2 ，运行 gconf-editor 在左侧目录树中，找到 /apps/metacity/general/ 在右侧找到键： button_layout ， 修改值为 menu:minimize,maximize,close Ubuntu 关闭触摸板：sudo modprobe -r psmouse即可。如果想打开的话可以把前面两种方式中的-r去掉即可。 来源：[1]http://www.brucebot.com/2010/05/solve-error-of-gnome-panel-and-network-manager-under-ubuntu-1004/[2]http://apps.hi.baidu.com/share/detail/17102222[3] http://blog.csdn.net/iaccepted/article/details/6857454]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[T420 Linux 安装的问题]]></title>
    <url>%2F2011%2F11%2F14%2FT420%20Linux%20%E5%AE%89%E8%A3%85%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题一,因为软件兼容问题，需要安装ubuntu 10.04，但是这个版本的Linux对T420的支持的并不好。 操作系统安装后发现无法上网，网卡无法识别。查资料发现，需要安装一个e1000e的驱动，于是下载最新的版本：http://sourceforge.net/projects/e1000/files/e1000e%20stable/安装里面的README说明，解决了上网问题。 问题二，AT&amp;T VPN client问题，不知道是因为ubuntu版本缘故还是怎么的，11.10是能使用http://huang.yunsong.net/2008/att-network-client-ubuntu.html说的发现是可行的，但是10.04怎么就是不行，出现Kill VPN的错误，好吧。继续搜索，发现一个顶用的信息：http://www.attnetclient.com/forum/viewtopic.php?t=715解决问题 问题三，Java plugin for Firefox brower因为使用的是openjdk，所以需要新的插件，sudo apt-get install icedtea6-plugin如果是sun的jdk那么就用ubuntu wiki的说明：http://wiki.ubuntu.org.cn/Qref/More#.E7.BC.96.E8.AF.91.E7.8E.AF.E5.A2.83.E9.85.8D.E7.BD.AE本人还是跟随ubuntu推荐的openjdk算了，不跟sun凑热闹了。 问题四，显卡的分辨率低，还是ubuntu 10.04的驱动问题，11.10是没有问题的，好吧，那我就编译3.0内核试试，因为1024*768的分辨率实在无法忍受。 编译内核需要注意的问题，1） 一个是 mdio-gpio的already register的问题，虽然不影响进入操作系统，但是每次都打印一行这种信息，很碍眼。所以，为了避免编译内核出现这种问题，那么就需要，将 MDIO_GPIO 这一项的config配置成 编译成模块，默认的是编译进内核。这样就不会出现这个问题了。 2）对于显卡的问题，编译内核的时候注意nvidia，intel的显卡相关的选项都配成编译成模块,或者编译进内核.还有一个Laptop Hybrid Graphics 选上，毕竟这个T420是支持双显卡的。 3）关于编译后出现的module dep的问题，我在自己的前面的内核编译中讲过处理的办法，这里不再说明。 4）编译后的有个问题是声卡正常，外音没有，耳机插入有声音。 好吧，这个暂时可以忍受。 5）无线网卡也可以识别出来，自己进行配置选取可行的网络，即可。 6）编译后的显卡直接是1600900， 没有其他的选项，有点不足，不过比1024768的好多了。]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[usb 安装 iso 文件, 安装 ubuntu]]></title>
    <url>%2F2011%2F11%2F13%2Fusb%20%E5%AE%89%E8%A3%85%20iso%20%E6%96%87%E4%BB%B6%2C%20%E5%AE%89%E8%A3%85%20ubuntu%2F</url>
    <content type="text"><![CDATA[刻录光盘安装发现费事,而且一不小心就浪费一张,搞的很疲惫. 后来网上发现,直接使用USB(只要是FAT16 或32格式就行,于是,果断采取USB安装. 下载制作软件 Universal USB Installer 下载ubuntuI的ISO 制作完成, 修改电脑BIOS的Boot顺序, Flash Disk优先 安装OS开始, 完成 Universal USB Installer is a Live Linux USB Creator that allows you to choose from a selection of Linux Distributions to put on your USB Flash Drive. The Universal USB Installer is easy to use. 具体参考细节: http://www.pendrivelinux.com/universal-usb-installer-easy-as-1-2-3/]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟化技术简介[转]]]></title>
    <url>%2F2011%2F11%2F13%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF%E7%AE%80%E4%BB%8B%5B%E8%BD%AC%5D%2F</url>
    <content type="text"><![CDATA[看到一篇还不错的介绍虚拟化的文章，所以记下来来源：http://www.cnblogs.com/ventlam/archive/2010/10/09/1846862.html一.虚拟化技术的类型 1.全虚拟化全虚拟化(Full virtualization),也称为原始虚拟化技术,全虚拟化是指虚拟机模拟了完整的底层硬件，包括处理器、物理内存、时钟、外设等，使得为原始硬件设计的操作系统或其它系统软件完全不做任何修改就可以在虚拟机中运行。该技术架构图如图1-1所示： 图1-1. 全虚拟化: 使用Hypervisor分享底层硬件由于计算机硬件化资源被抽象化，必须需要一个机制来管理抽象化之后的资源。这个机制一般称作Hypervisor或者VirtualMachine Monitor(VMM)。该模型使用虚拟机协调客户操作系统和原始硬件.因为VMM在客户操作系统和裸硬件之间用于工作协调.一些受保护的指令必须由Hypervisor(虚拟机管理程序)来捕获和处理.因为操作系统是通过Hypervisor来分享底层硬件。全虚拟化的运行速度要快于硬件模拟, 但是性能方面不如裸机, 因为Hypervisor需要占用一些资源.它的唯一限制是操作系统必须能够支持底层硬件(比如, PowerPC) 代表项目;VMWare 闭源/ z/VM(IBM) 闭源2.半虚拟化半虚拟化(Paravirtualization)是另一种类似于全虚拟化的热门技术.它使用Hypervisor(虚拟机管理程序)分享存取底层的硬件。半虚拟化技术使得操作系统知道自身运行在一个Hypervisor，它的客户操作系统集成了虚拟化方面的代码. 该方法无需重新编译或引起陷阱, 因为操作系统自身能够与虚拟进程进行很好的协作.如图1-2所示： 图1-2半虚拟化: 通过客户操作系统分享进程上面提到过, 半虚拟化需要客户操作系统做一些修改(配合Hypervisor), 这是一个不足之处. 但是半虚拟化提供了与原始系统相近的性能. 与全虚拟化一样, 半虚拟化可以同时能支持多个不同的操作系统.代表项目： XEN GPL / UML GPL3.硬件辅助虚拟化硬件辅助虚拟化(Hardware-assiisted virtualization).或者称作硬件虚拟机(HVM)主要是指操作系统在其之上运行时,必须靠系统的硬件来完成虚拟化的过程。硬件辅助虚拟技术不但能够提高全虚拟的效率（VM的产品都加入该类功能），而且使用半虚拟技术的XEN也通过该项技术做到支持Window，Mac之类闭源的操作系统。该技术的架构图如图1-1所示： 图1-3. HVM架构图 X-86平台（包括X-86 64，AMD64）上的硬件辅助虚拟化项目主要是：Intel的VT和AMD的AMD-V 操作系统级的虚拟化最后一个需要了解的虚拟化技术是操作系统级的虚拟化(Operating system-level virtualization),它使用不同于上面的虚拟化方法. 该类只能仿真出主机的操作系统，如在Linux上只能运行Linux，Window上只能运行Window 图1-4操作系统级的虚拟化: 隔离单个服务器二.具体的虚拟化产品1.XENXen作为最优秀的半虚拟化引擎，在基于硬件的虚拟化的帮助下，现在也支持完全虚拟化MS windows了.XEN架构如图2-1所示： 图2-1 XEN架构 最底层的是计算机硬件，包括CPU，RAM，硬盘接口，网卡，外设数据总线等等。硬件层之上，是Xen hypervisor层，包括总控界面（Xen Control Interface），虚拟CPU，虚拟RAM，虚拟硬盘，虚拟网卡等等。在Xen层之上，是各个OS实例（OSinstances）。其中最左边的OS实例很特别。在启动Xen的时候，最左边的OS实例，Domain0 onXenoLinux，自动被启动。Domain0里运行着Xen ControlSoftware，这个软件控制着各个OS实例的启动，终止，以及监控其运行情况。Domain0对于其它OS实例的控制，是通过Xen层中Xen Control Interface来实现的。而这个XenControlInterface只对Domain0开放。其它OS实例只有被管理的义务，而没有管理其它实例的权力。DomUs可以运行被修改过或者标准化的操作系统。被修改的系统运行在paravirtualization（半虚拟化）每个OS实例都被分配一套虚拟的CPU，RAM，硬盘和网卡。每个OS实例使用这些虚拟的设备，与通常的OS并无不同。在新版的XEN中通过PCI允许客户OS直接读取硬件，以提高整体性能。如图2-2所示，客户OS直接使用硬件 图2-2客户OS通过XEN PCI 直接读取硬件 2.KVMKVM是在X86平台上的Linux全虚拟化方案。Linux 2.6.20内核增加了KVM虚拟化技术.它的特点是系统内核通过添加KVM的kernel module（kvm.ko），使系统内核自身成为一个Hypervisor(虚拟机管理程序)。内核中的KVM模块通过/dev/kvm字符串设备显示被虚拟的硬件. KVM使用修改过的QEMU进程做为客户操作系统接口.ＫＶＭ的虚拟化架构如图2-3所示： 图2-3. KVM的虚拟化 KVM模块向内核增加了一个新的执行模式: 客户模式. 官方原始内核(vanilla kernel)支持内核和用户模式. 客户模式用于执行所有非I/O客户代码, 普通用户模式支持客户I/O.它是第一个整合到Linux内核的虚拟化技术. 3.VMware WMware是全球最大的虚拟化厂商，该公司产品线漫长，主要包括桌面版的 Vmware workstation和企业版的VMWare ESX server。它们使用的虚拟化技术主要是全虚拟，在加上硬件辅助虚拟化后，产品性能有所提高。 在云计算中，VM主打产品是vSphere。它是非常完整的虚拟机群集产品，其组件包括：ESX Server 群，vCenter管理中心，数据库，vSphere （VI4）客户端。vSphere组件层如图2-4所示： 图2-4vSphere组件层]]></content>
      <tags>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VirtualBox - 自动调整屏幕大小，显示分辨率]]></title>
    <url>%2F2011%2F10%2F22%2FVirtualBox%20-%20%E8%87%AA%E5%8A%A8%E8%B0%83%E6%95%B4%E5%B1%8F%E5%B9%95%E5%A4%A7%E5%B0%8F%EF%BC%8C%E6%98%BE%E7%A4%BA%E5%88%86%E8%BE%A8%E7%8E%87%2F</url>
    <content type="text"><![CDATA[在VirtualBox中安装了Ubuntu后，Ubuntu的屏幕调整不太好，操作起来非常不方便，需要安装Vbox的增强功能。具体如下： 在 设备–》 安装增强功能这时会自动加载VBOXADDITIONS的虚拟光盘 /media/VBOXADDITIONS_4.0.10_72479 （4.0.10_72479是版本号）找到对应的操作系统的文件，比如Linux的是，VBoxLinuxAdditions.run 运行这个文件，需要管理员权限 操作完成，重启Ubuntu 然后，就会，发现其中的菜单项“Switch to Seamless Mode”可以使用了 点击“自动调整窗口大小”菜单项，这样屏幕分辨率会随着屏幕大小自动调整，非常方便 参考资料：http://aofengblog.blog.163.com/blog/static/631702120101117104437593/]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat7.0 jndi连接池的配置]]></title>
    <url>%2F2011%2F09%2F04%2FTomcat7.0%20%20jndi%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%9A%84%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[测试环境： 123456ubuntu 11.04Kernel: 2.6.38Mysql: 5.1.54Tomcat: 7.0eclipse: 3.6Mysql数据库驱动： mysql-connector-java-5.1.17.zip 因为打算看看后端的数据库操作，所以就搭了环境试验一下，对于普通的数据库连接（使用JDBC的方式，比较简单，所以就试验jndi 连接池） 搭建好tomcat服务器 在mysql建立一个BookDB的数据库，建立一个books表，内容如下： 123456789mysql&gt; select * from books;+-----+-----------+------------------------+-------+------+--------------------------------+------------+| id | name | title | price | yr | decription | saleAmount |+-----+-----------+------------------------+-------+------+--------------------------------+------------+| 201 | wangfang | Java programming guide | 33.75 | 1999 | Guide user to grasp quickly | 1001 || 202 | zhangbing | Weblogic tech | 50.25 | 2000 | Good to learn web logic | 2000 || 203 | sunyan | Oracle Database | 60 | 2002 | database entry book | 2700 || 204 | Aling | Hadoop Guide | 100 | 2004 | A cookbook for distrbuted Arch | 5700 |+-----+-----------+------------------------+-------+------+--------------------- 将Mysql驱动中得jar文件拷贝到 {TomcatHome}/lib/ 使用eclipse建立一个Dynamic Web Project, 在META-INF/ 下建立context .xml 1234567891011121314151617181920212223xml version="1.0" encoding="UTF-8"?&gt;&lt;Context&gt;&lt;Resource auth="Container"driverClassName="com.mysql.jdbc.Driver"maxActive="100"maxIdle="40"maxWait="12000"name="jdbc/BookDB"username="root"password="test"type="javax.sql.DataSource" url="jdbc:mysql://localhost:3306/BookDB?characterEncoding=UTF-8" /&gt;Context&gt; 在WEB-INF/ 下创建 web.xml 12345678910'-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN''http://java.sun.com/j2ee/dtds/web-app_2_3.dtd'&gt; DB Connection jdbc/BookDB javax.sql.DataSource Container``` 5. 创建jsp文件， index.jsp &lt;%@ page language=”java” import=”java.util.,javax.naming.,java.sql.,javax.sql.“pageEncoding=”UTF-8”%&gt; &lt;% Context ctx = new InitialContext(); String strLookup = &quot;java:comp/env/jdbc/BookDB&quot;; DataSource ds =(DataSource) ctx.lookup(strLookup); Connection con = ds.getConnection(); if (con != null){ out.print(&quot;success&quot;); }else{ out.print(&quot;failure&quot;); } %&gt;` 运行，OK]]></content>
      <tags>
        <tag>Mysql/postgreSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell的特殊符号]]></title>
    <url>%2F2011%2F08%2F03%2Fshell%E7%9A%84%E7%89%B9%E6%AE%8A%E7%AC%A6%E5%8F%B7%2F</url>
    <content type="text"><![CDATA[这里的记录仅仅是备忘，标记前人做的很好的总结，以备很好的作为工具书查看： http://blog.csdn.net/wiserstar/article/details/4345628 shell中的if判断： http://hi.chinaunix.net/?483016/viewspace-44373]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux sed工具的用法]]></title>
    <url>%2F2011%2F08%2F03%2FLinux%20sed%E5%B7%A5%E5%85%B7%E7%9A%84%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[sed的用法，如果不常用就老是忘记，搜到了两篇文章，介绍的很好，特此标记一下，以后就不费功夫每次搜索找了： 一篇是介绍去掉空格相关的：http://www.blogjava.net/xzclog/archive/2010/12/28/341752.html 还有一篇是介绍sed用法的，里面包含很多奇妙的替换方法： http://blog.csdn.net/wxm7075/article/details/5260110 最后一篇来了个sed集锦，也不错： http://blog.csdn.net/y8421/article/details/6441694]]></content>
      <tags>
        <tag>Python/Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop的配置问题（windows下eclipse）]]></title>
    <url>%2F2011%2F07%2F31%2Fhadoop%E7%9A%84%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98%EF%BC%88windows%E4%B8%8Beclipse%EF%BC%89%2F</url>
    <content type="text"><![CDATA[配置eclipse和hadoop关联有点费工夫，主要是eclipse for hadoop的插件和eclipse版本有些兼容的关系，比较乱，基本参考：（1）http://ebiquity.umbc.edu/Tutorials/Hadoop/23%20-%20create%20the%20project.html 里面针对的是hadoop的老版本，如果是0.20.2或最新的0.20.203，那么插件会出现不工作的情况，我用eclipse 3.6，hadoop 0.20.203，没有配成功，主要是在最后的run on hadoop的问题，具体参考： （2）http://hi.baidu.com/laxinicer/blog/item/fbaddaf58bdae63fbc3109a0.html 你需要将下载的插件，更名为对应你hadoop版本的文件名，比如你的下载的插件是：hadoop-eclipse-plugin-0.20.3-SNAPSHOT.jar，而你的hadoop是0.20.2那么需要更名为：hadoop-0.20.2-eclipse-plugin.jar 然后按照（1）操作就行了，那么run on hadoop的问题就基本解决了。还有一篇参考，可以看看。http://hi.baidu.com/nowhere/blog/item/10a18ab1ce580641092302ba.html 这个不兼容真是一个头疼的事情。]]></content>
      <tags>
        <tag>WINDOWS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[朱雀森林公园攻略]]></title>
    <url>%2F2011%2F06%2F18%2F%E6%9C%B1%E9%9B%80%E6%A3%AE%E6%9E%97%E5%85%AC%E5%9B%AD%E6%94%BB%E7%95%A5%2F</url>
    <content type="text"><![CDATA[外出游玩最重要的一件事莫过于从网上获取前人的攻略指南，他们的经验在很大程度上会减少我们的时间成本损失，也同样囊括了不少安全上的提示，非常有用。 我们根据前人的朱雀旅行行程建议，安排了两天的时间。如果你是从西安出发，具体的建议是这样：从西安到户县的这一段路程是走高速，那么你从城南客运站买票，一定注意买高速的票，公交的比较慢。如果西安市里交通不算拥堵的话，到户县差不多要60分钟。到户县下车后，到三球仪（南站）坐车去朱雀森林公园。由于下车的地方离三球仪还是有一段距离的，所以你可以坐三轮车过去，也就4块钱。 从户县到朱雀森林公园一共4班车，最早的一班是9：00，其次分别是10：00，12：30，13：30，最好赶9:00那班，或者10：00，再晚的话，当天的旅游就泡汤了。 我们没赶上9：00那班车，只能10：00出发，由于高速有时会堵车（恰巧我们碰到了，还好时间不长），所以尽量安排的行程不要太晚 ，户县到朱雀森林公园需要60分钟。 朱雀森林公园海拔较高，最高顶冰晶顶3105米，从龙潭口到冰晶顶来回需要7～8个小时，所以我们当天爬完是不可能，最好安排两天的时间。我们在公园门口找了一家农家乐，定了房子，房价30元/人，（据说旺季会贵一些）。房子尽量多做比较，虽说价钱相差不是太大，但是还是有相当比较的余地，我们找的房间虽然贵点，但是比较舒适，有独立的卫生间。 按照时间初步安排，当天走龙潭子景区，明天走冰河翠景区，赶下午2：30的班车回户县，然后坐车回西安。 龙潭子景区景点较多，以瀑布较多，开发的还算完善，都有台阶（从龙潭口到草甸营地的路都比较好走，草甸营地海拔2530米）。我们在农家乐稍作休息后，才从景区门口出发，从景区门口到龙潭口（真正的景区入口）大概有4公里路程，这段路是公路，景点没有什么特别。考虑到时间和体力因素，推荐雇个面包车，（农家乐都有，或者让售票点的师傅联系面包车），30元/趟，5，6个人的话比较合算。 我们从龙潭口1：00出发，走龙潭子景区到搓石板接近4：20，然后下山，回农家乐6：10。当天我们没做面包车，因为也没打算当天爬很高。 第二天，6：20出发，做面包车到龙潭口，开始了探险之旅——冰河翠景区，这一段路到山顶，比较原始，都没有很好的开发，以土路为主。一路上顺着清晰的红色路标前进即可，因为这一段路程比较崎岖和原始，建议3个人以上结伴行进。最美的莫过于登上高山草甸，走出原始森林俯瞰山下云雾缭绕，相当壮观。从冰川遗迹再往上走就很快了，我们到冰晶顶时大概是11：00，这时一览众山小的感觉才真切的感受到，山顶的风很大，好在6月份的山顶不是很冷，所以短袖也没问题。由于要赶2：30的车，我们在山顶没长时间停留，开始下山。要是从冰河翠景区这一段路下山，那就不太容易了，我们也没打算原路返回，这就没意思了。我们正好打算从草甸营地，杜鹃林那边下山，因为昨天也没走完那段路，这样就正好完成穿越。 从冰晶顶到草甸营地的这段下山路都是大石块相互堆叠而成，一般需要四肢并用，不是很容易，要注意安全。走过这段路后，基本都是台阶了，相当轻松了，我们到龙潭口2：10，然后让面包车送我们下山，赶上了2：30的旅游班车。时间安排恰好，农家乐的老板都不敢相信我们这么快就到了山顶，完成了穿越。说实话，我们在上山的路上还走走停停不少，也不是一直走，就是下山的这段路基本没多少休息。值得赞叹的是通行的4位师大女生都跟着完成了穿越，赞她们的毅力。 总的说来，朱雀之行的建议如下： 至少安排两天的时间，两天足够了。 出行前了解朱雀森林公园的最近两天的天气，下雨天切莫登顶，比较危险。 完成穿越，最好是留第二天行走冰河翠景区，第一天就走龙潭子景区即可。 不要带太多的食物，最靠近景区门口的农家乐的饭菜价格还算合理，只是肉菜比较贵，其他还算可以，一般的像葱花鸡蛋18元/盘，一个大饼（够两个人吃）8元/个，一碗面8元/碗，所以可以安排两顿饭在农家乐吃（第一天的中午和晚上），第二天的一顿半就吃自己带的食物即可。 从西安到户县的车尽量赶早，最好赶上户县到朱雀的9：00的那班车。 注意防晒，第一天是晴天，阳光比较强烈，我和同学没抹防晒霜，结果回来皮肤真晒伤了，红红的，蛮疼的。 不懂的问题，尽量咨询景区的人员和农家乐的老板。 注意安全，最好3人以上，领队的要注意天气变化，合理安排时间和路线，安全第一。 冰河翠景区的那条线山脚下有个牌子写的未开发区域，禁止由此上山，有吓人之嫌，也许景区考虑这条线路比较原始，害怕出意外，所以来告诫游人。但是以我们的行走经历，只要不是阴雨雪天气，这段路还是比较安全的，只要3人以上结伴行进即可。 最后说一句：朱雀森林公园真的是一个值得爬山和穿越的地方。]]></content>
  </entry>
  <entry>
    <title><![CDATA[翠华山游记]]></title>
    <url>%2F2011%2F06%2F11%2F%E7%BF%A0%E5%8D%8E%E5%B1%B1%E6%B8%B8%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[常听别人提起翠华山，说没什么爬的意思，但是实在没去过，心里觉得别人说的或许有失公正，毕竟有华山二字相配。曾登过华山，对华山颇有好感，觉得险峻实在名不虚传。 早晨出发，经旅游专线一个小时的路程到了翠华山脚下。沿山而上，经碧水湖瀑布，台阶不算陡峭，但是比较短小，所以爬起来有些费劲。其实翠华山最有意思（也可能是最有名）的地方在于天，风和冰洞。天，风，冰洞颇有人间避暑佳境，但是天洞和冰洞里面有过多的人工雕琢之感，一线天的景观以风洞为代表。6月份的天气大约在35度左右，冰洞气温在-4度左右，所以进去后会感觉冷气逼人。 翠华山海拔才1000米，所以整个行程比较快，大概3个小时，时间比较充裕，玩的还算尽兴。 华山乃大家闺秀，险奇峻拔，颇为壮观。翠华山却多了份小家碧玉，以独特景观让人印象深刻，尤其群峰围绕，天池之水从天而下，颇有意思。]]></content>
  </entry>
  <entry>
    <title><![CDATA[linux下恢复ntfs分区的误删文件]]></title>
    <url>%2F2011%2F05%2F26%2Flinux%E4%B8%8B%E6%81%A2%E5%A4%8Dntfs%E5%88%86%E5%8C%BA%E7%9A%84%E8%AF%AF%E5%88%A0%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[linux下恢复ntfs分区的误删文件 今天操作文件的时候，稍不留神，直接shift+del一个重要文件，很郁闷。但是想想windows下自己试过不少恢复软件，能够工作的不错，linux下应该也很多，所以就决心寻找丢失的文件。查了个debugfs，实在用不来，恢复老出问题。后来用了ntfsundelete终于搞定！所以写下来，也算给大家些资料。 恢复过程： 确定你删除文件的分区，这个用fdisk -l就可以了。（比如 /dev/sda6) 卸载误删的分区，因为会检查ntfs卷是否处于打开状态。也不用卸载，直接使用-f选项，不进行检查。 查看最近三天（这个在参数里可以设置，就是下面的3d）删除的文件 1$ sudo ntfsundelete /dev/sda6 -f -t 3d 这时会列出，下面的信息： 123456Inode Flags %age Date Size Filename2012 ......... ..... ... 603136 2022 ......... ..... ... 70 ....Files with potentially recoverable content 8 还好，表明还有8个文件可以恢复。因为列出来的文件名都是none，那我怎么知道我要恢复的文件？ 笨方法是一个个恢复，不过大家都不笨，根据时间，大小的信息可以推断。注意列出来的时间可不是删除文件的时间。就像你ls列出文件的时间，这个是你最近修改文件的时间戳。我删除的是word文档，比较大，一眼能看出来，而且是昨天修改保存的。所以直接锁定2012这个inode。 恢复文件到指定的目录（如 /home/nice) 1$ sudo ntfsundelete /dev/sda6 -f -u -i 2012 -d /home/nice /home/nice下就出现一个unknown的文件，查看是不是你的文件。 哦，god，谢天谢地，真是原来的word文档，ntfsundelete这家伙不赖！ 参考资料：http://www.06net.com/article/20110412/75860.html]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[量子计算机首次正式投入商用， 真的是量子计算机？]]></title>
    <url>%2F2011%2F05%2F23%2F%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E9%A6%96%E6%AC%A1%E6%AD%A3%E5%BC%8F%E6%8A%95%E5%85%A5%E5%95%86%E7%94%A8%EF%BC%8C%20%E7%9C%9F%E7%9A%84%E6%98%AF%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97%E6%9C%BA%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[看了今天的IT资讯，D-Wave One满天飞，128量子比特，液氮，10,000,000$的天价，可谓大热！ 但是报道中没有对所谓的量子计算机细节进行剖析，究竟算不算真正意义上的量子计算机：wiki上，量子计算机： 量子信息存储单位 + 对应于适当量子算法的量子电路 + 量子测量量子计算机需要解决量子计算中的相干性问题，提高量子的相干性，有利于处理更为复杂的问题，至于所谓的最优动力学解耦成为了一种保持量子相干性的方法。对于这个计算机到底是炒作噱头还是踏进了量子计算机的门槛，留待专家们认真申论。 量子编程会是啥样子，现在的多核编程还没出现什么重大的进步，如果量子编程也是杀伤脑细胞的话，那真是够狠的，呵呵。]]></content>
      <tags>
        <tag>IT业界</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装，使用perfsuite性能分析]]></title>
    <url>%2F2011%2F05%2F17%2F%E5%AE%89%E8%A3%85%EF%BC%8C%E4%BD%BF%E7%94%A8perfsuite%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[编译过程：首先编译之前确保安装了perfsuite组件正常工作必须依靠的软件或补丁：参见INSTALL说明：实验环境ubuntu10.04 我的安装环境linux-2.6.36，已经包含了对performance counter的支持安装PAPI，这个安装很简单，参见其INSTALLexpattcl/tktdombfdMPI(可选)Cube(可选) 说明：expat tcl/tk tdom 安装都比较简单（至少在ubuntu下）直接 sudo apt-get install ** 一般tcl, expat tdom都要安装dev版本. 因为没有安转dev版本，会在configure输出中有warning，这个你只需要通过查看configure输出，确保没有warning（当然必须没有error)，configure就成功了. /这里注明一下：还是有一个warning的，关于Test.class。WARNING: I have to compile Test.class from scratch这个没什么影响，说明编译是通的过的。关于fortran编译器我指定的是gfortran，貌似用f77有问题 / 还有bfd这个库，就是安装binutils-dev configure配置选项，主要是因为对于默认的安装目录不一致时，你需要明确的指出。包括papi，tdom库， linux内核的源码目录(你当前使用的内核，uname -r可以查看)还有你要安装perfsuite的目录。我的如下： 1# ./configure --prefix=/home/jsi/software/perfsuite-1.0.0b1/ --with-papi=/home/jsi/software/papi-4.1.2.1/ --with-tdom=/usr/lib/tcltk/tdom0.8.3/ --with-kernel-srcdir=/usr/src/linux-2.6.36.2-change/ &gt;output 2&gt;&amp;1 这里的output是configure过程的输出。为了方便查看。 编译：n为你的cpu核数，为了加快编译速度 1#make -jn 运行测试suite 1#make -s check 看看输出是不是都ok，如果有错误参见INSTALL中的Running the test suite一部分，我的没有 安装 1#make install Finally, you can remove files created during the build to further conserve ondisk space by running: make clean (or) make distclean 体验以下perfsuite的功能 set up environment， 主要是你的安装目录不是默认的情况下， 1#. $PERFSUITEDIR/bin/psenv.sh 其中的PERFSUITEDIR是你configure中指定的安装目录具体参见psrun等的document 卸载在你build的目录执行 1#make uninstall]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VNC远程登陆xfce桌面]]></title>
    <url>%2F2011%2F04%2F21%2FVNC%E8%BF%9C%E7%A8%8B%E7%99%BB%E9%99%86xfce%E6%A1%8C%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[vnc登陆gnome桌面刷新屏幕速度慢的实在无法忍受，所以查查资料，发现xfce轻量级桌面会使速度加快不少，所以就试试，动手如下： 安装xfce桌面环境，就弄个简单的吧 1sudo apt-get install xfce4 你也可以试试xubuntu-desktop2，我觉得越简单越好，所以就用xfce4就行了 安装x11vnc服务 1sudo apt-get install x11vnc 打开服务准备远程登陆（**是你指定的密码，明文很恶心，不知道有没有加密的方法输入） 1sudo x11vnc -forever -passwd ****** 使用你的windows上的vnc viewer软件登陆就行了，这个简单，就是指定对应远程机器的ip，然后根据提示的输入第3步设置的密码即可。 感谢资料：http://blog.csdn.net/kartorz/archive/2009/06/14/4268372.aspxhttp://wiki.ubuntu.org.cn/index.php?title=%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2&amp;variant=zh-tw]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redhat5 企业版的编译老问题]]></title>
    <url>%2F2011%2F03%2F30%2Fredhat5%20%E4%BC%81%E4%B8%9A%E7%89%88%E7%9A%84%E7%BC%96%E8%AF%91%E8%80%81%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[前段时间ubuntu编译的步骤在redhat下还是遇到了些问题，主要是 mount:could not find filesystem ‘/dev/root’解决方法： http://www.hetlife.com/compile-the-kernel-prompt-mount-could-not-find-filesystem-devroot-solution.html 编译时修改.config文件中的“CONFIG_SYSFS_DEPRECATED_V2”，默认该选项为not set,被注释掉的，将其改为y。即修改为“CONFIG_SYSFS_DEPRECATED_V2=y”，修改后，再编译，重启即正常了。（这个在make menuconfig可以查看相关的选项说明，说是老linux发行版版本存在这个问题） insmod: error inserting ‘/lib/dm-region-hash.ko’ : -1 File exists这个问题不影响启动，但是看着碍眼， 123456789101112131415解决方法： http://linuxme.blog.51cto.com/1850814/3907781.解压initrd文件 #mkdir /var/aa #cp /boot/initrd-2.6.30.4.img /var/aa #cd /var/aa # mkdir newinitrd # cd newinitrd/ # zcat ../initrd-2.6.30.10.img | cpio -i10236 blocks释放之后看到如下内容 lsbin dev etc init lib proc sbin sys sysroot 2.vim init#删除一下重复的两行 重新打包initrd 123456 #find . | cpio -c -o &gt; ../initrd # cd .. # rm -f initrd-2.6.30.10.img # gzip -9 &lt; initrd &gt; initrd-2.6.30.10.new.img # lsinitrd-2.6.30.10.new.img initrd newinitrd 好了，initrd-2.6.30.10.new.img就是重新打包的 initrd了，然后把initrd-2.6.30.10.new.img拷贝到/boot，更改grub.conf里边的initrd- 2.6.30.10.img为initrd-2.6.30.10.new.img就可以了重新启动，好了上述出现的问题消失了！！！ 还有细节小问题，安装模块时，先把原来的/lib/modules/ 下对应的内核文件夹东西清空或者备份到别处，否则新编译后的安装模块会和原来的混起来，个人原出过莫名奇妙的错误，貌似和这个有点关系。反正这样做是保险点。 注明：相关的解决问题出处标注了来源，对相关的网上资料感谢。]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大师的时代]]></title>
    <url>%2F2011%2F03%2F04%2F%E5%A4%A7%E5%B8%88%E7%9A%84%E6%97%B6%E4%BB%A3%2F</url>
    <content type="text"><![CDATA[科学网刘老师的一篇博客“走近“大师”、感受伟大”读后很有感触。冯友兰，陈寅恪，马相伯，叶企孙…..太多的经典，太多的惊叹。那个时代造就的是一批胸怀天下，出类拔萃的英雄，不需要所谓的奖来衡量，因为当时我们当时的自信，自立都是一个高峰，精华。而如今，当版面，新闻拿国外的标准衡量，拿奖说话，实在说明我们还差的很远，越是强调，就越是说明我们的不足，这就是最典型的心理学知识。时代还在继续，我们仍然需要奋勇前行。因为我们还有自己的梦想。 附上，刘老师这篇博文。http://blog.sciencenet.cn/home.php?mod=space&amp;uid=326763&amp;do=blog&amp;id=418516]]></content>
  </entry>
  <entry>
    <title><![CDATA[vsftpd其实配置没这么麻烦]]></title>
    <url>%2F2011%2F03%2F04%2Fvsftpd%E5%85%B6%E5%AE%9E%E9%85%8D%E7%BD%AE%E6%B2%A1%E8%BF%99%E4%B9%88%E9%BA%BB%E7%83%A6%2F</url>
    <content type="text"><![CDATA[今天打算在ubuntu server上装个ftp服务器软件，发现了vsftpd.然后按照http://wiki.ubuntu.com.cn/Vsftpd%E5%AE%9E%E4%BE%8B进行配置，发现使用设置的用户给/var/ftp/pub上传不行， 提示：200 PORT command successful. Consider using PASV.不能create file 也就是说没写的权限。 网友说是权限没设置对，不过已经弄成775了，搞不成要777，貌似有的测试不行，说归结到selinux相关的问题，好多给的方案是： setsebool -P ftpd_disable_trans 1 service vsftpd restart 发现这个根本不起作用。嗨，发现这个其实说的很简单，http://forum.ubuntu.com.cn/viewtopic.php?f=54&amp;t=115655&amp;start=0你设置成建立用户对应于home下的目录就行了，整/var下既麻烦，还要禁止selinux，实在不怎么好。 对了，如果你设置disable selinux，那怎么改回去，这个有点意思。终于找到一个给力的帖子：http://www.crypt.gen.nz/selinux/disable_selinux.html运行 fixfiles relabel 再 reboot。 搞了半天，没有大繁化简，。。。。。。]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从定位效应说起]]></title>
    <url>%2F2011%2F03%2F02%2F%E4%BB%8E%E5%AE%9A%E4%BD%8D%E6%95%88%E5%BA%94%E8%AF%B4%E8%B5%B7%2F</url>
    <content type="text"><![CDATA[定位效应来自于人们受先入为主信息的干扰，进而受其误导，作出非理性的判断。 举个例子，这个月刚发工资，你想买件外套，走进一家商店（这里能还价），店主像你兴致勃勃的推荐一款流行的样式，你看着觉得不错。 这时你问价钱，老板说500，你说“宰人呀”，打算扭头走，老板赶忙拉着你，可以低点。然后你会给个价钱，最后以300元成交。老板心里很得意，赚了100块。 这个例子中，在老板开价后，你的还价会受500一定的左右，所以你的还价（如果你不是很在行）以500为基准点，往下调整的幅度不会太大。这个就是“定位效应”。 还有很多例子，比如人们愿意听好话，这种偏好性，也是定位效应的影响，为了作出理性的决策，应该多听取不同的意见，作出最终的决策。忠言逆耳利于行。]]></content>
  </entry>
  <entry>
    <title><![CDATA[国人文化靠谁拯救？]]></title>
    <url>%2F2011%2F02%2F28%2F%E5%9B%BD%E4%BA%BA%E6%96%87%E5%8C%96%E9%9D%A0%E8%B0%81%E6%8B%AF%E6%95%91%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[今天看见google的主页log标志才知道是李白诗人的诞辰，突然感慨自己的忘却了，想想小学时的“我歌月徘徊，我舞影凌乱”的月下浪漫，高中时刻的“安能摧眉折腰事权贵，使我不得开心颜”的那份直率和性情。想想大学时的“千金散尽还复来”的豁达，而如今的“天生我才必有用”的豪情壮志。 李白，这个伴随我成长过程的诗人，读其诗，效其行，念其才，竟忘其人，悲哉悲哉！ 幸亏google的log的提醒，我忽然想起我们国人中有几个记起他呢？其实一直很喜欢google的log设计，每逢重要的时刻他都会出现一个别样的设计，提醒人们这是一个什么的节日。而看其国内网多少，有多少记得中国的这些好的文化呢？新的尚未建立，到时旧的抛得十分干脆。前些年还是韩国人的做法让国人记得自己文化的重要性，我们到底是怎么了？国人的文化还要靠外人的普及，真是莫大悲哀了。。。。。]]></content>
  </entry>
  <entry>
    <title><![CDATA[有时我们过于“吝啬”]]></title>
    <url>%2F2011%2F02%2F20%2F%E6%9C%89%E6%97%B6%E6%88%91%E4%BB%AC%E8%BF%87%E4%BA%8E%E2%80%9C%E5%90%9D%E5%95%AC%E2%80%9D%2F</url>
    <content type="text"><![CDATA[每当自己如何借口太忙而把健身卡放置一边的时候，每当计划好跑步而赖在座位上一晚上时，我们太过吝啬了，对健康过于吝啬，觉得投资的回收效果不怎么明显，觉的没有立竿见影的效应。当人们年轻的时候不注重对身体的投资，这个潜移默化的蝴蝶效应会在中年后越发突出，譬如对长期工作的投入，没有循序渐进的坚持必然最后会面目全非。年轻时想的更多的是奋斗没有错，但是需要的健康的人生观，身体的投资也是纳入奋斗的范围。一旦陷入工作狂的境界，实际离人生的成功也越来越远。工作，身体，二者需兼得。]]></content>
  </entry>
  <entry>
    <title><![CDATA[因为非2才知道她-扎西拉姆·多多]]></title>
    <url>%2F2011%2F02%2F16%2F%E5%9B%A0%E4%B8%BA%E9%9D%9E2%E6%89%8D%E7%9F%A5%E9%81%93%E5%A5%B9-%E6%89%8E%E8%A5%BF%E6%8B%89%E5%A7%86%C2%B7%E5%A4%9A%E5%A4%9A%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920班扎古鲁白玛的沉默你见，或者不见我 我就在那里 不悲不喜 你念，或者不念我 情就在那里 不来不去 你爱，或者不爱我 爱就在那里 不增不减 你跟，或者不跟我 我的手就在你手里 不舍不弃 来我的怀里 或者 让我住进你的心里 默然 相爱 寂静 欢喜 当李香山的女儿在父亲的“提前追悼会”上念着这首诗时，那种淡淡的凄美让人的心灵引发极大的震撼。每个字似乎都顿挫淡然，对爱情，对人生，叩响而至，我竟有些潸然了。一份默然，一份寂静，也许就是追求爱情的最高境界吧。]]></content>
  </entry>
  <entry>
    <title><![CDATA[__define_initcall 作用]]></title>
    <url>%2F2010%2F12%2F29%2Fdefine-initcall%E4%BD%9C%E7%94%A8%2F</url>
    <content type="text"><![CDATA[很好的一篇文章，所以转过来了，感谢前人的探索。http://bigfirebird.iteye.com/blog/824818 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125前言 宏定义__define_initcall(level,fn)对于内核的初始化很重要，他指示 编译器在编译的时候，将一系列初始化函数的起始地址值按照一定的顺序 放在一个section中。在内核初始化阶段，do_initcalls() 将按顺序从该 section中以函数指针的形式取出这些函数的起始地址，来依次完成相应 的初始化。由于内核某些部分的初始化需要依赖于其他某些部分的初始化 的完成，因此这个顺序排列常常很重要。 下面将从__define_initcall(level,fn) 宏定义的代码分析入手，依次 分析名称为initcall.init的section的结构，最后分析内核初始化函数 do_initcalls()是如何利用宏定义__define_initcall(level,fn)及其相 关的衍生的7个宏宏定义，来实现内核某些部分的顺序初始化的。 1、分析 __define_initcall(level,fn) 宏定义 1) 这个宏的定义位于inlclude\linux\init.h中： #define __define_initcall(level,fn) \ static initcall_t __initcall_##fn \ __attribute__((__section__(".initcall" level ".init"))) \ = fn 其中 initcall_t 是个函数指针类型： typedef int (*initcall_t)(void); 而属性 __attribute__((__section__())) 则表示把对象放在一个这个 由括号中的名称所指代的section中。 所以这个宏定义的的含义是：1) 声明一个名称为__initcall_##fn的函数 指针(其中##表示替换连接，)；2) 将这个函数指针初始化为fn；3) 编译 的时候需要把这个函数指针变量放置到名称为 ".initcall" level ".init" 的section中(比如level="1"，代表这个section的名称是 ".initcall1.init")。 2) 举例：__define_initcall(6, pci_init) 上述宏调用的含义是：1) 声明一个函数指针__initcall_pic_init = pci_init； 且 2) 这个指针变量__initcall_pic_init 需要放置到名称为 .initcall6.init 的section中( 其实质就是将 这个函数pic_init的首地址放置到了这个 section中)。 3) 这个宏一般并不直接使用，而是被定义成下述其他更简单的7个衍生宏 这些衍生宏宏的定义也位于 inlclude\linux\Init.h 中: #define core_initcall(fn) __define_initcall("1",fn) #define postcore_initcall(fn) __define_initcall("2",fn) #define arch_initcall(fn) __define_initcall("3",fn) #define subsys_initcall(fn) __define_initcall("4",fn) #define fs_initcall(fn) __define_initcall("5",fn) #define device_initcall(fn) __define_initcall("6",fn) #define late_initcall(fn) __define_initcall("7",fn) 因此通过宏 core_initcall() 来声明的函数指针，将放置到名称为 .initcall1.init的section中，而通过宏 postcore_initcall() 来 声明的函数指针，将放置到名称为.initcall2.init的section中， 依次类推。 4) 举例：device_initcall(pci_init) 解释同上 1－2)。 2、和初始化调用有关section--initcall.init被分成了7个子section 1) 他们依次是.initcall1.init、.initcall2.init、...、.initcall7.init 2) 按照先后顺序依次排列 3) 他们的定义在文档vmlinux.lds.S中 例如 对于i386+，在i386\kernel\vmlinux.lds.S中有： __initcall_start = .; .initcall.init : &#123; *(.initcall1.init) *(.initcall2.init) *(.initcall3.init) *(.initcall4.init) *(.initcall5.init) *(.initcall6.init) *(.initcall7.init) &#125; __initcall_end = .; 而在makefile 中有 LDFLAGS_vmlinux += -T arch/$(ARCH)/kernel/vmlinux.lds.s 4) 在这7个section总的开始位置被标识为__initcall_start， 而在结尾被标识为__initcall_end。 3、 内核初始化函数do_basic_setup(): do_initcalls() 将从.initcall.init 中，也就是这7个section中依次取出任何的函数指针，并调用这些 函数指针所指向的函数，来完成内核的一些相关的初始化。 这个函数的定义位于init\main.c中： extern initcall_t __initcall_start, __initcall_end; static void __init do_initcalls(void) &#123; initcall_t *call; .... for (call = &amp;__initcall_start; call *********************************************************************** 假如您希望某个初始化函数在内核初始化阶段就被调用，那么您 就应该使用宏__define_initcall(level,fn) 或 其7个衍生宏来 把这个初始化函数fn的起始地址按照初始化的顺序放置到相关的 section 中。 内核初始化时的do_initcalls()将从这个section 中按顺序找到这些函数来执行。 假如您希望某个初始化函数在内核初始化阶段就被调用，那么您 就应该使用宏__define_initcall(level,fn) 或 其7个衍生宏来 把这个初始化函数fn的起始地址按照初始化的顺序放置到相关的 section 中。 内核初始化时的do_initcalls()将从这个section 中按顺序找到这些函数来执行。 ******************************************************************* http://forum.oss.org.cn/viewtopic.php?p=8899&amp;sid=1f5aee1b543bfca24793e4508dd115d0 今天在做一个驱动的时候要用到另一个驱动（I2C）提供的API，在内核初始化时碰到了一个依赖问题。 我的驱动在I2C初始化之前就运行起来了，而这时I2C提供的API还处于不可用状态。查了很多资料，网上有人说任何使用module_init这个宏的驱动程式的起动顺序都是不确定的（我没有查到权威的资料）。 任何的__init函数在区段.initcall.init中还保存了一份函数指针，在初始化时内核会通过这些函数指针调用这些__init函数指针，并在整个初始化完成后，释放整个init区段（包括.init.text，.initcall.init等）。 注意，这些函数在内核初始化过程中的调用顺序只和这里的函数指针的顺序有关，和1）中所述的这些函数本身在.init.text区段中的顺序无关。在 2.4内核中，这些函数指针的顺序也是和链接的顺序有关的，是不确定的。在2.6内核中，initcall.init区段又分成7个子区段，分别是 .initcall1.init .initcall2.init .initcall3.init .initcall4.init .initcall5.init .initcall6.init .initcall7.init 当需要把函数fn放到.initcall1.init区段时，只要声明 core_initcall(fn); 即可。 其他的各个区段的定义方法分别是： core_initcall(fn) ---&gt;.initcall1.init postcore_initcall(fn) ---&gt;.initcall2.init arch_initcall(fn) ---&gt;.initcall3.init subsys_initcall(fn) ---&gt;.initcall4.init fs_initcall(fn) ---&gt;.initcall5.init device_initcall(fn) ---&gt;.initcall6.init late_initcall(fn) ---&gt;.initcall7.init 而和2.4兼容的initcall(fn)则等价于device_initcall(fn)。各个子区段之间的顺序是确定的，即先调用. initcall1.init中的函数指针，再调用.initcall2.init中的函数指针，等等。而在每个子区段中的函数指针的顺序是和链接顺序相关的，是不确定的。 在内核中，不同的init函数被放在不同的子区段中，因此也就决定了他们的调用顺序。这样也就解决了一些init函数之间必须确保一定的调用顺序的问题。按照include/linux/init.h文档所写的，我在驱动里偿试了这样两种方式： __define_initcall("7", fn); late_initcall(fn); 都能够把我的驱动调整到最后调用。实际上上面两个是一回事： #define late_initcall(fn) __define_initcall("7", fn)]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何让你的linux读出你计算机器件温度？]]></title>
    <url>%2F2010%2F12%2F26%2F%E5%A6%82%E4%BD%95%E8%AE%A9%E4%BD%A0%E7%9A%84linux%E8%AF%BB%E5%87%BA%E4%BD%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%99%A8%E4%BB%B6%E6%B8%A9%E5%BA%A6%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[前段时间本想根据温度来调节功耗的，所以就想看看linux下给出的接口，能否方便的读取，进而调节。刚开始在ubuntu下运行 1#sensors 提示没有安装相关的驱动。这时要运行sensors-detect 1#sensors-detect 其中只要回答yes即可，最后的出现 12345678910Do you want to overwrite /etc/sysconfig/lm_sensors? (YES/no): noTo load everything that is needed, add this to one of the systeminitialization scripts (e.g. /etc/rc.d/rc.local):#----cut here----# Chip driversmodprobe coretempmodprobe it87/usr/local/bin/sensors -s#----cut here---- 如果马上想用不想重启，那么就直接使用modprobe安装相关的驱动。 即 12#modprobe coretemp#modprobe it87 最后来验证， 12345678910111213141516171819202122232425262728#sensorscoretemp-isa-0000Adapter: ISA adapterCore 0: +30.0°C (high = +76.0°C, crit = +100.0°C)coretemp-isa-0001Adapter: ISA adapterCore 1: +29.0°C (high = +76.0°C, crit = +100.0°C)it8718-isa-0a10Adapter: ISA adapterin0: +1.07 V (min = +0.03 V, max = +0.02 V) ALARMin1: +2.16 V (min = +0.00 V, max = +4.08 V)in2: +2.16 V (min = +0.00 V, max = +4.08 V)in3: +3.02 V (min = +0.00 V, max = +4.08 V)in4: +2.16 V (min = +0.00 V, max = +4.08 V)in5: +0.06 V (min = +0.00 V, max = +4.08 V)in6: +0.10 V (min = +0.00 V, max = +4.08 V)in7: +2.96 V (min = +0.00 V, max = +4.08 V)Vbat: +3.30 Vfan1: 1391 RPM (min = 10 RPM)fan2: 1220 RPM (min = 0 RPM)fan3: 0 RPM (min = 0 RPM)temp1: +19.0°C (low = +127.0°C, high = +127.0°C) sensor = thermal diodetemp2: +28.0°C (low = +127.0°C, high = +127.0°C) sensor = thermistortemp3: -70.0°C (low = +127.0°C, high = +127.0°C) sensor = thermal diodecpu0_vid: +0.000 V 成功，呵呵。 当然，可以参考下面的文章，也有相关的介绍： 123http://forums.linuxmint.com/viewtopic.php?f=42&amp;t=31978&amp;start=0#p184022http://www.thinkwiki.org/wiki/Thermal_sensorshttp://www.lm-sensors.nu/]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编译缺少头文件 mmzone.h ....bounds.h的问题]]></title>
    <url>%2F2010%2F12%2F24%2F%E7%BC%96%E8%AF%91%E7%BC%BA%E5%B0%91%E5%A4%B4%E6%96%87%E4%BB%B6%20mmzone.h%20....bounds.h%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[出现这个问题，大都是在内核源码目录外编译产生的，google了一下，发现一篇文章，原来这些问题是在kbuild时产生的，内核本身没有，这够晕的。。。 见下面解决方法： 来源：http://blog.csdn.net/wby0322/archive/2010/05/26/5624565.aspx 出现的问题：编译的时候提示缺少头文件 mmzone.h ….bounds.h…等 include/linux/mmzone.h:18:26: error: linux/bounds.h: No such file or directoryinclude/linux/mmzone.h:197:5: warning: “MAX_NR_ZONES” is not defined 原因：bounds.h是在编译内核时生成的，类似于编译产生的.o文件，如果你运行 “make clean” or “make distclean”，这个文件就会被清除掉（详情查看内核Makefile）。因此，如果再利用此内核源码编译内核模块，如果有涉及bounds.h，就会出现找不到该文件的错误。 解决：独立内核目录之外编译模块时，要确保makefile文件中所定义的内核源代码树已经make过一遍，且没有make clean。这样就不会清除生成的bound.h头文件，这个文件是生成模块必须的。 或者”make prepare” 这样就会重新生成bounds.h，搞定了！]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[强大的cscope+vim+ctags]]></title>
    <url>%2F2010%2F12%2F16%2F%E5%BC%BA%E5%A4%A7%E7%9A%84cscope%2Bvim%2Bctags%2F</url>
    <content type="text"><![CDATA[强大的cscope+vim+ctags今天终于打算弄弄linux下的cscope这套工具了，以前总是没用到地方看到了http://blog.csdn.net/jsufcz/archive/2009/03/13/3988883.aspx 写的一篇文章，进行了相关的验证，发现阅读代码很是方便。 实验环境：Ubuntu-9.10 首先确认vim支持cscope， 方法： vim –version | grep cscope 如果显示 +cscope 就是支持了；再安装cscope。如果不支持，似乎要重新编译vim和下载cscope（这个没有验证，ubuntu默认的支持）。 其次，安装ctags3. 然后就是具体操作了，体验强大之处吧，比如你一个目录下存放的一个软件的源代码，那么进入目录中，进行如下的操作： 操作: 1231， ctags -R 这一步是为了递归生成标签文件操作2， cscope-indexer -r 这一步是生成索引信息文件操作3， cscope 使用cscope查看源代码了。 还是很方便的。 附上一点常用命令：（转自：http://blog.csdn.net/jsufcz/archive/2009/03/13/3988883.aspx）在vim中ctags的简单使用 1) 跳转到指定的函数进入vim后，用 “:tag func_name“ 跳到函数func_name处。使用tag命令时，可以使用TAB键进行匹配查找，继续按TAB键向下切换。某个函数有多个定义时 :tag跳到第一个定义处，优先跳转到当前文件:tnext跳到第一个:tfirst跳到前count个:[count]tprevious跳到后count个:[count]tnext跳到最后一个:tlast你也可以在所有tagname中选择：:tselect tagname 如果想跳到包含block的标识符:“tag /block” 然后用TAB键来选择。这里’/‘就是告诉vim‘block’是一个语句块标签。2)用“CTRL + ]“快捷键，跳转到光标所在函数标识符的定义处。3)使用“CTRL + T”退回上层。如果想在以write_开头的标识符中选择一下， :tselect /^write_ 这里，’^’表示开头，同理，’$’表示末尾。多个同名的标识符 感谢前人开发的工具和网友在配置上做的探索。]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[看看green500，谈谈个人看法]]></title>
    <url>%2F2010%2F08%2F09%2F%E7%9C%8B%E7%9C%8Bgreen500%EF%BC%8C%E8%B0%88%E8%B0%88%E4%B8%AA%E4%BA%BA%E7%9C%8B%E6%B3%95%2F</url>
    <content type="text"><![CDATA[今年上半年公布的green500里，曙光的 Nebulae表现不错，排名第4. 前面几名还是IBM稳坐，不过看起来好像是同一解决方案，应该是同样的技术。曙光 Nebulae在今年的top500里，排名第2，今年在green里拿到第4已经不错了，何况 top500 里的第 1 名Jaguar都在green里56名，第3名Roadrunner，在green里第7。 看看数据： Green500 MFLOPS/W Site* Total Power (kW)Rank 4 492.64 National Supercomputing Centre in 2580（Nebulae）Shenzhen (NSCS) 7 444.25 DOE/NNSA/LANL 2345.5（Roadrunner) 11 379.24 National SuperComputer Center in 1484.8（Tianhe） Tianjin/NUDT 56 253.07 Oak Ridge National Laboratory 6950.6（Jaguar） NUDT的天河总机1484.8kW， Nebulae的总机功耗2580kW，RoadRunner 2345.5kW。如果按照绝对值增加的话（以天河为基准）：Roadrunner在增加860.7kW的情况下，能效（MFLOPS/W）增加了65.01。Nebulae增加1092.5kW， 能效增加了113.4。似乎要比Roadrunner更好一些，当然高性能超级计算机的一个很值得研讨的课题就是可扩展性，性能的线性增加，并不意味着功耗的增加是线性的，可能是指数增加的。 我们能效公式是: 性能（MFLOPS）/ 功耗*1000(W) =能效: 1234 Nebulae Tianhe Roadrunner Jaguar Rmax(TFPOS) 1271.00 563.10 1042.00 1759.00 Power(kW) 2580 1484.8 2345.50 6950.6 这个数据很有意思，前三者基本还表现为功耗随性能线性增加，可Jaguar实在有些差强人意，功耗耗增加的过快。不同的架构也许在小机器上差别很小，但是根据蝴蝶效应，在超级计算机上就可能颇为悬殊了。但还不至于这么夸张，都有互相借鉴对方的长处的，我忽然想到CISC和RISC的历史了，呵呵。再说了，大家不是在同一个时间下出来的机器，比较起来自然有些不太公平，毕竟超级计算机领域的变化可谓日新月异，发展太快了。新机器在各指标上都会要好些。虽然我们的超级计算机取得了不错的成果，但是还要看到很多的不足之处，应该发展的全面一些，既有性能卓越，能效突出的超大型机器（但是功耗还是比较大），又有性能不错，能效卓越的小一点的机器（功耗小于前者的1/4），那么就代表在supercomputing科技里有足够的底气，当然至于能不能在近年里出现国产CPU大批量应用在超级机器中还不好说，可这应该是我们的目标，核心部件，核心工艺不在我方，谈何真正的科技领先呢，岂不要处处受制于人，为了国家的安全和未来发展，国产CPU及集成电路的一系列的技术都是要长期着手要重点抓的，技术的发展当然少不了基础科学的支持，所以也要大力支持基础科学的研究，这方面还是有很多要改进的地方的。 里面都仅仅是个人之见，有的扯得比较远，可能不够严谨，值得商榷，呵呵。]]></content>
  </entry>
  <entry>
    <title><![CDATA[从“龙芯”的尴尬看我国科研布局的严重缺失]]></title>
    <url>%2F2010%2F07%2F22%2F%E4%BB%8E%E2%80%9C%E9%BE%99%E8%8A%AF%E2%80%9D%E7%9A%84%E5%B0%B4%E5%B0%AC%E7%9C%8B%E6%88%91%E5%9B%BD%E7%A7%91%E7%A0%94%E5%B8%83%E5%B1%80%E7%9A%84%E4%B8%A5%E9%87%8D%E7%BC%BA%E5%A4%B1%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132从“龙芯”的尴尬看我国科研布局的严重缺失 邹谋炎 “龙芯”在电视报道后，声名远扬。它是中科院计算所的研究成果，确实代表了国内在CPU芯片设计方面的最高水平。然而，即使是在国内应用市场上，它的处境却十分尴尬。人们需要了解的是：从国家信息技术的角度，芯片设计只是芯片技术这个大题目中的一项。我们缺的技术还太多：(1) 芯片制造技术及相关的材料、超净、工艺控制等；(2) 芯片制造工艺设备研发，特别是新工艺支撑技术、系统和设备；(3) 设计和验证工具的自主开发；(4) 基本单元的物理层设计和新基本单元的自行开发能力；(5) 专用电路单元或片上系统（SOC）设计、验证和工业化生产技术，例如超高速和高精度数字芯片；微波、大功率模拟芯片；以及具有抗高热、抗辐射要求的设计技术。其中（2）和（5）是核心中的核心，是最“卡脖子”的技术。大致从80年代后期起，国际上芯片设计就已属于可开放技术，有计算机科学或数字系统经验的工作者可以进入工作。而要开展所列出的5项工作，主要是(1)(2)(4)(5),则需要宽得多的技术基础积累，涉及工艺的则难于介入。国内数字多媒体芯片发展商“中星微电子”拥有与龙芯不同的系统级和电路级设计技术。而从芯片技术这一角度来看，则属于类似的技术等级。由于设计结果要靠“芯片代工厂”流片，国内芯片设计企业受限制于可以得到的工艺条件。严峻的实事是，龙芯是通用器件，可得到的工艺水平上晚国外一步，就丧失了产品的主流市场。现在，人们将国与国之间的经济和国力竞争归结为创新性竞争，并且浓缩为芯片制造技术和系统的竞争或工艺竞争。而这才是芯片技术的核心。高端工艺包括相关的基础理论和基础技术（方法、技术、设备、和条件）两个不可分割的部分。受工艺影响的绝不只是芯片技术，而是国家科技和产业的各个领域中最关键和最核心的部分。它直接限制或提升国家的科技创新能力和各领域高新技术产品的自主开发能力。欧美的大学、研究所有开展基础技术研究的长远历史，而在我国却极稀缺。遗憾的是，这种影响全局的问题始终没有得到我国科技高层和政府高层的强烈关注。可以说，国家科技发展规划纲要的制定过程决定了，它的若干内容只反映目前正在实施的研究发展项目的延续性要求，受制于利益而缺乏真正意义上的科学性和前瞻性。欧美日各国政府长期以来一直极为看重以芯片技术为中心带动工艺的全面进步。从80年代起，美国政府支持“半导体加工工艺财团”（SEMATECH），日本政府提出建立“Technology Nation”的目标，以及欧盟通过尤里卡发展计划的努力，都卓有成效，并在以后从不间断地持续。我国缺失太多，要弥补起来是一件需要全面规划的问题。靠几个“分钱工程”的“举国体制”一定不会有好结果。我们需要一个教育、培养、引进、发展过程。花点钱，买几十套国外工业淘汰下来的成套工艺线，放到各地学校中，让教授们、教师们、学生们能够从实践学起，多少认识一点工艺是怎么回事，自然会生长出一批有志者。让脱离实际的教授、专家们懂点工艺，让大学生和研究人员知道潜心研究工艺有前途、不受穷，这需要国家用“举国体制”来长期支撑。如果能这样做，中国科技和产业被“卡脖子”的日子，应该在十年以内结束。此文亦可催促我们还有还多事情要做，前进不止。]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用xcutsel共享 vncviewer与Xserver的剪切板]]></title>
    <url>%2F2010%2F07%2F20%2F%E4%BD%BF%E7%94%A8xcutsel%E5%85%B1%E4%BA%AB%20vncviewer%E4%B8%8EXserver%E7%9A%84%E5%89%AA%E5%88%87%E6%9D%BF%2F</url>
    <content type="text"><![CDATA[最近使用vnc很 是频繁，我的工作环境是控制端为archlinux被控端为winxp，它们之间剪切板的共享问题一直没有解决，以前少的字符总是自己打上去的，大的段落就用ftp把文件传过去后复制粘贴，由于今天要复制的内容十分的多，终于促使我下决心解决这个问题了，在网上搜了半天终于发现原来解决方法是这么的简单，都怪以前太懒，浪费了大把大把的时间呐。解决问题的关键就是这个xcutsel程序，这个程序相当的简单，只有三个丑陋的按钮，分别是：1，quit2，copy primary to 03，copy 0 to primary解释下使用法方，在windows中复制文本内容后，点击3:copy 0 toprimary，然后在linux下点击鼠标中键或者shift+insert，即可实现clipboard transfer。反过来，在linux下中复制文本内容后，点击2:copy primary to 0，然后就可以复制到windows中了。So Easy~~ 注：上面的内容是引用，我的系统是ubuntu 10.04其实关于从windows xp向ubuntu直接可以粘贴，不需要xcutsel的帮忙。只是从linux到xp要借助xcutsel的帮助，有个小问题就是xp到linux有时会出现内容里的引号丢失的现象，不太明白。以后再说吧，先研究程序吧。]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apue.2e 源码编译遇到的问题解决方法]]></title>
    <url>%2F2010%2F07%2F20%2Fapue.2e%20%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[apue.2e 源码编译遇到的问题 修改Make.defines.linux的WKDIR 然后makeerror:提示threadctl中的getenv1.c的ARG_MAX没有定义添加#define ARG_MAX 4096error:getenv3.c出现同样的问题同样如上添加最后成功 gcc 4.4.3OS：Ubuntu 10.04 也是从网上的一些资料学习的，在此感谢那些人们。]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[参加2010开源高峰论坛有感]]></title>
    <url>%2F2010%2F06%2F30%2F%E5%8F%82%E5%8A%A02010%E5%BC%80%E6%BA%90%E9%AB%98%E5%B3%B0%E8%AE%BA%E5%9D%9B%E6%9C%89%E6%84%9F%2F</url>
    <content type="text"><![CDATA[第一次参加高峰论坛，也看到好多开源界中的专家，很高兴， 不过此次的论坛安排的演讲比较密集，所以基本上没有提问交流时间，apache基金会创始人，linux基金会负责人，还有intel，ibm，nokia，红旗，中标等若干企业的高级技术总监和经理参加，围绕了开源给中国软件带来的机遇和挑战，开源在中国的发展还是任重道远，需要更多的在核心创新上做贡献，简单的外围修修补补还是很难在激烈的竞争中取得优势，当然这还是需要政策的大力支持，不管企业界，高校也有义不容辞的责任。开源更多的应该是强调贡献，创新。 后来还围绕开源的标准化给了相关的介绍。 当然会议少不了最近比较热的概念，云计算下的开源发展，iBM的智慧地球等。第二天的圆桌会议不对外（非正式邀请嘉宾）开放，所以没听。具体就不知道了，其实说下来收获也不是很大，报告的比较宽泛，倒是眼界开阔了些，这就可以了。 脚踏实地，每天进步一点，努力。]]></content>
      <tags>
        <tag>IT业界</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[新一期的 top500之我见]]></title>
    <url>%2F2010%2F06%2F03%2F%E6%96%B0%E4%B8%80%E6%9C%9F%E7%9A%84%20top500%E4%B9%8B%E6%88%91%E8%A7%81%2F</url>
    <content type="text"><![CDATA[6月份又出了新一期的top500，比较有看点的地方是又一个中国的星云（Nebulae）系统杀入前10（2009年12月份的是国防科大研制的天河一号）。此次的星云Linpack实测达到1.271PFlop/s,理论峰值达2.98PFlop/s（目前最快）。根据目前的Linpack实测数据表明星云的性能还有很大的提升空间，因为No.1的Jaguar系统的理论峰值（2.33PFlop/s）虽然没有星云高，但是Linpack实测却达到1.75PFlop/s，至少说明我们这个系统还不是很优化，天河一号的Rmax也是应该有较大的优化余地。 12345System Cores Rmax(GFlops) Rpeak(GFlops) Nmax Nhalf 1.Jaguar 224162 1759000 2331000 5474272 0 2.Nebulae 120640 1271000 2984300 2359296 0 3.Roadrunner 122400 1042000 1375776 2249343 0 7.Tianhe-1 71680 563100 1206190 2240000 0 注：Nmax: the maximal achieved performance Rmax for the problem size Nmax。 之所以列出Roadrunner，是因为它采用了PowerXCell 8i 处理器，这和我国的系统采用GPU加速部件有相似之处。虽然星云系统达到No.2，但离真正的超级计算机自主化有些距离，看一下： Dawning TC3600 Blade, Intel X5650, NVidia Tesla C2050 GPU的配置，没见到国产高速CPU的影子。 前端时间是报道过中科大研制成基于龙芯3A万亿次计算机，这是高性能计算向个人化方向的进展，但是具体大规模应用到我们实际的超级计算机中不知道还要多久。 值得期待的是Green500也马上要发布了，最近的一期排名可以看到Tianhe-1表现不错： 123Green500 Rank MFLOPS/W Site* Total Power (kW) TOP500 Rank* 6 444.25 DOE/NNSA/LANL 2345.5 2 8 379.24 Tianjin/NUDT TH-1 Cluster 1484.8 5 目前的高性能计算领域可谓变化迅速，每一期的top500都会有新的看点，各国都投入了大量了人力，物力，财力到超算领域。是我们也会看到超算领域大多用到研究领域，如何切实有效的应用实际生产，生活，在编程简易，系统可靠性，能效性都是值得研究的地方。 数据来源：http://www.top500.org/lists/2010/06http://www.green500.org/lists/2009/11/top/list.php]]></content>
  </entry>
  <entry>
    <title><![CDATA[聆听William C.Y.Lee的报告]]></title>
    <url>%2F2010%2F05%2F24%2F%E8%81%86%E5%90%ACWilliam%20C.Y.Lee%E7%9A%84%E6%8A%A5%E5%91%8A%2F</url>
    <content type="text"><![CDATA[李教授今天着一身深灰的西装，很有精神（当然了，老人家本来就很精神）。围绕移动无线通信展开了相关的探讨，主要是总结了提出一些自己的看法和经验，对未来技术的展望。从60年代到加入贝尔实验室开始研究移动无线通信到现在，可谓经历了风风雨雨，自然对此有很深的感想。 移动无线通讯确实给我们带来了很便利的生活，让生活更加美好，更加colorful。但是我们不能忽视随着人工智能，纳米技术，云计算等技术的演进，是否会出现第二个singularity（第一个singularity是人类从其他动物中脱离，演化成智能的拥有creativity动物），人来是否会被Intelligentmachine所控制，奴役，好像是个未知的问题。 不过目前可以放心一点：digital式的机器，使用是binary logic，而人类的复杂性的Fuzzy logic，analog式的思维，目前以及将来很长的一段时间机器水平是远远达不到。人类的复杂感情是目前机器难以模拟的，至于长远的未来，也许几千年之后，人类会不会造出来一中hybrid computer，有analog和digital的复杂rule，那么可能会出现第二个singularity，至于人类那时是什么样子，我实在想不来，但可以确定那时人类面临的问题会相当棘手。 谈到移动无线通信，谈到系统，当然少不了标准。看目前的3G标准有四大阵营CDMA2000，WCDMA，TD-SCDMA，WiMAX。欧洲的，美国的，中国的。中国提出来很有必要，尤其是下一代4G标准，LTE，WIMAX两大家子在争得不亦乐乎，而我们目前的TD-SCDMA也要向4G推进，当然TD-SCDMA，应该算是TD-LTE，是LTE的一个分支吧，我不清楚其中的专利细节。但相信一点，未来标准中的争夺，无非是专利的重点，各大帮派的互相争夺最后都是归结专利的利益核心点。一旦专利写进标准，那么就增加了自己的话语权和收益权，我们国家为什么要提出自己的标准，因为标准中没有专利权，未来就受制于人，国家的安全核心（通信）就有很大的威胁。标准中不恰当的妥协会慢慢的丧失自己话语权，丧失的是整个国家的核心利益。现在国家在资助研究试点，作为每个技术人员，科学家都应该尽到自己作为一个国人的责任，关心自己的国家，好好搞，决不能短视之见，毁掉国家的未来，那可是千古罪人呀！ 听报告所感，仅仅个人一些看法，欢迎各位指教。]]></content>
  </entry>
  <entry>
    <title><![CDATA[李凯教授的成功公式-包老师写的不错]]></title>
    <url>%2F2010%2F05%2F16%2F%E6%9D%8E%E5%87%AF%E6%95%99%E6%8E%88%E7%9A%84%E6%88%90%E5%8A%9F%E5%85%AC%E5%BC%8F-%E5%8C%85%E8%80%81%E5%B8%88%E5%86%99%E7%9A%84%E4%B8%8D%E9%94%99%2F</url>
    <content type="text"><![CDATA[李凯教授是普林斯顿大学计算机系教授，研究方向包括操作系统、存储系统、体系结构和分布式系统等。 李凯教授对学术界和工业界都有深远影响。他于上世纪80年代提出分布式共享内存（DSM）思想，开创了新的研究领域。他在普林斯顿领导了一系列令人瞩目的项目，包括SHRIMP、Scalable Display Wall等。鉴于其对计算机系统结构作出的根本性贡献，李凯教授于1998年被评为ACM Fellow。随后李凯教授于2001年共同创办了Data Domain公司，研制出世界上第一款商用重复数据删除(Data Deduplication)产品。如今重复数据删除技术已成为存储领域的新分支，Data Domain公司也成为该领域的领头羊，并于2009年被EMC以21亿美元收购。 李凯教授培养了众多杰出人才，如Yuanyuan Zhou、Pei Cao等。李凯教授于1977年获吉林大学学士学位，1981年获中国科大（中科院）硕士学位，1985年获美国耶鲁大学博士学位。 123456789101112131415161718192021222324 5月6日下午，容纳80人的报告厅竟然慕名来了超过120位所里的年轻人。 虽然之前和李凯老师接触比较多，也听他讲过一些经历，但第一次听他用幻灯片系统地介绍他对科研与创业的体会，依然很有收获。 Success = Talent + Opportunity + Effort 一个看起来很大道理的公式，但是当李凯老师分别用从自己科研与创业的经历来诠释时，这个公式的确变得生动而富有启发性。 对于科研而言，李老师认为对于能进入计算所的人来说，已经具备了科研基本的Talent了，但还需要不断地提高。每个人的Talent也是各有所长的，有的擅长发现问题，有的擅长解决问题，有的擅长工程实现。大多数人很难做到同时具有多个Talent，但我们至少要保证自己在某一项上是最优秀的。而科研中的Opportunity有很多种形式，可能是自己的导师，可能是暑假实习机会，也可能是与前辈交流等，好好把握。李老师引用了《Outlier》一书中的10000小时来解释Effort，也就是说要做好一件事至少要持续投入10000小时，比如球员、钢琴家、画家、科学家等，如果每周投入30小时，那需要6年。李老师承认自己不是最聪明，但很勤奋，在Princeton做助理教授的好几年里也是坚持写程序，他笑称自己写程序的时间肯定超过10000小时。这样，Talent + Opportunity + Effort 就可能获得Success了。 对于创业而言，Talent、Opportunity和Effort则又赋予了不同的含义。李老师认为创业所需要的Talent其实比科研要求更多，其中有一条更是让他很有体会——知道自己的劣势。他认为国内的很多不善于管理的创业者往往不愿把自己的企业交给专业的管理人员打理，这会大大阻碍企业成长的进程。他认为Data Domain成功的主要原因就是在于他和几个共同创始人及时地寻找到公司的CEO。创业的Opportunity也是比科研多得多。此外创业所需要付出极大的Effort。在硅谷，startup就等于“hard work”。但是，即使这些因素都具备，其实创业的Success也不是那么就能够达到的，还需要一些运气，毕竟在硅谷创业成功的企业也只有0.1%左右。（在之前的博文“[2009-11-17] 几则关于科研的小故事（1）”中简单介绍了李凯老师创业的故事。） 和李老师交流过的人都能感觉到，他是一个思维敏捷、语言组织能力也很出色的人，其实是很善于宣传和表达。但这几年来和他的接触，我又感觉到他是一个非常低调的平凡人。这种低调不仅体现在他在学术圈与工业界的低调，甚至在延伸到生活中。他很少在很多场合抛头露面，也很少面对媒体发表各种评论；他的穿着非常的朴素，开着用了很多年的老本田，还亲自去中关村淘山寨手机。平凡的生活中透着不平凡的经历，这更能感染他人]]></content>
  </entry>
  <entry>
    <title><![CDATA[绿色打印机的一体化方案]]></title>
    <url>%2F2010%2F05%2F01%2F%E7%BB%BF%E8%89%B2%E6%89%93%E5%8D%B0%E6%9C%BA%E7%9A%84%E4%B8%80%E4%BD%93%E5%8C%96%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[文献[1]的一篇文章给出了联想打印机的绿色之路，很有意思。主要是介绍了打印机从生产，运输，利用和回收的的整体化绿色方案。生产上要保证材料的可降解，可回收运输上保证最少的距离和环节送到客户手中，这个涉及到物流的运筹调度优化利用上，首先要保证易用性，至少不能给客户造成时间上的浪费，客户不可能接受一个很复杂的操作方式（即使这种方式更加绿色节能），其次有人性化的绿色设计使得用户可以觉得绿色节能原来就这么简单易行。比如其中谈到的绿色设计和绿色应用：双面打印设计、瞬时热熔定影技术，包括耗材的长寿命感光鼓设计等。开发出省墨模式、一键全能、封闭式纸盒等产品功能。回收上，文中说到联想作为国内唯一具有打印机耗材商业回收资格的企业（不太了解），正在逐步建立健全打印机耗材的绿色回收制度。如在全国建立正品耗材回收网点，无偿回收废弃墨盒（这个无偿回收？？人家愿意把墨盒交出来，无偿对谁来说？不解） 总之，在如今的各大OEM厂商中，这个观念应该贯穿其中，但是一般好多企业不涉及到链条的全部，作为链条的一部分，如何指定比较有效的节能方案从而保证链条整体的绿色节能最优，好像不是单单的科学问题，还要法律的制度保证。节能绿色对于每个企业来说既是责任也是道德的衡量利剑。 参考资料：http://www.ccw.com.cn/weekly/tech/test/htm2010/20100420_856891.shtml]]></content>
  </entry>
  <entry>
    <title><![CDATA[绿色云计算充满挑战]]></title>
    <url>%2F2010%2F05%2F01%2F%E7%BB%BF%E8%89%B2%E4%BA%91%E8%AE%A1%E7%AE%97%E5%85%85%E6%BB%A1%E6%8C%91%E6%88%98%2F</url>
    <content type="text"><![CDATA[云计算时代的绿色计算吹起了号角，各大公司也在摩拳擦掌， 文献[1]里面介绍了比较有趣的绿色数据中心采用的技术。 毫无疑问，在当下的各大企业中，数据中心和个别服务应用的超级计算机的能耗问题越来越突出，一年下来上百万或千万的电费确实让人受不起。比较苦恼的是当下的电费还不是用在刀刃上，相当的一大部分用在了机器冷却和降温，中心的照明等方面，真正用于计算，存储等服务上的却还不到50%，能效比可以很好的衡量数据中心能源的利用率，采用performance/energy，比如flops/w。对于集群系统的PUE=total_data_center_power/IT_equipment_power,当然还有很多的衡量指标。 实际上数据中心在规划之初的时候需要一个可行的设计方案，保证既能很好适应将来业务的需求而动态扩展，另一方面有尽可能的降低成本，设备的利用率尽可能的高，这是个很有挑战性的问题。供电和制冷设备的规划，可以采用模块化的供电和制冷架构服务器电源的改进，冗余电源改为N+1的设计方式，适应负载变化的动态电源管理，动态制冷等技术。 总之，节能不是简单的单方面行动，需要考虑安全，性能，冗余的多方面因素，绿色计算任重道远，充满机遇和挑战。 参考资料：http://www.ccw.com.cn/weekly/tech/enterprisecomputing/htm2010/20100420_856868.shtml]]></content>
  </entry>
  <entry>
    <title><![CDATA[人生与事业：目标与过程的平衡（鲁先生的人生观）]]></title>
    <url>%2F2010%2F04%2F29%2F%E4%BA%BA%E7%94%9F%E4%B8%8E%E4%BA%8B%E4%B8%9A%EF%BC%9A%E7%9B%AE%E6%A0%87%E4%B8%8E%E8%BF%87%E7%A8%8B%E7%9A%84%E5%B9%B3%E8%A1%A1%EF%BC%88%E9%B2%81%E5%85%88%E7%94%9F%E7%9A%84%E4%BA%BA%E7%94%9F%E8%A7%82%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223 人生与事业：目标与过程的平衡. II 下面，我们来讨论第二个问题——过程。再次提到普林斯顿校长雪莉•蒂尔曼，她在讲怎么样 培养乐观精神实现目标时，讲了一句发人深省的话：“如果你已经明确的了解了你想要做什么，那么对你来说普林斯顿可能并不是一个合适的地方。”这句话让我感 慨良久。我在普林斯顿访问的时候，看到一群中国新生的家长，他们第一次来, 就问普林斯顿的领导，你们怎么做可以使我的孩子毕业后上哈佛医学院，上斯坦福法律学院，或者上麻省理工商学院，学校领导反反复复跟那些家长们说，孩子刚刚 进大学，你要给他们灌输的不是怎样出大学，而是怎么过好这四年，大学四年是人生很重要的经历，在四年里不光是要学习，还要去感受。上大学不仅是为了从大学 毕业，拿学位，也不仅仅是学知识长本领，上大学本身是一个过程，一种经历。一个人一生有多少个四年? 这四年是你人生的黄金时代，你要好好的体验这四年，而不是一进大学就想到毕业拿文凭的那天。有一个很典型且很让我震惊的事情，我在访问麻省理工大学时，那 里的老师告诉我，麻省理工所有的课程全部都被录像并放在网上，所有的有名教授的讲座都可以下载。既然世界上任何人都能免费看到麻省理工的课程，那么为什么 还要到麻省理工读书呢？到麻省理工读书是一个过程，跟在网上哪怕做所有老师布置的作业，听所有老师讲课都不一样。上大学不是一个简单学习课程的过程，你在 听老师讲课的时候，不仅仅是在学老师讲的知识，还在学老师的风格，老师的个性，老师的特点，老师的做人方式……这才是真正的学习。而且，在学校四年，绝大 数情况下你不是在上课而是跟同学朋友在一起，朋友会影响你的人生。你参加各种各样学校组织的活动，各种各样的社团活动，各种各样的志愿活动，所有这些都构 成了大学的性格和大学的文化，这些大学文化能够熏陶每一个人。所以, 麻省理工虽然把所有的课都放到了网上，但你光靠上网是不能变成一个真正的麻省理工学生。总之上大学就要去享受过程中的每一天，做好这个过程中的每一件事 情。 说到享受生命的过程，没有人比兰迪•鲍什（Randy Pausch）更有资格。鲍什是一名46岁的计算机教授，但是他的名气却不是因为自己的学术成就。鲍什因为得胰腺癌已经去世，在去世之前，他在卡耐基梅隆 大学做了一场演讲, 一年一度的“最后的演讲”，这往往是邀请八九十岁的有终生成就的人来讲最后一课。 http://download.srv.cs.cmu.edu/~pausch/ http://en.wikipedia.org/wiki/Randy_Pausch 那次请他来，大家都怀着非常沉重的心情参加，因为他的生命只剩下最后几个月了。结果他在 台上谈笑风生，做俯卧撑，讲笑话。他说：“我不想你们感到悲伤，而希望看到你们快乐。”整个演讲洋溢着对人生的乐观，充满了幽默。他知道自己活不过圣诞 节，但是在整个演讲过程中，你看不到任何一点悲哀绝望的东西，整个演讲充满活力、幽默和情趣。这就是NBC,CBS等大的媒体都采访他的原因。他的演讲下 载量是最高的，在美国家喻户晓，即使老百姓也都深刻地体会到他的人生观——无论生命还剩几天，都要好好的去享受这个过程，他用自己的生命诠释了这一切。 还有我个人的一个体会，有一次儿子送我一本书——《放慢你的生活脚步》作为礼物，书中说 现代社会生活节奏越来越快，技术越来越先进，从座机到手机，从短信到电子邮件到因特网，高速公路地铁飞机越来越现代化，但是唯独没有看到我们的生活越来越 轻松，反而我们的时间越来越少，整天都在忙忙碌碌，这到底是为什么呢？人生难道就是为了做很多很多事情吗？书的主题就是让我们放慢脚步，享受过程，去欣 赏, 体验每一件事, 让生活变得更有意义。17岁的儿子就用他自己的方式批评我整天忙忙碌碌，跑的太快，忽略了享受过程。他后来又写了篇文章，也是这个观点，说出生在我们这样 的家庭，觉得少了些什么东西。他喜欢小提琴，他说拉小提琴的目的不是将一首曲子从头到尾准确无误的拉完，而是用自己的心去感受,去体验, 好好演奏每个音符, 让自己让听众都得到美的享受。我读了之后很受震撼。 我做演讲时经常引用一个例子，加百利•加西亚•马尔克斯（Gabriel Garcia Marquez）,诺贝尔文学奖的获得者，他是哥伦比亚的作家，他的书《沧桑阅尽话人生》（Living to tell the tale）中也反映了类似的思想，”生命的真諦不是你活过多少，而是你能记住和描述多少（Life is not what one lived, but what one remembers it and how one remembers it in order to recount it）。一般你能记住能描述的往往是比较重大比较意义的事. 生活中的事情如果忘掉了，等于没有活过。其实你的人生，你的灿烂你的色彩，全部都在你的记忆里。从某种意义上说，记忆才是你的生命。我拿这个例子来说回忆 是多么重要，也说明过程非常重要，而且你要记住过程，这就是经验。 生活不是目的，而是过程。过程往往比目标更重要。林肯有句名言，人生的价值不在与你活了 多少年，而在于每一年中你有多少精彩的生活（In the end it's not the years in your life that count. It's the life in your years）。有的人即使活到百余岁，其生命没多大意义，有的人生命非常短暂，但却非常灿烂，灿烂到能够照耀到几百年后直到今天。苏格拉底很早就被人杀死 了，但是他留下的思想今天还闪闪发光；莫扎特英年早逝，但是他创造的音乐至今使世界为之倾倒。威廉姆•布罗迪（William R. Brody）是霍普金斯大学（John Hopkins）的校长，他说不要问自己要做什么，而要问自己将要成为什么样的人。他的意思是不要过多思考我要做什么事，而要去想我要怎么活。我觉得这句 话很深刻，也说明了同样的问题，即要强调过程而非目的。 当然过程中我们不可避免的会遇到困难，你怎么来对待这个艰难的过程呢？这里我要讲一个 人，詹姆斯•斯托克戴尔（ James Stockdale）是越战期间被俘的美军最高将领，被俘后他受了二十多次拷问， 因为他官位最高，所以经常被带去电视台录像宣传如何优待俘虏。这种场合，他会拿着凳子砸自己的脸，把自己砸的鼻青脸肿，或者拿刮胡刀把自己脸上刮的都是 血，使敌人没法拿他做宣传。在这种情况下往往会产生两种人，一种是觉得过不了多久我们就会被释放，美国政府会救我们；另一种是认为自己没有希望了。斯托克 戴尔认为这两种态度都是不可取的，他认为首先要有信心，总有一天自己会被释放的，但是也不能盲目乐观，因为这很可能是一个漫长的过程。正是靠这种理智的乐 观使他后来发明一种使得监狱里其他的美国俘虏兵可以互相联络。在历尽八年的磨难后斯托克戴尔终于获释。他出狱后,根据他与在美国的太太的书信，写了一本 书，叫做《战争与爱情》(In Love and War)。斯坦福有个教授用他做例子，命名为斯托克戴尔原则, 来阐释成功企业应有的坚忍不拔的精神，即将种种难以忍受的经历变成人生的一大财富（I can turn the experience into the defining event of my life, which, in retrospect, I would not trade）.艰难，挫折，你是不能选择的，当上帝把不幸降临到你头上的时候你可能毫无办法，但是你可以选择怎么来面对。正如有人对命运的解释为“你无法 选择自己会遇到什么，这就是命，但是你可以决定如何面对，这就是运。” 你经历面对的过程最后将变成你个人独特的历史与经历。所以斯托克戴尔说, 这种艰难曲折的经历, 是金不换的. 丰富你的经历，因为它造就了你这个独特的人。每个人的经历，你去了哪些地方，交了什么朋友，经过什么事件，最终都阐释了“你是谁”。今天我可以站在这里讲 这么多东西，也正是因为我有这么多经历去定义我自己。人的品质, 魅力, 个性, 往往是从艰难挫折中发展出来的。 人的性格往往是在困难中发展完善的，布克•华盛顿（ Booker Washington）是美国早期的反种族歧视的黑人领袖，他有过这样一句名言：“衡量成功的标准, 不是你最终达到的目标，而是你克服的多少困难而达到那个目标。” 同样的成就，经过艰难困苦后达到的，我想会更有意义。很多人知道兰斯•阿姆斯特朗（Lance Armstrong）是一名无出其右的自行车运动员，他在环法自行车赛连续7次获得世界冠军，环法自行车赛可以算是所有运动里面最艰难的，但是更值得惊讶 也更让人肃然起敬的是在1996年，他得了睾丸癌，并且扩散转移到脑子里，他做了手术和化疗，一般来说能活下来就不错了，但是他在患病以后，还连续7年参 加世界上最难的运动并拿到冠军，这简直就是不可思议的。他后来写了一本书，It's Not About the Bike（中文书名为《阿姆斯特朗传》），他说自己在成功之外的东西更值得体会和学习，所以这本书叫做It's not about the bike，他说“假如没有癌症的话，我还不一定能赢环法自行车赛，它给了我新的力量。”是癌症这个经历造就了今天的阿姆斯特朗，使他变的与众不同。 我最后的建议是，你到底做什么不重要，重要的是做自己喜欢的事情。而要做自己喜欢的事情 就要努力去发现自己真正的兴趣与热情所在。当你做这个事情的时候你要想办法追求最好，追求卓越，在追梦的过程中，你会有一个精彩的过程，一个辉煌的人生， 追求每一天的过程，享受每一天，快乐每一天。一言以蔽之，做个好梦，然后去实现它。]]></content>
  </entry>
  <entry>
    <title><![CDATA[从“头悬梁、锥刺股”到时间管理-马老师不错的文章]]></title>
    <url>%2F2010%2F04%2F26%2F%E4%BB%8E%E2%80%9C%E5%A4%B4%E6%82%AC%E6%A2%81%E3%80%81%E9%94%A5%E5%88%BA%E8%82%A1%E2%80%9D%E5%88%B0%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86-%E9%A9%AC%E8%80%81%E5%B8%88%E4%B8%8D%E9%94%99%E7%9A%84%E6%96%87%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[看到了马老师写的文章，很不错，拿来一作收藏，二来分享，绝不有任何侵犯之意。时间管理在我们的生活中起到了非常重要的作用，我们似乎每天都很忙，又不知每天在忙些什么。忙的不知忙的什么，是很可悲的。同时，我们在工作的效率上没有很好的提高，仅是时间量上的积累，且不谈更多的人把时间过多的花在了一些杂七杂八的事情上。哎，人人想法不一，也不想妄下断言，工作生活兼要，切不可所谓的拼命工作，年轻时无妨到老了就很有体会了。竭泽而渔，杀鸡取卵要不得。送给工作在HW+SW的战友！读到王进老师在科学网关于时间管理的博文，深有启发！ http://sciencenet.cn/blog/user_content.aspx?id=315828自古以来，中国是一个崇尚勤奋的国家。古代就有“头悬梁、锥刺股”的故事。现代社会的报纸，当报道高考状元、考进哈佛大学的人物、著名科研工作者时，总是千篇一律强调他们每天从早到晚地辛勤劳作，每周工作近百小时。的确，勤能补拙，勤奋也是我们国家不可丢弃的优良传统。但是大家有没有深究：为什么读高中的时候，大家花的时间都差不多（白天都在课堂上，晚上要完成回家作业），但是结果会有如此大的差别？报纸上总是说硕士期间出20篇SCI论文的同学取得了巨大成功，是因为他每天工作16小时，但是大家有没有想过：为什么每天工作8小时的同学没有发表10篇SCI论文？也曾看到很多研究生从早到晚地忙碌在实验室：吃在实验室，学习在实验室，娱乐在实验室，甚至睡在实验室，但为什么几年过去了，什么成果都没有？这说明了什么问题？ 出国前，我是一个非常强调勤奋的人。出国后，一开始我在给导师的月度报告中以表格形式记录了自己每天干什么，比如星期一上午做了什么实验、下午做了什么实验。在年度考评的时候，我罗列出无数数据，并且列出我看过的几十种杂志，说我为了做这个课题读了几百篇文献。但是美国博导对我说：不需要看到我向他汇报上午做了什么、下午做了什么，也不需要向别人汇报读了几篇文献，关键是效果。我的美国博导说，你勤奋，但是未必要让别人看见你的汗水（勤奋），作报告的时候，越是难的课题，你就是要把它讲得轻松自在，听众才会觉得你聪明。可是，我还是没有悟出导师的话。我在实验室从早到晚地干着活，象完成任务似地记录着今天干了这个、明天干了那个，周末带着女朋友给我做的饭菜到实验室干活。结果，长此以往，女朋友受不了了，提出分手！听到这个，我如一盆冷水浇了下来。一个“过来人”对我说：科研和工作都是一个长期的过程，是“马拉松”，不是“百米冲刺”。如果年轻的时候“竭泽而渔”的话，工作和生活（家庭）的平衡无法维持。“死到临头”，我被迫改变了自己， 周末也尝着和女友出去玩，平时抓紧干活。我的观念改变最大的是做博士后的时候。一开始和妻子两地分居，我周末也去实验室干活，但是由于没有“侦探地形”就一头扎进了实验，得到了一堆废数据，起初的三个月时间都浪费了。我接触了一些时间管理的书（如关于work-lifeblance的书、The 7 Habits of Highly Effective People、Brian Tracy写的Eat That Frog！等），并在实践中悟出时间管理的奥秘。我一周工作五天，周末都在家里看书、学习，做博士后三年半不但出了十多篇第一作者文章，还出了十多篇第二作者文章，并且还在报刊杂志上发表关于教育和科研的文章九篇。可以说，时间管理方法具有强大的魔力，能够带动效率的飞跃。 http://sciencenet.cn/blog/user_content.aspx?id=289037 如今，读到王进老师总结的时间管理秘诀，感到格外亲切。时间管理、提高效率，值得大力提倡和学习。如果能够照王进老师所说的每一条去做的话，一定能实现巨大提高！以往我国媒体报道先进人物的时候总是反复强调如何用功（正如说到别人回国，总是千篇一律地写道“断然放弃国外高薪聘请，毅然回国报效祖国”），但是这种“高、大、全”似的写作风格需要改变！这种新闻报道的思路使我想起中学老师总是在课堂上大声疾呼：“要抓紧分分秒秒，创造中考、高考的辉煌！”成功的人，以结果为导向，以目标为导向。自信的人，用成果来说话，是不需要强调自己每周工作多少小时的。或者说，自信的人有自己的价值理念和幸福标准，无须向别人自我辩白自己的成果和超额工作时间。最近《中国青年》报道饶毅教授的时候，就提到饶毅“几乎从不加班”。建议国内媒体多介绍些关于时间管理的实用内容。比如 王进老师的博文，很值得发表、珍藏和学习！]]></content>
  </entry>
  <entry>
    <title><![CDATA[岁月神偷]]></title>
    <url>%2F2010%2F04%2F25%2F%E5%B2%81%E6%9C%88%E7%A5%9E%E5%81%B7%2F</url>
    <content type="text"><![CDATA[昨天看了岁月神偷，虽然主旋律中的励志信念，加上故事中折射出的感人，但是我却不能说是特别出色的片子，感觉有的地方欲言又止，所以我没觉得很感动。但是片中的音乐都配搭的很贴切，听起来很美，让人有种怀旧的冲动，不过任达华表演的应该算很用心了，得到金像奖影帝也不算过分了。还有其他的多个小人物都是用心的表演，总体上看过后应该有种淡淡的温暖吧-做人总要信。]]></content>
      <tags>
        <tag>闲散</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[地球很精彩 奥秘仍难解]]></title>
    <url>%2F2010%2F04%2F22%2F%E5%9C%B0%E7%90%83%E5%BE%88%E7%B2%BE%E5%BD%A9%20%E5%A5%A5%E7%A7%98%E4%BB%8D%E9%9A%BE%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[参考科普信息： http://www.yic.cas.cn/kpzx/kpzl/201005/t20100511_2843098.html 了解节能减排的一些活动]]></content>
  </entry>
  <entry>
    <title><![CDATA[中国节能任重道远]]></title>
    <url>%2F2010%2F04%2F19%2F%E4%B8%AD%E5%9B%BD%E8%8A%82%E8%83%BD%E4%BB%BB%E9%87%8D%E9%81%93%E8%BF%9C%2F</url>
    <content type="text"><![CDATA[参见 http://blog.sciencenet.cn/blog-374251-314143.html 倪维斗先生的博文]]></content>
  </entry>
  <entry>
    <title><![CDATA[品位乡愁]]></title>
    <url>%2F2010%2F04%2F17%2F%E5%93%81%E4%BD%8D%E4%B9%A1%E6%84%81%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718乡愁 -- 余光中 小时候 乡愁是一枚小小的邮票 我在这头 母亲在那头 长大后 乡愁是一张窄窄的船票 我在这头 新娘在那头 后来啊 乡愁是一方矮矮的坟墓 我在外头 母亲在里头 而现在 乡愁是一湾浅浅的海峡 我在这头 大陆在那头 下雨的时候也许特别会让人想起很多伤感的东西，如果远在异地也会想起故乡的那篇土地，那里的亲人，读读余先生的乡愁真是别有一番滋味在心头。]]></content>
  </entry>
  <entry>
    <title><![CDATA[再读雨巷]]></title>
    <url>%2F2010%2F04%2F17%2F%E5%86%8D%E8%AF%BB%E9%9B%A8%E5%B7%B7%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243雨巷 -戴望舒 撑着油纸伞，独自 彷徨在悠长，悠长 又寂寥的雨巷， 我希望逢着 一个丁香一样的 结着愁怨的姑娘 。 她是有 丁香一样的颜色， 丁香一样的芬芳， 丁香一样的忧愁， 在雨中哀怨， 哀怨又彷徨； 她彷徨在这寂寥的雨巷， 撑着油纸伞 像我一样， 像我一样地 默默彳亍着， 冷漠，凄清 ，又惆怅。 她静默地走近 走近，又投出 太息一般的眼光， 她飘过 像梦一般地， 像梦一般地凄婉迷茫。 像梦中飘过 一枝丁香地， 我身旁飘过这女郎； 她静默地远了，远了， 到了颓圮的篱墙， 走尽这雨巷。 在雨的哀曲里， 消了她的颜色， 散了她的芬芳， 消散了，甚至她的 太息般的眼光， 丁香般的惆怅。 撑着油纸伞，独自 彷徨在悠长，悠长 又寂寥的雨巷， 我希望飘过 一个丁香一样的 结着愁怨的姑娘。 每当下雨天的时候，都会莫名的会想起这首优美的诗，伤感中的美丽，恬静下的寂寥。字字都蕴含着一息一息的淡淡感伤，这样的时候，这样的地方，确实如此。]]></content>
  </entry>
  <entry>
    <title><![CDATA[大师Linus Pauling的故事]]></title>
    <url>%2F2010%2F04%2F14%2F%E5%A4%A7%E5%B8%88Linus%20Pauling%E7%9A%84%E6%95%85%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[看到了这篇王老师写的文章，里面的评论很不错，读后很有收获，拿来和大家分享一下。听大师Linus Pauling讲“诺贝尔奖背后的故事” Linus Pauling是最伟大的科学家之一，也是少数几个获得两次诺贝尔奖的大师之一。上周我拿他的故事为例，给大学生讲“摩登化学”（官方称“当代化学”，呵呵），大家还挺有兴趣的，拿出来分享一下。 Pauling 获得Nobel Chemistry prize主要归功于1931年在Journal of American Chemical Society上发表的一篇文章：“The Nature of the Chemical Bond. I. Application of ResultsObtained from the Quantum Mechanics and from a Theory of ParamagneticSusceptibility to the Structures of Molecules”，1931, 53, 1367。1979年8月6日他写过一篇散文（全文图片见http://osulibrary.oregonstate.edu/specialcollections/coll/pauling/bond/notes/1979a2.10.html），介绍了这个“诺贝尔奖背后的故事”。（注：红斜体为原文，黑汉字为本人评论） “During my early years as a scientist, beginning in 1919, I had a special interest in the problem of the nature of the chemical bond; that is, the nature of the forcesthat hold atoms together in molecules, crystals, and substances. Much of my work during this early period was directed toward a solution ofproblem, by application of both experimental and theoretical methods.” 从这一段可以看出三点： (1) Pauling还是个大学生的时候（1917-1922），就已经自称为“科学家”了，更确切地说，树立了要当“科学家”的伟大目标。因此，现在有人甚至还在争议“科学家”与“科学工作者”等称号的“级别”，多么可笑啊！ (2) 想当科学家，有个特别感兴趣的问题非常重要！还是本科生的Pauling，就认准了一个问题，一生再也没有放弃过！ (3) 为了能解决问题，实验与理论并重。虽然普遍认为Pauling是个理论化学家，但实际上他对实验的掌握程度绝对不输于任何一个实验化学家，他的博士学位其实就是做的实验研究。 “As soon as quantummechanics was discovered, in 1925, I began striving to apply thispowerful theory to the problem. I published several theoretical papersin this field during the next few years, without, however, having beenable to answer a number of important questions.” 从这一段可以看出三点： (1) Pauling能及时发现、并充分利用现有条件开展有效的工作。量子力学在当时还是非常抽象的（当然至今仍然是^_^），基本属于物理研究领域。但是，做为一个刚毕业的搞化学的博士生，Pauling就能主动拿过来为己所用，是不是要比现在那些“饭来张口、衣来伸手”型的研究生好很多？ (2) Pauling不怕失败，虽然没有解决自己的问题，但仍然保持高度热情，大有不解决誓不罢休的豪情。看来，没志气是不会有多大出息的。 (3) 发表学术论文是做为一个科学家的基本功夫，是最基本的科研训练，虽然都是解决不了问题的“垃圾”，对于年轻科学家来说，还是非常必要的。 “Then one evening, inDecember, 1930, while I was sitting at my desk in my study at our homeon Arden Road and California Street, in Pasadena, California, I had anidea about a way to simplify the quantum-mechanical equations in such amanner as to permit their easy approximate solution. I was so excitedabout this idea that I stayed up most of the night, applying the idea to various problems.” 从这一段也可以看出三点： (1) 搞科研不分场合地点，即使在家里，脑子里想的还是科学问题！现在有多少人能做到这一点？陈景润应该算一个，走路都撞电线杆。不要说在宿舍了，就是在实验室里，也是QQ消磨时间！教授？教授的问题都在饭桌上解决了，呵呵！ (2) 创新成果靠积累，虽然只是一闪念，但这一闪需要长期坚持不懈的积累才行哦！只有等到云雾的电压积累的足够高的时候，才能一道闪电耀眼，正所谓“山穷水尽疑无路，柳暗花明又一村”是也！山不穷、水不尽，是看不到路的。 (3) 科学家的特点就是对自己的成果感到“兴奋”，兴奋的一夜都睡不着觉！兴奋的感觉来源于“自我实现”，当然是兴趣使然。那些按部就班的“研究”，到点下班，即使有个金元宝在前面等着捡，也要先睡一觉等到明天再干，据说寒号鸟就是这么冻死的！ “During the next twomonths I continued to work on this idea, and to write a papercommunicating the results of its application to the problem of thenature of the chemical bond. As I recall, the manuscript to which thisis an introduction was written in early February 1931. A typescript wasprepared from it, and the manuscript was put in the wastepaper basket,presumably by me, although I do not have a clear memory of this matter.Forty-seven years later the manuscript was given to me by ProfessorRalph Hultgren. In 1931, Ralph Hultgren was one of my graduate students, working for his Ph.D. in chemistry. He stated, when he gave me themanuscript, that he had removed it from the wastepaper basket and hadkept it for the intervening forty-seven years.” 从这一段可以看出两点： (1) 自己写的“草稿”最好不要随便扔到垃圾桶，说不定哪天就成了文物！(2) 当个勤快的学生很重要，每天替老板倒垃圾，看似是下等活，但也能跟着老板名垂青史，呵呵！当然，这离不开对老板的尊重与信任。 “I made some changes inthe typescript, and the revised typescript was submitted to the editorof the Journal of the American Chemical Society” on 17 February 1931. It was published in the April issue, which appeared on 6 April 1931, onpages 1367 to 1400 of the JACS, Volume 53. The short time that elapsedbetween receipt of the article and publication in the Journal indicatesthat the Editor of the Journal, Professor Arthur B. Lamb of HarvardUniversity, did not go through the usual process of submitting the paper to referees for criticism, but instead decided that it was proper forit to be sent immediately to the printer.” 从这一段可以看出两点： (1) 文章能否发表，与编辑、评审人关系不大，只有作者自己才是文章发表与否的决定者！你的文章有真货，自然能发表，而不是靠与编辑、评审人进行所谓的“争论”来达到目的，当然更不可能是花钱买啦！ (2) 即使文章不受“同行”普遍所认知，一样也可以闪光。据当时JACS的主编Lamb后来说，没有对Pauling的文章进行评审是因为：“could not think of anyone qualified to referee it”。因此，根本用不着抱怨自己的成果“太超前”而发表不了，如果是真家伙，发表根本就不是问题。 后面还有两段，篇幅所限，从略。从以上几点，或许已经能够体会到Pauling为啥能够获得Nobel奖了。再反过来对照一下我们自己，是不是也能找到为啥无法获得Nobel奖的原因呢？关于这位伟大的科学家-Linus Pauling，可以看维基百科，里面介绍了这位传奇的科学家的一些事情。]]></content>
  </entry>
  <entry>
    <title><![CDATA[读徐志摩的沙扬娜拉]]></title>
    <url>%2F2010%2F04%2F11%2F%E8%AF%BB%E5%BE%90%E5%BF%97%E6%91%A9%E7%9A%84%E6%B2%99%E6%89%AC%E5%A8%9C%E6%8B%89%2F</url>
    <content type="text"><![CDATA[最是那一低头的温柔，像一朵水莲花不胜凉风的娇羞，道一声珍重，道一声珍重，那一声珍重里有蜜甜的忧愁 — 沙扬娜拉！ 爱情的羞涩，离别的留恋，忧而不浓，美而不娇，甚美。]]></content>
  </entry>
  <entry>
    <title><![CDATA[品读艾青]]></title>
    <url>%2F2010%2F04%2F11%2F%E5%93%81%E8%AF%BB%E8%89%BE%E9%9D%92%2F</url>
    <content type="text"><![CDATA[123456789101112我爱这土地 艾青 假如我是一只鸟， 我也应该用嘶哑的喉咙歌唱： 这被暴风雨所打击着的土地， 这永远汹涌着我们的悲愤的河流， 这无止息地吹刮着的激怒的风， 和那来自林间的无比温柔的黎明…… ——然后我死了， 连羽毛也腐烂在土地里面。 为什么我的眼里常含泪水？ 因为我对这土地爱得深沉…… ——写于一九三八年十一月十七日 闲时读来，仍感诗中感情浓烈，让人回味无穷，因为我对这土地爱的深沉，多么美呀！]]></content>
  </entry>
  <entry>
    <title><![CDATA[博士论文--看到徐老师写的不错，遂拿来收藏]]></title>
    <url>%2F2010%2F04%2F09%2F%E5%8D%9A%E5%A3%AB%E8%AE%BA%E6%96%87--%E7%9C%8B%E5%88%B0%E5%BE%90%E8%80%81%E5%B8%88%E5%86%99%E7%9A%84%E4%B8%8D%E9%94%99%EF%BC%8C%E9%81%82%E6%8B%BF%E6%9D%A5%E6%94%B6%E8%97%8F%2F</url>
    <content type="text"><![CDATA[今天在科学网看到了徐老师写的一篇文章，关于博士论文的问题，里面的讲到的几个问题确实是当下的整体的大现象，如何从本质上解决这些问题，徐老师到是后面的一声叹息，让人感到不是滋味的无奈。 眼下的创新的难点在于多方面，我觉得本身的活多的在于部分的研究要么太脱离实际，要么突击战，申请的项目结题，完了。没有形成一定的深度，所以最终的结果的是导师的水平保持原来，博士的水平没见高涨，一个导师如果不能培养出比他杰出的学生，确实不是让人很敬佩。如果有导师能对自己的学生说，你已经在学术水平上超过我了，我相信这是导师的自己的骄傲，也是学生的自豪。（想到了冯卡门对钱学森说过的话）我们国家的科研还是任重而道远，看看美国人的整天的忧患意识，老怕别人超过自己，所以在不停的赶步，丝毫不敢停下来，而我们作为落后的一方，又怎能懈怠呢？说实话，没有懈怠的资本，如果说哪方面强了那也是片刻而已，世界的竞争如此激励，决不能沾沾自喜呀。博士作为国家科研的主力军，确实承担着国家兴的责任，虽然是要毕业为先，但还是希望能真正的做出写有价值的东西来，造福人类，光耀科学。如果如此心不甘情不愿，何必要费力的读个博士呢，混文凭？？那确实痛苦些，还是不要的好。踏踏实实做个工程师也是很好呀！ 不废话了，现把文章拿来，与大家一块分享！ 123456789101112131415161718192021222324252627282930博士论文：老生常谈的问题又到了学生们送审（博士学位）论文，赶着毕业，教授们忙于评审论文的季节。记得去年，所里的研究生部抽查了一部分已经被学位委员会通过的博士论文，外送盲审。返回的外部专家意见所指出的共性问题主要集中在三条：一是缺乏创新（或者说创新性不够），二是缺乏理论分析，三是写作不规范。从某种意义上来说，博士论文的水平与质量透视着一个学术（科研或教育）单位的学术水平、学术风气、人才培养质量和创新能力。从更高的层面上来说，也反映出一个国家科学研究和教育的水平，乃至未来研究队伍的潜力与素质。当今世界，至少有相当一部分重要的科学研究成果是由攻读博士的学生们在教授的指导下完成的。问题一：缺乏创新。创新是整个研究工作的核心，没有创新，也就谈不上工作的意义。影响创新能力的因素固然复杂，但从智力的层面上来说，既取决于导师，也取决于学生。导师如若没有长期的专业积累和高屋建瓴的洞察力（vision），不能将学生引领到学科的前沿地域，提出最为重要、关键的问题，即便是学生再聪明，再努力，也只能是玩一些低层面上的小把戏，谈不上高层次（高端）的创新。这就如同低水平的教练，培养不出世界冠军一样。另一方面，如果学生自身的基础条件差（不是那块料），教练即便是肝脑涂地，呕心沥血，也无能为力。正如毛主席所说，鸡蛋可以孵出小鸡，而即便是再好的条件下，石头也孵不出小鸡来。创新固然艰难，但我们必须去追求。唯有追求，才有可能产生卓越，才能让中国人在世界上“活得更有尊严”。可悲可怕的是没有追求。更可怕的是压根就没有创新，却自吹自擂，夜郎自大，堂而皇之地巧取名利。问题二：缺乏理论分析。长期以来，重实际、轻理论的观念与文化占据主导地位。使得搞理论，搞基础的人陷于经费困难的尴尬局面。有些人借一些低水平“理论”（既无理论根基又缺乏实验佐证）的无用来大批“理论”无价值，大肆否定理论研究的意义。导致为理论研究付出的辛勤劳动得不到认可，学生们畏惧理论，不愿意去钻研、弄懂、学习理论，见到公式就躲。连他人提出的理论都看不懂，就更谈不上理论层面的创新了。长此以往，使得从事理论研究的人才和有一定理论基础的学生愈来愈匮乏，大量实验上的数据缺乏认真的分析、整理，缺乏在理论层面的归纳、总结。满足于在低端学术期刊上匆匆发表。所谓的论文，不过是测量数据或者观察结果堆砌而成的“报告”而已。真正的“Science”愈来愈成为我们的软肋。所以，学生们的（学位）论文缺乏理论分析也就不足为怪了。问题三：写作不规范。按道理来说，这一条原本就不应该发生。没有创新、没有理论分析这些“内容”上的东西，只要尽力了，也就罢了，至少在“形式”上也得说得过去。因此，这一条是最不应该得到宽恕和原谅的。导致其发生的原因可能有以下两条：一是学生（甚至也可能包括其导师在内）缺乏规范的科学论文写作的基本训练；二是对论文写作根本就没有以认真态度来对待。有的学生对学位论文写作的艰难严重估计不足，为了搭上毕业的末班车，粗制滥造；有的导师不负责任（或者是没那个水平），敷衍了事，对学生的论文既不修改，也不提要求，听之任之。使学生们失去了难得的最后一次专业训练的机会。博士论文写成这个样儿，还谈什么培养人才？一个连学位论文都不认真对待，错误百出的人（作者），能够在将来的工作中担当重任，令人信赖吗？问题找到了，也可谓是老生常谈，成了“和尚头顶的虱子——明摆着”。但似乎却没有一处改进医治的良方（一剂“猛药”）。只能是面对其周而复始，一声叹息而已！http://www.sciencenet.cn/m/user_content.aspx?id=310169]]></content>
  </entry>
  <entry>
    <title><![CDATA[真不好意思]]></title>
    <url>%2F2010%2F04%2F08%2F%E7%9C%9F%E4%B8%8D%E5%A5%BD%E6%84%8F%E6%80%9D%2F</url>
    <content type="text"><![CDATA[今天下午去听报告，因为看到的时候比较晚，人家是下午2点，我到1点50分才看到。急匆匆的跑到那里，也没带纸和笔.所以当时就跟别人借，旁边的男士们没有多余的笔了，到稍微靠后的地方向一个女生借来一支（因为当时看见她有个笔袋，所以肯定有多余的）。听完报告后，要去还的时候，发现人不见了，真是弄得我不好意思。这事弄得，哎。 报告介绍了他们课题组的无线传感器网络设计的相关工作，挺有收获。]]></content>
  </entry>
  <entry>
    <title><![CDATA[2009年4月5日，注定是个不平凡的日子]]></title>
    <url>%2F2010%2F04%2F05%2F2009%E5%B9%B44%E6%9C%885%E6%97%A5%EF%BC%8C%E6%B3%A8%E5%AE%9A%E6%98%AF%E4%B8%AA%E4%B8%8D%E5%B9%B3%E5%87%A1%E7%9A%84%E6%97%A5%E5%AD%90%2F</url>
    <content type="text"><![CDATA[2009年4月5日，对于王家岭煤矿来说注定是个不平凡的日子，3.28透水事故至今已经发生了170多个小时。从最初排水进展的缓慢让人心急如焚，到今日凌晨0时40分见证生命奇迹诞生的时刻让人热泪盈眶：首批成功救出4名井下被困人员，紧接着是一批批的被救人员出井，13时34分许：王家岭煤矿“３·２８”透水获救者已达到106人。按捺不住心里的激动和欣喜。大爱无私，全国人民的心在紧紧牵挂被困的矿工弟兄们。当看到录像中的救援人员激动的痛哭流涕的时候，我的眼角湿润了。 是啊，艰难疲惫的救援工作终于换来了鲜活的生命，那份敬畏生命，珍惜生命的感受已经难以用言语表达了；当看到被救矿工的那瘦弱煤黑的手臂时，我难以想象被困在如此恶劣地环境长达170多个小时的那种顽强生命的抗争，除了敬畏，我不知道该说什么好；当听到救援人员因为疲惫不堪而在救援现场打盹的时候，我只想说你们真的付出了所有大爱。作为一个普通百姓，我只能默默的感谢搜救人员的艰辛努力，是你们的大爱让更多的矿工兄弟们与死神插肩而过，被困的兄弟们挺住，因为有大爱就会铸就奇迹。 注以上的一些数据来源：http://nf.nfdaily.cn/yaowen/content/2010-04/05/content_10758377.htmhttp://news.163.com/10/0405/11/63GM36FA000146BD.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[王家岭的兄弟们，挺住]]></title>
    <url>%2F2010%2F04%2F03%2F%E7%8E%8B%E5%AE%B6%E5%B2%AD%E7%9A%84%E5%85%84%E5%BC%9F%E4%BB%AC%EF%BC%8C%E6%8C%BA%E4%BD%8F%2F</url>
    <content type="text"><![CDATA[塌方，瓦斯爆炸，透水事故，最近的一段时间煤矿的安全事故发生的颇为密集，对于这些事故我不愿再多说什么，再一次一次杯具面前指责都变的苍白无力，为什么一次一次上演？或许某些人从来未曾反思，从来未曾尊重生命，我确是出离的愤怒，无奈和悲哀了。 当听到第五天王家岭煤矿的救援现场地下巷道传来的敲杆声，我的心几乎都快跳出来了。希望在，真的在。看着网上的报道都一直在揪心，几天了，水依旧没排完，进展缓慢，我只能祈祷这些兄弟们坚持住，因为我敬畏生命，相信奇迹。 施工现场的兄弟们也要奋力抢救，你们也许很累，但是一想起底下的兄弟们传达出来的敲杆声，我相信你们就有无穷的动力和决心，明天把人救上来。 默默期待底下的兄弟们平安。]]></content>
  </entry>
  <entry>
    <title><![CDATA[环境问题-人的问题]]></title>
    <url>%2F2010%2F03%2F20%2F%E7%8E%AF%E5%A2%83%E9%97%AE%E9%A2%98-%E4%BA%BA%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[西南5省市干旱，沙尘蔓延数省，加上前段时间的不正常雨雪，真不知道最近到底怎么了，我们的环境似乎在一步步朝着恶化的地方前进，虽然出台了一系列的环境保护法规，法律，但是你不见那地方上的企业利益熏心，连人都不当回事，更别提什么环境了，真不知道是我们人类的悲哀还是活该。哥本哈根会议是取得了一个框架式的东西，没有什么法律约束性的实质达成。其实大家都在为自己国家拉筹码，扯皮。这是无话可说，但是不敢想象人类若干年之后的生活会是什么样子 （如果能迁移出太阳系的话，那么可以暂时不考虑这个问题。其实人也不会关心太远，这也就奠定了最终的解决是走一步看一步。大都是看到问题出现了，才会解决，绝不会主动谈什么环境问题。）]]></content>
  </entry>
  <entry>
    <title><![CDATA[转：“被创新了”：那些消失了的工种-很好的一篇文章]]></title>
    <url>%2F2010%2F03%2F20%2F%E8%BD%AC%EF%BC%9A%E2%80%9C%E8%A2%AB%E5%88%9B%E6%96%B0%E4%BA%86%E2%80%9D%EF%BC%9A%E9%82%A3%E4%BA%9B%E6%B6%88%E5%A4%B1%E4%BA%86%E7%9A%84%E5%B7%A5%E7%A7%8D-%E5%BE%88%E5%A5%BD%E7%9A%84%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[本文引用韩建科学网的博客。感到行文分析入理，对于我们这些从事技术的开发人员等很有启发，遂拿来引用 1234567891011121314151617181920“被创新了”：那些消失了的工种闲来和老丈人聊天，讲到他在台湾创业经历：二战期间他当兵，学了一手电器修理的绝活，于是战争结束后自己开店修理收音机等家用电器。一路做了三十年，从真 空管收音机，到半导体，什么他都能修，生意也很红火。可是到了集成电路时代，慢慢地，生意就没有了。也记得小的时候，我父亲也有一个能收短波的真空管收音机，总是坏，需要送去修理。有点象下面图片里的型号，是飞跃牌的。前些天在华尔街报的网站上还看到列出十几个已经消失了的工作：包括电梯操作员（不知道国内为什么还有），电话接线员等（google "jobs no longer exist")。无线电修理，最后也和很多工种一样，消失了。这些工作为什么消失了？一个简单的答案就是被新技术取代了。可是，只有更深地分析这个问题，我们才能学到“不被替代”甚至是“替代别人”的诀窍。从质量不保证的真空管，到体积又小，质量又稳定的半导体，产品（收音机）的质量有了明显的提高，需要修理的机会也越来越少。所以稳定质量，批量生产，成本降低，就是一个技术和产品发展的大方向。如果你的工作是顺着这个大方向的，就相对稳定。如果你的工作是以产品和服务的不稳定为前提的，那你的工作也会是暂 时的。把这个转换到生物技术上来该如何理解？假设你找到一份工作，给Luminex技术平台做售后服务，维修仪器。这看来是一个很好的工作。可是你是否想过，如果一个仪器一点到晚总是坏，那这个公司的产品可能就有问题，一旦其它厂家生产出更好的产品来，很少坏，那我的工作不就没有了吗？这可以总结为“顺技术者昌，逆技术者亡”。类似推理也可以用到科研选题上面来。选择上升期的新课题，用最新的技术，做最新的发现，就永远处于让他人的工作过时的地位。相反，就很被动，时刻都有丢饭 碗的可能。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Donald Knuth-把一件平常事做到人间极致，佩服]]></title>
    <url>%2F2010%2F03%2F14%2FDonald%20Knuth-%E6%8A%8A%E4%B8%80%E4%BB%B6%E5%B9%B3%E5%B8%B8%E4%BA%8B%E5%81%9A%E5%88%B0%E4%BA%BA%E9%97%B4%E6%9E%81%E8%87%B4%EF%BC%8C%E4%BD%A9%E6%9C%8D%2F</url>
    <content type="text"><![CDATA[相信大家（从事计算机行业的大牛和小牛）都对唐纳德·克努斯(Donald Knuth)有所耳熟吧，这位图灵奖史上最年轻获奖者就是按照这个信念：把一件平常事做到人间极致，计算机程序设计艺术，卷卷包含了艺术的灵巧和美丽，而后的排版系统TEX更是出版界的革命，直到现在仍是全球学术排版的不二规范（引自科学网的话），一个个奇迹，正是这个信念让这位大师取得了骄人的成就。 当下充斥的浮躁情绪确实是我们国家科技最大的敌人，至于浮躁情绪的背后的东西都是需要我们努力改进的，我们都需要反思，反思之后更多的应该是实践，执行。—经典在继续，我们也要不停的奋斗，努力的学习。]]></content>
  </entry>
  <entry>
    <title><![CDATA[纳兰容若《木兰花令·拟古决绝词》欣赏]]></title>
    <url>%2F2010%2F03%2F05%2F%E7%BA%B3%E5%85%B0%E5%AE%B9%E8%8B%A5%E3%80%8A%E6%9C%A8%E5%85%B0%E8%8A%B1%E4%BB%A4%C2%B7%E6%8B%9F%E5%8F%A4%E5%86%B3%E7%BB%9D%E8%AF%8D%E3%80%8B%E6%AC%A3%E8%B5%8F%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[谣传，反思自己呀]]></title>
    <url>%2F2010%2F03%2F04%2F%E8%B0%A3%E4%BC%A0%EF%BC%8C%E5%8F%8D%E6%80%9D%E8%87%AA%E5%B7%B1%E5%91%80%2F</url>
    <content type="text"><![CDATA[今天最晕的事情莫过于看到http://news.sciencenet.cn//htmlnews/2010/3/229064.shtm霍金不满英国削减科研经费欲移民加拿大这则消息，前段时间还以为这位伟大的科学家去世了（铺天盖地的消息），原来是谣传，这位伟大的科学家霍金健在。 哎，喟叹自己的对消息真伪的辨别力了，真的改反思反思了！]]></content>
  </entry>
  <entry>
    <title><![CDATA[不要让农民工回家这么辛苦]]></title>
    <url>%2F2010%2F02%2F04%2F%E4%B8%8D%E8%A6%81%E8%AE%A9%E5%86%9C%E6%B0%91%E5%B7%A5%E5%9B%9E%E5%AE%B6%E8%BF%99%E4%B9%88%E8%BE%9B%E8%8B%A6%2F</url>
    <content type="text"><![CDATA[今天听广播新闻，农民工买票难，想出回家新方法。原来是一些农民工买到重庆的车票始终买不到，最后改用买辆摩托车，为了不迷路，还买了一个带GPS导航定位的手机（1300多），一路上疲惫不堪，历经3天到达老家。 听后，心里不觉的一痛，真不知道广播中的“回家新方式”，到底是对农民工回家方式的好奇而播报，还是抑或对我国铁路运输的极大讽刺，其实火车票的需求是虽然在年底是很疯狂，但是加开的列车应该是铁道部在有效估计乘客流量的前提下做出的合理计划，那既然合理，票怎么难买呢？票贩子的问题，这个目前是很严重，但是如何防止火车票的不合理流向，真正遏制票贩子现象，这应该是政府的尤其是铁道部的责任吧，广东的实名制不知道效果如何，且待今年春运后，再做定论。在大城市火车站，你都会发现执勤的工作人员都在倒票，你要在火车站的大厅里退票时，保准一帮倒票的人围你个水泄不通。倒票利益链是存在的，也许我们不能杜绝它，但是至少应该将这种倒票现象遏制在一个很小的程度，否者就是不作为了。至少也可以看到农民工回家的高高性性的回家过年，不要这么辛酸的回家路了。真正的为人民服务，落到了实处。写于2010-2-4 晚]]></content>
  </entry>
  <entry>
    <title><![CDATA[谈谈自己对“教育部严禁再聘代课人员 将补偿被辞退者的一点看法”]]></title>
    <url>%2F2010%2F01%2F22%2F%E8%B0%88%E8%B0%88%E8%87%AA%E5%B7%B1%E5%AF%B9%E2%80%9C%E6%95%99%E8%82%B2%E9%83%A8%E4%B8%A5%E7%A6%81%E5%86%8D%E8%81%98%E4%BB%A3%E8%AF%BE%E4%BA%BA%E5%91%98%20%E5%B0%86%E8%A1%A5%E5%81%BF%E8%A2%AB%E8%BE%9E%E9%80%80%E8%80%85%E7%9A%84%E4%B8%80%E7%82%B9%E7%9C%8B%E6%B3%95%E2%80%9D%2F</url>
    <content type="text"><![CDATA[谈谈自己对“教育部严禁再聘代课人员 将补偿被辞退者的一点看法”（新闻来源http://news.163.com/10/0122/03/5TJR1G2J0001124J.html）： 教育部人事司副司长吕玉刚谈了对于目前代课人员问题的如何解决的一些看法，个人感觉出发点是好的，那就是保证教师队伍的素质，保障学生的利益。但是如何实施起来，怎样区别的对待目前的代课人员，没有提供明确的方案，提到需要地方的配合，对，但是目前的地方有多少能出台合理的政策呢？且不谈什么政策，先谈谈这边部分特殊的代课人员：代课人员称为代课教师，代课老师是学校因工作需要聘请的临时工。他们的工资待遇一般都是由单位自筹。学校事业单位编制工人的工资待遇由财政全额拨款。 来源:http://sp.meizhou.gov.cn/communicateWebAction.do?action=viewDetail&amp;forwardName=appViewDetail&amp;id=19583 他们为当地的教育事业奉献着自己的青春和力量，目前的公办教师中待遇要远远超过代课教师待遇，所谓一致提倡的公平，和谐，我不明白。代课教师的水平确实存在良莠不齐的情况，但是我们不能搞一刀切的政策，很多代课教师的教课水平要好于公办教师，他们的付出的努力也可能远大于公办教师，没有合适的名分不说，还要整天担心被辞退，所谓的照顾学生的利益，更不应该简单的把所以代课人员清退，因为大多数的代课人员已经具备了正式教师的资格，他们努力考取了教师资格证，自考获取了大学文凭，优秀的授课水平获得了学生和同行的肯定，这些人员应该怎么办？？其实客观的看来，这些人应该被立即的吸取到正式教师的队伍中，真正的保证了他们的合法权益和学生的利益，而不是受制于一些别有用心的人。也是和谐和公平的体现。吕司长还提到了允许合格代课人员进入教师队伍，这是很好的建议，的确的需要的。但是由于缺乏一个明确的指导，怎么实施，如何保证地方不存在滥用权走后门的路，如何进行刷选，公开招聘？考试？都是可以考虑的方方面面。 总之，希望我们的国家能够对这部分人员给与充分的关怀和照顾，不要让他们的数年数月的汗水和辛劳用简简单单的几百元来打发，他们可是真正对我国的基础教育事业起到了推动作用的群体。最后热切期待各地的允许合格代课人员进入教师队伍合理政策的出现。]]></content>
  </entry>
  <entry>
    <title><![CDATA[关于LXR和glimpse配置实现方便阅读Linux源代码的过程]]></title>
    <url>%2F2010%2F01%2F15%2F%E5%85%B3%E4%BA%8ELXR%E5%92%8Cglimpse%E9%85%8D%E7%BD%AE%E5%AE%9E%E7%8E%B0%E6%96%B9%E4%BE%BF%E9%98%85%E8%AF%BBLinux%E6%BA%90%E4%BB%A3%E7%A0%81%E7%9A%84%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[参考资料1： http://hi.baidu.com/fanzier/blog/item/3ad7d7546f58a55dd009066b.html 资料2：http://blog.csdn.net/zjujoe/archive/2009/05/18/4199025.aspx 其中的相同部分没有做修改，在此声明，有“注意：”的地方是结合自己的情况进行的修改。 (本人机器的OS—Ubuntu 9.10) 1.安装apache2 1$sudo apt-get install apache2 2.安装lxr 1$sudo apt-get install lxr 编辑修改lxr.conf文件 1$sudo vi /usr/share/lxr/http/lxr.conf 修改glimpse的路径 找到 glimpsebin这一行，修改成你机器上glimpse的位置（自己查看使用$whereis glimpse） 1glimpsebin: /usr/local/bin/glimpse 注：红色部分是我机器上的glimpse的位置 在/etc/apache2/httpd.conf 末尾加上以下内容: 1234Alias /lxr /usr/share/lxrOptions AllAllowOverride All 这样可以达到 http://localhost/lxr/ =&gt;/usr/share/lxr 在/usr/share/lxr/http下创建文件 .htaccess, 1$sudo vi /usr/share/lxr/http/.htaccess 并添加下面的内容: 1SetHandler cgi-script 重启服务 1$sudo /etc/init.d/apache2 restart 创建/usr/share/lxr/source/XX目录 (XX为版本号) 1$mkdir /usr/share/lxr/source/2.6.30.10 然后在/usr/share/lxr/source/2.6.30.10 下创建linux符号连接 1$ln -s /home/my/linux-2.6.30.10 /usr/share/lxr/source/2.6.30.10/linux 注：这里的黄色部分改成你目前的源代码的所在目录，比如 /home/you/linux-2.6.30.10 创建/usr/share/lxr/source/versions，这里记录所有要看的版本 1sudo vi /usr/share/lxr/source/versions 将下面的版本号（自己的源代码版本号）添加到versions中2.6.30.102.6.32.3 创建/usr/share/lxr/source/defversion，这里记录缺省要看的版本， 1$sudo vi /usr/share/lxr/source/defversion 添加缺省查看的版本号： 2.6.30.10 这里为什么是这两个文件，见/usr/share/lxr/http/lxr.conf里的相关设置 建立索引 1234$cd /usr/share/lxr/source/2.6.30.10/$sudo glimpseindex -H ../ ./linux $sudo genxref ./linux 上面的两个命令运行时间稍微长一些，主要是生成freetext交叉索引数据库（glimpseindex）和关键字交叉索引数据库（genxref），上面两个命令不可颠倒顺序，见下面的注 注： 资料1原文中的顺序是： 123$sudo glimpseindex -H /usr/share/lxr/source/2.6.22/ /usr/share/lxr/source/2.6.22/linux $sudo genxref 2.6.22 自己按照上面实验顺序后，发现最后的源码不能很好的链接上，不可以实现符号跳转，仅仅是显示代码 这里如果没有安装glimpse，运行sudo glimpseindex -H ../ ./linux ，会提示没有相关的命令glimpseindex 于是安装glimpse，需要到http://webglimpse.net/download.php下载glimpse-latest.tar.gz 然后在下载文件所在的目录执行 1234567$tar -zxvf glimpse-latest.tar.gz$./configure$make //注意这里会提示没有flex命令，需要安装flex ，直接sudo apt-get install flex$sudo make install 8.修改属性 1$sudo chmod +r -R /usr/share/lxr/source/2.6.30.10/* 重启服务 1$sudo /etc/init.d/apache restart 启动浏览器输入下面的URL即可查看，很方便呀！！ http://localhost/lxr/http/blurb.html 如果还要添加其他的版本源代码，只需要按照顺序从第6步执行一直到第9步，这样就可以查看多个版本的源代码了，比较方便。 附加心得： 最初在网上的找linux下的源代码查看工具，介绍的好几种，最初实验的kscope，有个问题就是他需要依赖下面的软件： Qt4 version 4.4.0 and above QScintilla2 (http://www.riverbankcomputing.co.uk/software/qscintilla/download) Standard build tools 安装上面的软件之后，make还是出错，发现提示一些cpp文件中未定义的符号，这个要一个个修改比较麻烦了。 所以后来又试了一下 deb包，安装提示需要libqscintilla2-3，好下载先安装这个libqscintilla2-3，然后安装kscope 的deb包，成功了！！后来发现根本启动不了，提示segmentation fault，这个郁闷坏了，网上有的说的是个bug，然后试着安装低版本的kscope—1.6.2，还是出现同样的segmentation fault，唉，暂时想不出解决反感，只好放弃kscope了。 接着实验global，发现好像是命令行的东西，要是命令行熟悉的话，就用vim+ctags了，只是想找稍微简单一点，我只是想浏览源代码，不想提前记好多命令，呵呵，有点懒啦，只好作罢 最后选择据说比较难安装的LXR，网上这方面的资料很多，一步一步接着做，然后修改了其中的一些叙说不完善的地方，发现竟然成功了，很好，原来这个复杂的东西不是这么夸张，比前面的要好点，还是幸亏这么完备的网上共享的资料呀，感谢那么多对这些资料做出过补充完善的作者！！ 最后的一点缺憾是不能像LXR主站上的服务器上的源代码的那种链接跳转，可能是哪里没有配置正确，不过还是迈出了一大步，下面在继续研究吧！！！ —-已经解决，就是前面的glimpseindex和genxref运行顺序问题， 12.将来问题 目前发现查看源代码跳转有时还是比较慢，我感觉是数据库查找效率问题，这是算法的问题吧，应该不牵涉浏览器的问题吧？？ 欢迎大家提出自己的看法。 `]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于虚拟机下的ubuntu访问windows xp共享文件，设置密码访问的方法]]></title>
    <url>%2F2010%2F01%2F10%2F%E5%85%B3%E4%BA%8E%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%8B%E7%9A%84ubuntu%E8%AE%BF%E9%97%AEwindows%20xp%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%EF%BC%8C%E8%AE%BE%E7%BD%AE%E5%AF%86%E7%A0%81%E8%AE%BF%E9%97%AE%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[关于虚拟机下的ubuntu访问windows xp共享文件，设置密码访问的方法 1.首先取消简单文件共享，具体设置为： 工具—-&gt;文件夹选项—-&gt;查看—&gt; 在高级设置中，去掉下面选项的√ 使用简单文件共享（推荐） 2.设置windows xp下的访问账户及密码 在window下，如果没有启用guest账户，那么可以启用guest账户（当然可以自己创建其他的账户），然后设置相关的密码。 关于设置guest密码 我的电脑—&gt;管理—-&gt;本地用户和组—&gt;用户—&gt;右边找到guest—&gt;右键选择 设置密码 点继续—&gt;输入密码—&gt;确定保存 3.具体访问方法 ubuntu下访问windows xp如下： 1$smbclient //要访问的IP/要访问的文件夹 比如： 1$smbclient //192.168.0.123/my_test 终端提示输入密码； 这时输入刚才设置的guest密码；就会出现： 1smb: \&gt; 这时就可以使用get命令下载所需要的文件了 当然设置了密码后，采用ubuntu 系统自带的连接到服务器功能访问，填写相应的字段即可。 4.额外说明 关于无密码访问，即使用简单文件共享，然后设置相关的共享文件夹即可。具体的访问方法同上面的说明（smclient或者ubuntu 系统自带的连接到服务器功能） 关于windows xp访问ubuntu的共享文件夹的设置可以参看资料2给出的详细介绍，主要是对安装samba后的配置文件smb.conf的修改。也有相关的密码访问和无密码访问设置） 对参考资料中的指导给出特别的感谢，也许有的无法找到原作者，再次一并致谢！！ 注：本例中的虚拟机下的ubuntu是可以上网的。 参考资料： [1] http://zhidao.baidu.com/question/360083.html?fr=qrl[2] http://wiki.ubuntu.org.cn/Samba]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux源码编译小记]]></title>
    <url>%2F2010%2F01%2F03%2Flinux%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%B0%8F%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[首先进行修改内核的步骤： 1.修改相应的c源文件 2.修改相应的Kconfig 3.修改相应的makefile (如果添加了其他的源文件) 然后开始内核的编译步骤： 注：如果不是初次编译，那么要在第5，6步之间运行下面的命令： 12make dep (检查编译过程中的依赖的文件和头文件的一致性)make clean (清除旧的目标文件) 首先make menuconfig，进行相关的配置，会生成内核配置文件 然后运行make命令 (编译内核) 运行make modules (编译模块) //这一步在2.6以后的内核不需要了，make命令已经集成了对模块的编译，本人在2.6.30.10的编译中也确定了这一说法 运行make modules_install (安装编译好的模块) 运行 mkinitramfs -o /boot/initrd-2.6.30.img /lib/modules/2.6.30(生成内核镜像文件) 运行make install (安装内核) 接下来就是修改启动选项，将你所编译成功的内核加载到启动选项中：运行gedit /boot/grub/menu.lst 按照上面原来的内核的启动选项格式书写即可。 注意： 如果在第5步没有进行相关的其他配置(除了对自己编写模块的编译配置那么最终生成的initrd文件会很大，比如我编译2.6.30.10的内核后就有57M多，而ubuntu系统自带的仅有8M多。 不要把7，8，9，10的顺序颠倒，具体结果没试验。 第10步将复制内核到boot目录，生成system.map。 第11步中menu.lst的vmlinuz及initrd的具体名字要和运行9，10后在/boot生成相关的文件一致。 本文参考了http://blog.chinaunix.net/u2/73525/showart_2015506.html，在此感谢！]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[新年瑞雪记]]></title>
    <url>%2F2010%2F01%2F03%2F%E6%96%B0%E5%B9%B4%E7%91%9E%E9%9B%AA%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[新年的第一场雪下的好大，从2号晚上持续到今天晚上，而且丝毫没有减弱的意思，漫天的雪花顺风飘向大地，晶莹剔透的雪花映射着泛黄的街灯，有种很让怀旧的冲动。 这个冬天的雪来的很早，这大概是第3场大雪了。每逢下雪，都禁不住站在空旷的场地张望着天空。对雪的喜爱由来很久，那种洁白之美，冲刷掉世界的污浊，滋润着干涸的心情。下雪的时候也是最能记起小时候的快乐时光，那时的点点滴滴很让人回味着岁月的变化之快。 今日心情甚佳，于是小“诗”一首： 新年恰逢瑞雪到 京城尽镀玉珍珠 晶莹剔透照无暇 漫天纷飞映街灯 此景此地甚为感 此地可曾再来顾 同是天涯奋斗人 何必在意此地住 聊以记下，时2010年1月3日19时]]></content>
  </entry>
</search>
